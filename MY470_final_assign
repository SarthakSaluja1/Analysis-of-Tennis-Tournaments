 2/1: print 'Hello world'
 2/2: print('hello world)
 2/3: print('hello world')
 2/4: x=5
 2/5: y=0.25
 2/6: z='hello'
 2/7:
x=2
type(x)
 2/8:
x=[2,3,4,5,'a;,.6]
type(x)
 2/9:
x=[2,3,4,5,'a',.6]
type(x)
2/10: x(0)
2/11: x[0]
2/12:
x=2
type(x)
x=[2,3,4,5,'a',.6]
type(x)
x[0]
#if else 
weight=90
if weight<50:
    print('eh')
    print('lol')
elif weight>50 and weight<100:
    print('good 1')
    print('kewl')
    print('wow')
else:
    print('uh')
2/13:
weight = 68
if weight <50:
    print('eh')
    print('lol')
elif weight>50 and weight<100:
    print('good 1')
    print('kewl')
else:
    print('uh')
2/14:
for I in range(5):
    print('hello',I)
2/15:
for I in range(3,10):
    print('abc')
2/16:
for I in range(3,10):
    print('abc',I)
2/17:
for I in range(3,10,2):
    print('a',I)
2/18:
while true:
    print("aaaaaaa")
2/19:
while True:
    print("aaaaaaa")
2/20:
x=5
while x<20 :
    print('h a l p')
    x=x-1
2/21:
x=5
while x<20 :
    print('h a l p')
    x=x+1
2/22:
x=[7,5,8]
len(x)
2/23:
x=[7,5,8]
len(x)
max(x)
2/24:
x=[7,5,8]
len(x)
max(x)
sum(x)
2/25: robotech_labs()
2/26: robotech_labs()
2/27: myfun(2,3,4)
2/28:
def myfun(a,b,c):
    d=a+b-c
    return d
2/29: myfun(2,3,4)
2/30: import code2
2/31:
import code2
code2.sar(2,3)
2/32:
import code2
code2.sar(2,3)
2/33: import time
2/34: time.ctime()
2/35:
print ('a')
time.sleep(5)
print('b')
2/36:
import time 
time.ctime()
print ('a')
time.sleep(5)
print('b')
2/37:
import time 
time.ctime()
print ('a')
time.sleep(5)
print('b')
2/38: import textblob
2/39:
import textblob
# Machine translation 
data = textblob.TextBlob('Hello everyone')
2/40: data.translate(to="hi")
2/41: data.translate(to="fr")
2/42:
data=textblob.TextBlob('aaaaa')
data.sentiment.polarity
2/43:
data=textblob.TextBlob('Rcae is a good movie')
data.sentiment.polarity
2/44:
data=textblob.TextBlob('Rcae is an awesome movie')
data.sentiment.polarity
2/45:
data=textblob.TextBlob('Rcae is a bad movie')
data.sentiment.polarity
2/46:
data=textblob.TextBlob('Rcae is not a bad movie')
data.sentiment.polarity
2/47:
data=textblob.TextBlob('Rcae is the worst movie')
data.sentiment.polarity
 3/1:
x=[4,5,6]
y=[7,1,2]
x+y
 3/2:
x=numpy.array(4,5,6)
y=numpy.array(7,1,2)
 3/3:
x=numpy.array([4,5,6])
y=numpy.array([7,1,2])
 3/4:
x=numpy.array([4,5,6])
y=numpy.array([7,1,2])
x+y
 3/5:
x=numpy.array([4,5,6])
y=numpy.array([2,3,8])
x+y
 3/6:
x=numpy.array([7,1,2])
y=numpy.array([4,5,6])
x+y
 3/7:
x=numpy.array([7,5,2,6,4])
x.max()
 3/8:
import numpy
x=[4,5,6]
y=[7,1,2]
x+y
#the lists will be merged
#you cant apply maths to lists
#need a mathematical entity, given by numpy - called arrays
x=numpy.array([7,5,2,6,4])
x.max()
 3/9:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.size()
3/10:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.size
3/11:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.size
x.shape
3/12:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape
3/13:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape#no. of elements per row
x.min()
3/14:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape#no. of elements per row
x.min()#lowest element
x.max()
3/15:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape#no. of elements per row
x.min()#lowest element
x.max()#largest element
x.min(axis=1)
3/16:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape#no. of elements per row, size is not an operation so dont use  paranthesis, as you cant pass an argument
x.min()#lowest element
x.max()#largest element
x.min(axis=1)
x.max(axis=0)
3/17:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape#no. of elements per row, size is not an operation so dont use  paranthesis, as you cant pass an argument
x.min()#lowest element
x.max()#largest element
x.min(axis=1)
x.max(axis=0)
x.max(axis=1)
3/18:
x=numpy.array([[4,5,6],[2,7,8],[11,2,9]])
x.shape#no. of elements per row, size is not an operation so dont use  paranthesis, as you cant pass an argument
x.min()#lowest element
x.max()#largest element
x.min(axis=1)#min value of every row. Thus axis=1 is used for rowise operation.
x.max(axis=0)#max value of every column. Thus axis=0 is used for columnwise operations
x.max(axis=1)#max value rowise.
x.min(axis=0)
3/19: x=numpy.arange(1,10,2)
3/20:
x=numpy.arange(1,10,2)
x
3/21:
x=numpy.arange(2,100,7)
x
3/22: x=numpy.random.rand(5)
3/23:
x=numpy.random.rand(5)
x
3/24:
x=numpy.random.randint(10,50,5)
x
3/25:
x=numpy.random.randint(10,50,(2,3))
x
3/26:
a=[[4,-3],[1,2]]
b=[14,9]
numpy.linalg.solve(a,b)
3/27:
m=numpy.matrix([[4,5,6],[7,5,2],[3,4,9]])
numpy.linalg.inv(m)
3/28:
m=numpy.matrix([[4,5,6],[7,5,2],[3,4,9]])
numpy.linalg.inv(m)*m
3/29:
m=numpy.matrix([[4,5,6],[7,5,2],[3,4,9]])
inv_m=numpy.linalg.inv(m)*m
inv_m.astype("int32")
3/30:
m=numpy.matrix([[4,5,6],[7,5,2],[3,4,9]])
inv_m=numpy.linalg.inv(m)*m
inv_m.astype("int16")
3/31:
m=numpy.matrix([[4,5,6],[7,5,2],[3,4,9]])
inv_m=numpy.linalg.inv(m)*m
inv_m.astype("int8")
3/32:
m=numpy.matrix([[4,5,6],[7,5,2],[3,4,9]])
inv_m=numpy.linalg.inv(m)*m
inv_m.astype("int")
3/33: inv_m.round()
3/34: inv_m.round(2)
3/35:
m1=numpy.matrix([[2,3,4,5],[7,8,9,1],[1,2,4,6],[0,1,2,3]])
numpy.linalg.inv(m1)
3/36:
m1=numpy.matrix([[2,3,4,5],[7,8,9,1],[1,2,4,6],[0,1,2,3]])
m2=numpy.linalg.inv(m1)
m2.round(2)
3/37:
m1=numpy.matrix([[2,3,4,5],[7,8,9,1],[1,2,4,6],[0,1,2,3]])
m2=numpy.linalg.inv(m1)
m3=m2.round(2)
m3*m1
3/38:
m1=numpy.matrix([[2,3,4,5],[7,8,9,1],[1,2,4,6],[0,1,2,3]])
m2=numpy.linalg.inv(m1)
m3=m2.round(2)
m4=m3*m1
m4.round(2)
3/39:
m1=numpy.matrix([[2,3,4,5],[7,8,9,1],[1,2,4,6],[0,1,2,3]])
m2=numpy.linalg.inv(m1)
m3=m2.round(2)
m4=m3*m1
m4.astype('int')
3/40: m4.round()
3/41: import pemdas
3/42: import pamdas
3/43: import pandas
3/44: df=pandas.read_csv(r'"C:\Users\SARTHAK\Downloads\datawh.csv")
3/45: df=pandas.read_csv(r"C:\Users\SARTHAK\Downloads\datawh.csv")
3/46: df.head()
3/47: df.shape
3/48: df.['Temperature']
3/49: df['Temperature']
3/50:
cols=["Temperature","Humidity"]
df[cols]
3/51: df["dates"]
3/52: df["Dates"]
3/53: df["Dates"][df['Humidity']>400]
3/54: df['dates'][df['pressure']>3][df['air quality']>1]
3/55: df['Dates'][df['Pressure']>3][df['Air Quality']>1]
3/56: df['Dates'][(df['Pressure']>3)&(df['Air Quality']>1)]
3/57: df['Dates'][(df['Pressure']>3) | (df['Air Quality']>1)]
3/58: df.describe()
3/59: df['mean'].mean()
3/60: df['Humidity'].mean()
3/61: df['Temperature'].std()
3/62: df=pandas.read_csv(r"C:\Users\SARTHAK\Downloads\datanh.csv")
3/63: df.columns=['Temp','Humidity','pressure','airqua']
3/64: df=pandas.read_html(r"https://coinmarketcap.com/currencies/bitcoin/historical-data/")
3/65: len(df)
3/66:
df1=df[0]
df2=df[1]
3/67: df1.to_csv('bitcoin.csv')
3/68:
import numpy
import matplotlib.pyplot as plt
x=numpy.arange(1,10,0.5)
y=numpy.sin(x)
plt.plot(x,y)
plt.show()
3/69:
plt.figure(fligsize=(12,5))
plt.plot(x,y,c='r')
3/70:
x=numpy.arange(1,10,0.5)
y=numpy.sin(x)
plt.figure(fligsize=(12,5))
plt.plot(x,y,c='r')
plt.show()
3/71:
x=numpy.arange(1,10,0.5)
y=numpy.sin(x)
plt.figure(figsize=(12,5))
plt.plot(x,y,c='r')
plt.show()
3/72:
plt.figure(figsize=(12,5))
plt.scatter(x,y,c='r')
plt.show()
3/73:
plt.figure(figsize=(12,5))
plt.scatter(x,y,c='b')
plt.show()
3/74:
plt.figure(figsize=(12,5))
plt.scatter(x,y,c='g')
plt.show()
3/75:
lbs=['DEL','BLR','BOM','MAA']
vals=[45,23,56,78]
plt.pie(vals,labels=lbs)
plt.show()
3/76:
import numpy
import pandas
import matplotlib.pyplot as plt
import seaborn as sns

df=pandas.read(r"C:\Users\SARTHAK\Downloads\Bank_churn_modelling.csv")
3/77:
import numpy
import pandas
import matplotlib.pyplot as plt
import seaborn as sns

df=pandas.read_csv(r"C:\Users\SARTHAK\Downloads\Bank_churn_modelling.csv")
3/78: df.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)
3/79:
plt.figure(figsize=(12,5))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['Creditscore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/80:
plt.figure(figsize=(12,5))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['Creditscore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/81:
plt.figure(figsize=(12,5))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['CreditScore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/82:
plt.figure(figsize=(20,5))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['CreditScore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/83:
plt.figure(figsize=(20,20))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['CreditScore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/84:
plt.figure(figsize=(15,20))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['CreditScore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/85:
plt.figure(figsize=(15,5))
sns.distplot(df['CreditScore'][df['Exited']==0])
sns.distplot(df['CreditScore'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/86:
plt.figure(figsize=(15,5))
sns.distplot(df['Age'][df['Exited']==0])
sns.distplot(df['Age'][df['Exited']==1])
plt.legend(['0','1'])
plt.show()
3/87:
plt.figure(figsize=(6,4))
sns.countplot(df['Geography']#for  categorical data
plt.show()
3/88:
plt.figure(figsize=(6,4))
sns.countplot(df['Geography'])#for  categorical data
plt.show()
3/89:
plt.figure(figsize=(6,4))
sns.countplot(df['Geography'])
plt.show()
plt.figure(figsize=(6,4))
sns.countplot(df['Geography'][df['Exited'==1])#for  categorical data
plt.show()
3/90:
plt.figure(figsize=(6,4))
sns.countplot(df['Geography'])
plt.show()
plt.figure(figsize=(6,4))
sns.countplot(df['Geography'][df['Exited']==1])#for  categorical data
plt.show()
3/91:
plt.figure(figsize=(6,4))
sns.countplot(df['Gender'])
plt.show()
plt.figure(figsize=(6,4))
sns.countplot(df['Gender'][df['Exited']==1])#for  categorical data
plt.show()
3/92:
plt.figure(figsize=(6,4))
sns.countplot(df['HasCrCard'])
plt.show()
plt.figure(figsize=(6,4))
sns.countplot(df['HasCrCard'][df['Exited']==1])#for  categorical data
plt.show()
3/93:
plt.figure(figsize=(6,4))
sns.swarmplot(x='Geography',y='Age',hue='Exited',data=df)
plt.show()
 4/1: import sys
 4/2:
for p in sys.path:
    print p
 4/3:
for p in sys.path:
    print (p)
 5/1: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/2: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/3: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/4: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/5: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/6: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/7: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/8: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 5/9: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
5/10: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
5/11: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
5/12: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
5/13: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
5/14: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/1: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/2: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/3: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/4: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/5: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/6: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/7: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/8: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 6/9: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
6/10: runcell(0, 'C:/Users/SARTHAK/.spyder-py3/temp.py')
 7/1: %reset
 7/2: dir()
 7/3: 5+6
 7/4: 5+6
 7/5: import matplotlib as plt
 7/6: plt.plot(range(10), 'o')
 7/7: import matplotlib.pyplot as plt
 7/8: plt.plot(range(10), 'o')
 7/9: import pandas as pd
7/10: covid_world = pd.read_excel('C:\Users\SARTHAK\Downloads\COVID-19-geographic-disbtribution-worldwide')
7/11: covid_world = pd.read_excel('COVID-19-geographic-disbtribution-worldwide')
7/12: covid_world = pd.read_excel('COVID-19-geographic-disbtribution-worldwide')
7/13: covid_world = pd.read_excel('COVID-19-geographic-disbtribution-worldwide.xlsx')
7/14: %reset()
7/15: %reset
7/16: pd.read_excel('COVID-19-geographic-disbtribution-worldwide.xlsx')
7/17: df = pd.read_excel('COVID-19-geographic-disbtribution-worldwide.xlsx')
7/18: df.head()
7/19: print(df)
7/20: df.columns()
7/21: columns(df)
7/22: df.mean()
 8/1: import numpy as np
 8/2: x = np.array([1,2,3,4,5])
 8/3: type(x)
 8/4: x.ndim()
 8/5: x.ndim
 8/6: x[0]
 8/7: d=x[3]
 8/8: d
 8/9: z=2x
8/10: z=2*x
8/11: u = np.array([1,2,3])
8/12: v= np.array([3,4,6])
8/13: z=u*v
8/14: z=np.dot(u,v)
8/15: np.linspace(-np.pi,np.pi,1000)
8/16: x=np.linspace(-np.pi,np.pi,1000)
8/17: y=np.sin(x)
8/18: import matplotlib as plt
8/19: plt.plot(x,y)
8/20: import matplotlib.pyplot as plt
8/21: plt.plot(x,y)
8/22: int(3.2)
8/23: A='1234567'
8/24: A[1::2]
8/25: B = '44'
8/26: A+B
8/27: tuple1=("A","B","C" )
8/28: tuple1[-1]
8/29: A=((11,12),[21,22])
8/30: A[1]
8/31: '1,2,3,4'.split(',')
8/32: V={'A','B'}
8/33: V.add('C')
8/34: V
8/35:
A=['1','2','3']


for a in A:

print(2*a)
8/36: A=['1','2']
8/37:
for a in A : 
    print(2*a)
 9/1: from matplotlib.backends.backend_agg import FigureCanvasAgg as Figure
 9/2: from matplotlib.figure import Figure
 9/3: fig = Figure()
 9/4: canvas = Figure(fig)
 9/5: from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
 9/6: from matplotlib.figure import Figure
 9/7: canvas = Figure(fig)
 9/8: from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
 9/9: from matplotlib.figure import Figure
9/10: fig = Figure()
9/11: canvas = FigureCanvas(fig)
9/12: import numpy as np
9/13: x = np.random.randn(1000)
9/14: ax = fig.add_subplot(111)
9/15: ax.hist(x,100)
9/16: ax.set_title('Normal Distribution')
9/17: fig.savefig('matplotlibhistogram.png")
9/18: fig.savefig('matplotlibhistogram.png')
9/19: ax.hist(x,100)
9/20: ax
10/1: import matplotlib.pyplot as plt
10/2: import numpy as np
10/3: x = np.random.randn(10000)
10/4: plt.hist(x,100)
10/5: plt.title(r'Random Distribution')
10/6: plt.show()
11/1: import numpy as np
11/2: import pandas as pf
11/3: import pandas as pd
11/4: from ___future___ impott print_function
11/5: from ___future___ import print_function
11/6: from __future__ import print_function
11/7: !pip install xlrd
12/1: import numpy as np
12/2: import pandas as pd
12/3: from __future__ import print_function
12/4: !pip install xlrd
12/5: df_can = pd.read_excel('C:\Users\SARTHAK\Downloads\Canada.xlsx', sheetname = 'Canada by Citizenship',skiprows = range(20), skipfooter=2)
12/6: df_can = pd.read_excel('C:\Users\SARTHAK\Downloads\Canada.xlsx', sheetname = 'Canada by Citizenship', skiprows = range(20), skipfooter=2)
12/7: df_can = pd.read_excel('C:\Users\SARTHAK\Downloads\Canada.xlsx', sheetname = 'Canada by Citizenship', skipfooter=2)
12/8: df_can = pd.read_excel('C:\Users\SARTHAK\Downloads\Canada.xlsx', sheetname = 'Canada by Citizenship')
12/9: df_can = pd.read_excel('C:\Users\SARTHAK\Downloads\Canada.xlsx')
12/10: df_can = pd.read_excel('C:/Users/SARTHAK/Downloads/UN_MigFlow_All_CountryFiles.zip/Canada.xlsx')
12/11: df_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx')
12/12: df_can = pd.read_excel('Canada.xlsx')
12/13: df_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx')
12/14: df_can.head()
12/15: df_can.show()
12/16: df_can
12/17: df_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', sheetname = 'Canada by Citizenship', skiprows = range(20), skip_footer = 2)
12/18: df_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20), skip_footer = 2)
12/19: df_can.head()
12/20: df_can.shape()
12/21: df_can.columns()
12/22: df_can.columns
12/23: df_can.shape
12/24: import matplotlib.pyplot as plt
12/25: df_can.groupby('AreaName").2013.hist()
12/26: df_can.groupby('AreaName').2013.hist()
12/27: df_can.groupby('AreaName')
12/28: df_can.plot("AreaName","2013")
12/29: df_can.plot("AreaName",2013)
12/30: df_can.plot("AreaName",2013, kind = scatter)
12/31: df_can.plot("AreaName",1996 kind = scatter)
12/32: df_can.plot("AreaName",1996)
12/33: df_can.plot("RegionName",1996)
12/34: df_can.plot("RegName",1996)
12/35: df_canada = df.set_index('OdName')
12/36: df_canada = df_can.set_index('OdName')
12/37: df_canada = df_can.set_index('RegName')
12/38: df_canada['Total'] = df_canada.iloc[:,8:42].sum(axes=1)
12/39: df_canada['Total'] = df_canada.iloc[:,8:42].sum(axis=1)
12/40: df_canada.head()
12/41: df_canada['Total'] = df_canada.iloc[:,5:39].sum(axis=1)
12/42: years = list(map(str,range(1980,2014)))
12/43: import matplotlib as mpl
12/44: import matplotlib.pyplot as plt
12/45: df_canada.loc('Central America', years).plot(kind='line)
12/46: df_canada.loc('Central America', years).plot(kind='line')
12/47: df_canada.loc['Central America', years].plot(kind='line')
14/1: print('Finally!')
14/2:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd
14/3:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd.read_excel('C:\Users\SARTHAK\Downloads\Canada.xlsx')
14/4:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

cpd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx')
14/5:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx')
14/6:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx')
pd_can.head()
14/7:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprow = range(20))
pd_can.head()
14/8:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprow = range(20))
pd_can.head()
14/9:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprow = range(20))
14/10:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprow = range(20))
pd_can.head()
14/11:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.head()
14/12:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName')
14/13:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total'].iloc[:,4:37].sum()
14/14:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,4:37].sum()
14/15:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,4:37].sum()
pd_can.head()
14/16:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum()
pd_can.head()
14/17:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum()
pd_can.head()
14/18:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axes=1)
pd_can.head()
14/19:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.head()
14/20:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
14/21:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
pd_can.head()
14/22:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
pd_can.head()
14/23:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
pd_can.head()
14/24:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
pd_can.head()
14/25:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
pd_can.head()
14/26:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName') 
pd_can['Total']=pd_can.iloc[:,5:38].sum(axis=1)
pd_can.fillna(0)
pd_can.head()
14/27:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
pd_can.set_index('RegName')
14/28:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canad = pd_can.set_index('RegName')
14/29:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName')
14/30:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=pd_can.iloc[:,5:38].sum(axis=1)
canada.fillna(0)
canada.head()
14/31:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=pd_can.iloc[:,4:37].sum(axis=1)
canada.fillna(0)
canada.head()
14/32:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=pd_can.iloc[:,4:37].sum(axis=1)
14/33:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=pd_can.iloc[:,4:37].sum(axis=1)
canada.head()
14/34:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada.head()
14/35:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada.fillna(0)
canada.head()
14/36:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
14/37:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'])
14/38:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'], Ascending = False)
14/39:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'], ascending = False)
14/40:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'], ascending = False, axis = 0)
14/41:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
14/42:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
14/43:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
14/44:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
df_canada = canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
14/45:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed.head()
df_canada = canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
df_canada.head()
14/46:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
canada_processed.head()
14/47:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2013)))
14/48:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2013)))
df_top5 = canada_processed.head()
14/49:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2013)))
df_top5 = canada_processed.head()
df_top5 = df_top5['years'].transpose()
14/50:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2013)))
df_top5 = canada_processed.head()
df_top5 = df_top5[years].transpose()
14/51:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2013)))
df_top5 = canada_processed.head()
14/52:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2013)))
df_top5 = canada_processed.head()
df_top5
14/53:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
df_top5 = canada_processed.head()
df_top5 = df_top5[years].transpose()
14/54:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
df_top5 = canada_processed.head()
df_top5 = df_top5[years]
14/55:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
df_top5 = canada_processed.head()
df_top5 = df_top5[int(years)]
14/56:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
for i in years : 
    i = int(i)
14/57:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
for i in years : 
    i = int(i)
df_top5 = canada_processed.head()
df_top5 = df_top5[years]
14/58:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
year.append(i)
14/59:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
year.append(i)
df_top5 = canada_processed.head()
df_top5 = df_top5[year]
14/60:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
year.append(i)
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
14/61:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
year.append(i)
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5
14/62:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
year.append(i)
year
14/63:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
    i=i+1
year.append(i)
year
14/64:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
year = []
for i in years : 
    i = int(i)
year.append(i)
i=i+1
year
14/65:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = []
for i in years : 
    i = int(i)
year.append(i)
i=i+1
year
14/66:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
14/67:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
14/68:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
14/69:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5
14/70:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5['year'].transpose()
14/71:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
14/72:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5
14/73:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plot(kind='area')
14/74:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plot(kind='area')
14/75:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plot()
14/76:
import numpy as np 

import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
import matplotlib as mlt 
import matplotlib.pyplot as plt 
df_top5.plot()
14/77:
import numpy as np 

import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
import matplotlib as mlt 
import matplotlib.pyplot as plt 
df_top5.plot()
plt.show()
14/78:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()

df_top5.plot()
plt.show()
14/79:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
14/80:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plot()
14/81:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5
14/82:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plot(kind='area')
14/83:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plt(kind='area')
14/84:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.pl0t(kind='area')
14/85:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.plot(kind='area')
14/86:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
14/87:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5.plot(kind='area')
16/1:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
16/2:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
16/3:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed['2013'].plot(kind='hist')
16/4:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed[2013].plot(kind='hist')
16/5:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed[2012].plot(kind='hist')
16/6:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed[2012].plot(kind='hist')
plt.title('Canada Immigration')
plt.xlable('No. of countries')
plt.ylable('Number of Immigrants')
plt.show()
16/7:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed[2012].plot(kind='hist')
plt.title('Canada Immigration')
plt.xlabel('No. of countries')
plt.ylabel('Number of Immigrants')
plt.show()
16/8:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed[2012].plot(kind='hist')
plt.title('Canada Immigration')
plt.xlabel('No. of areas')
plt.ylabel('Number of Immigrants')
plt.show()
16/9:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
canada_processed[2012].plot(kind='hist')
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
plt.show()
16/10:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
plt.show()
16/11:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
plt.show()
df_iceland = canada_processed[year]
16/12:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
df_iceland = canada_processed[year]
df_iceland
16/13:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
df_iceland = canada_processed.loc[year,'Northern Europe']
df_iceland
16/14:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
df_iceland = canada_processed.loc[year]
df_iceland
16/15:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
df_iceland = canada_processed[year]
df_iceland
16/16:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland
16/17:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)
plt.title('Canada Immigration')
plt.xlabel('No. of immigrants')
plt.ylabel('Number of Regions')
df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
16/18:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')
plt.show()
16/19:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')
plt.show()
16/20:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mpl.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')
plt.show()
16/21:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')
plt.show()
16/22:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy = (12,70), xytext = (14,20), xycoords = 'data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)
plt.show()
16/23:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy = (12,70), xytext = (14,20), xycoords = 'data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)
plt.show()
16/24:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy = (12,70), xytext = (14,20), xycoords = 'data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)
16/25:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy = (12,70), xytext = (14,20), xycoords = 'data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)
16/26:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy = (12,70), xytext = (14,20), xycoords = 'data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)
16/27:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(32, 70), xytext=(28, 20), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/28:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(12, 70), xytext=(14, 20), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/29:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(14, 70), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/30:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(14, 70), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/31:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(14, 100), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/32:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(14, 100), xytext=(12, 100), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/33:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(14, 1000), xytext=(12, 1000), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/34:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('', xy=(14, 20), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/35:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('I am not sure', xy=(14, 20), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/36:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('I am not sure', xy=(14, 20), xytext=(12, 20), xycoords='data', rotation = 75, va = 'bottom', ha = 'left', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.show()
16/37:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate(xy=(14, 20), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.annonate('I am not sure', xy = (12,10), rotation = 75, va='bottom',ha='left')
plt.show()
16/38:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 20), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.annonate('I am not sure', xy = (12,10), rotation = 75, va='bottom',ha='left')
plt.show()
16/39:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 20), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,10), rotation = 75, va='bottom',ha='left')
plt.show()
16/40:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 20), xytext=(12, 20), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,10), rotation = 90, va='bottom',ha='left')
plt.show()
16/41:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 35000), xytext=(12, 40000), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,10), rotation = 90, va='bottom',ha='left')
plt.show()
16/42:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='<->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,10), rotation = 90, va='bottom',ha='left')
plt.show()
16/43:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,10), rotation = 90, va='bottom',ha='left')
plt.show()
16/44:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,36000), rotation = 75, va='bottom',ha='left')
plt.show()
16/45:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,36000), rotation = 50, va='bottom',ha='left')
plt.show()
16/46:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,35000), rotation = 50, va='bottom',ha='left')
plt.show()
16/47:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,40000), rotation = 50, va='bottom',ha='left')
plt.show()
16/48:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.sort_values(['Total'], ascending = False, axis = 0, inplace = True)
years = list(map(str, range(1980,2014)))
years
year = [int(i) for i in years]
year
df_top5 = canada_processed.head()
df_top5 = df_top5[year].transpose()
df_top5.fillna(0)
df_top5
canada_processed.head()
count, bin_edges = np.histogram(canada_processed[2012])
canada_processed[2012].plot(kind='hist', xticks = bin_edges)

df_iceland = canada_processed.loc['Northern Europe', year]
df_iceland.plot(kind='bar')
plt.title('Iceland to Canada Immigration')
plt.xlabel('Year')
plt.ylabel('Number of Immigrants')

plt.annotate('',xy=(14, 40000), xytext=(12, 35000), xycoords='data', arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))
plt.annotate('I am not sure', xy = (12,36000), rotation = 50, va='bottom',ha='left')
plt.show()
17/1:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np
17/2:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_csv('C:\Users\SARTHAK\Downloads\Assam Floods.xlsx')
17/3:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_csv('C:/Users/SARTHAK/Downloads/Assam Floods.xlsx')
17/4:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
17/5:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data
17/6:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name')
17/7:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/8:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar', fig=(10,20))
17/9:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar', fig=(200,20))
17/10:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar', fig=(200,200))
17/11:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [100, 5]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/12:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [100, 100]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/13:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [100, 50]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/14:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [50, 50]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/15:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [25, 25]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/16:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [10, 10]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name').plot(kind='bar')
17/17:
import pandas as pd 
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
plt.rcParams['figure.figsize'] = [10, 10]

Assam_data = pd.read_excel('C:/Users/SARTHAK/Documents/Assam Floods.xlsx')
Assam_data.set_index('Area Name')
18/1:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.head()
18/2:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.group_by('AreaName', axis=0).sum()
18/3:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed.groupby('AreaName', axis=0).sum()
18/4:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
18/5:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada.plot('Total', kind='pie')
18/6:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada['Total'].plot( kind='pie')
18/7:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [10, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada['Total'].plot( kind='pie', fig=(40,100))
18/8:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 5]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada['Total'].plot( kind='pie')
18/9:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada['Total'].plot( kind='pie')
18/10:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada
18/11:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)
canada_processed

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada
18/12:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
df_canada
18/13:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
18/14:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada.drop([unnecessary])
18/15:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada.drop([unnecessary], axis = 0)
18/16:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada.drop(unnecessary, axis = 0)
18/17:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)
18/18:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)
df_canada['Total'].plot(kind='area')
18/19:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)
df_canada['Total'].plot(kind='pie')
18/20:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)
df_canada1['Total'].plot(kind='pie')
18/21:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)

canada_processed 
df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)
18/22:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

canada_processed
18/23:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
canada_processed 
df_middleafrica = canada_processed.loc(['Middle Africa'], year)
df_middleafrica
18/24:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc(['Middle Africa'], year)
df_middleafrica
18/25:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc([Middle Africa], year)
df_middleafrica
18/26:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year]
df_middleafrica
18/27:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year]
df_middleafrica.plot(kind='box')
18/28:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()
df_middleafrica.plot(kind='box')
18/29:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'.plot(kind='pie', autopct='%1.1f%%', startangle = 90)
18/30:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90)
18/31:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, explode = [0.1,0,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/32:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, explode = [0.1,0,0,0,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/33:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, explode = [0.1,0,0,0,0,0.1])
plt.legend(labels= df_canada1.index, loc='upper left')
18/34:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12)
plt.legend(labels= df_canada1.index, loc='upper left')
18/35:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, labels = None)
plt.legend(labels= df_canada1.index, loc='upper left')
18/36:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, labels = None, explode = [0.1,0,0,0.1,0,0.1,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/37:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, labels = None, explode = [0,0,0,0.1,0.1,0,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/38:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, labels = None, explode = [0,0,0.1,0.1,0,0,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/39:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, labels = None, explode = [0,0,0,0.1,0.1,0.1,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/40:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_canada1['Total'].plot(kind='pie', autopct='%1.1f%%', startangle = 90, pctdistance=1.12, labels = None, explode = [0,0,0,0,0.1,0.1,0])
plt.legend(labels= df_canada1.index, loc='upper left')
18/41:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_tot = pd.DataFrame(df_can[years].sum(axis=0))
df_tot.index = map(int, df_tot.index)
df_tot.reset_index(inplace = True)
df_tot.columns = ['year', 'total']
18/42:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()


df_tot = pd.DataFrame(canada_processed[years].sum(axis=0))
df_tot.index = map(int, df_tot.index)
df_tot.reset_index(inplace = True)
df_tot.columns = ['year', 'total']
18/43:
import numpy as np 
import matplotlib as mlt 
import matplotlib.pyplot as plt 
import pandas as pd 
plt.rcParams['figure.figsize'] = [20, 20]
mlt.style.use('ggplot')

pd_can = pd.read_excel('C:/Users/SARTHAK/Downloads/Canada.xlsx', skiprows = range(20))
canada = pd_can.set_index('RegName') 
canada['Total']=canada.iloc[:,4:37].sum(axis=1)
canada_processed = canada.fillna(0)


df_canada = canada_processed.groupby('AreaName', axis=0).sum()
unnecessary = ['Africa Total', 'Asia Total', 'Europe Total','Latin America and the Caribbean Total', 'Oceania Total']
df_canada1=df_canada.drop(unnecessary, axis = 0)

years = list(map(str,range(1980,2014)))
year = [int(year) for year in years]
 
df_middleafrica = canada_processed.loc[['Middle Africa'], year].transpose()

canada_processed.index = map(int, canada_processed.index)
df_tot = pd.DataFrame(canada_processed[years].sum(axis=0))
df_tot.index = map(int, df_tot.index)
df_tot.reset_index(inplace = True)
df_tot.columns = ['year', 'total']
18/44: import Seaborn as sns
18/45: import seaborn as sns
18/46: world_map = folium.Map()
18/47:
!conda install -c conda-forge folium=0.5.0 --yes
import folium

print('Folium installed and imported!')
19/1:
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import Seaborn as sns 
import pandas as pd
19/2:
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import seaborn as sns 
import pandas as pd
19/3:
import matplotlib as mpl 
import matplotlib.pyplot as plt 
import seaborn as sns 
import pandas as pd 
fifa_filepath = "../input/fifa.csv"
# Read the file into a variable fifa_data
fifa_data = pd.read_csv(fifa_filepath, index_col="Date", parse_dates=True)
20/1:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt
20/2:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv ')
20/3:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv ')
20/4:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv ')
fifa_data
20/5:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv ')
fifa_data.set_index('Date')
20/6:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv ', parse_dates=True)
fifa_data.set_index('Date')
20/7:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv ', parse_dates=True)
fifa_data.set_index('Date')
sns.lineplot(data=fifa_data)
20/8:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv')
fifa_data.set_index('Date')
sns.lineplot(data=fifa_data)
20/9:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv')
fifa_data.set_index('Date')
20/10:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
20/11:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
sns.lineplot(data=fifa_data)
20/12:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
pd.index.astype(int64)
sns.lineplot(data=fifa_data)
20/13:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
index.astype(int64)
sns.lineplot(data=fifa_data)
20/14:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
pd.date.astype(int64)
sns.lineplot(data=fifa_data)
20/15:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
pd.Index.astype(int64)
sns.lineplot(data=fifa_data)
20/16:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
pd.Index.astype('int64')
sns.lineplot(data=fifa_data)
20/17:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
pd.Index.astype(dtype='int64')
sns.lineplot(data=fifa_data)
20/18:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
sns.lineplot(data=fifa_data)
20/19:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
fifa_data['Dates'].astype(int)
sns.lineplot(data=fifa_data)
20/20:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
fifa_data['Date'].astype(int)
sns.lineplot(data=fifa_data)
20/21:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
fifa_data['Date'].astype(int64)
sns.lineplot(data=fifa_data)
20/22:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
fifa_data['Date'].astype(float)
sns.lineplot(data=fifa_data)
20/23:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
fifa_data['Date'].astype(int)
sns.lineplot(data=fifa_data)
20/24:
import pandas as pd 
import matplotlib as mpl 
import seaborn as sns 
import matplotlib.pyplot as plt 
fifa_data = pd.read_csv('C:/Users/SARTHAK/Downloads/fifa.csv',parse_dates = True)
fifa_data.set_index('Date')
fifa_data['Date'].astype('int')
sns.lineplot(data=fifa_data)
23/1:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
23/2:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores
23/3:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
23/4:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
scores
23/5:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = Scores['Percentage']
23/6:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
23/7:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
Data
23/8:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=85; 
    print i
23/9:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=85, 
    print i
23/10:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=85 :
    print i
23/11:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=85 :
    print(i)
23/12:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=85 :
        print(i)
23/13:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=70 and i<85 :
        print(i)
23/14:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i>=60 and i<70 :
        print(i)
23/15:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
Data = scores['Percentage']
for i in Data : 
    if i<60 :
        print(i)
23/16:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
scores
23/17:
import pandas as pd 
scores = pd.read_excel(r"C:\Users\SARTHAK\Downloads\Scores-converted.xlsx")
scores['Percentage']=scores.apply(lambda row : (row.Total)/3, axis =1)
scores 

x= 567 + 354 + 276 + 340
x
24/1:
import pandas as pd
data = pd.read_excel("'C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx'")
data
24/2:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx')
data
24/3:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data
24/4:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
24/5:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.describe()
24/6:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
24/7:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data1 = data.groupby('Country')
data1
24/8:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data1 = data.groupby('Country')
data1.head()
24/9:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data1 = data.groupby('Traffic_Rank')
data1.head()
24/10:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data1 = data.groupby('Website')
24/11:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data1 = data.groupby('Website')
data1
24/12:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data1 = data.groupby('Website')
data1.head()
24/13:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Website')
data1_change.head()
24/14:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Website')
data_change.head()
24/15:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Website')
24/16:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby(['Website']).description.count()
24/17:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Country.count()
24/18:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
24/19:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Traffic_Rank.count()
24/20:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Traffic_Rank.count()
data_change.head()
24/21:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Traffic_Rank.count()
data_change
24/22:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Traffic_Rank.max()
data_change
24/23:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Country']).Traffic_Rank.max()
data_change
24/24:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Traffic_Rank.max()
data_change
24/25:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Website']).Traffic_Rank.min()
data_change
24/26:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
24/27:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Country']).Traffic_Rank.min()
data_change
24/28:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Country']).Traffic_Rank.count()
data_change
24/29:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Country')['Traffic_Rank'].max()
data_change
24/30:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Country','Traffic_Rank']).max()
data_change
24/31:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby(['Country','Traffic_Rank']).max()
data_change
24/32:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Countries')
data_change.get_group('India')
24/33:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Country')
data_change.get_group('India')
24/34:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Country')
India = data_change.get_group('India')
24/35:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/36:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Country')
India = data_change.get_group('India')
Check = data.groupby('Country')['Traffic_Rank'].max()
Check
24/37:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data_change = data.groupby('Country')
India = data_change.get_group('India')
Check = data.groupby('Country')['Traffic_Rank'].mean()
Check
24/38:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data['Traffic_Rank']=data['Traffic_Rank'].astype(int)
data_change = data.groupby('Country')
India = data_change.get_group('India')
Check = data.groupby('Country')['Traffic_Rank'].mean()
Check
24/39:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data['Traffic_Rank']=data['Traffic_Rank'].astype(int)
24/40:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data['Traffic_Rank']= pd.to_numeric(data['Traffic_Rank'])
24/41:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data.describe()
24/42:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data.dtypes()
24/43:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
print(data.dtypes)
24/44:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data['Traffic_Rank'] = data['Traffic_Rank'].astype(int64)
data_change = data.groupby('Country')
India = data_change.get_group('India')
Check = data.groupby('Country')['Traffic_Rank'].mean()
Check
24/45:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data['Traffic_Rank'] = data['Traffic_Rank'].astype(int)
data_change = data.groupby('Country')
India = data_change.get_group('India')
Check = data.groupby('Country')['Traffic_Rank'].mean()
Check
24/46:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data.head()
data['Traffic_Rank'] = pd.to_numeric(data['Traffic_Rank'])
data_change = data.groupby('Country')
India = data_change.get_group('India')
Check = data.groupby('Country')['Traffic_Rank'].mean()
Check
24/47:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Traffic_Rank')
India = data_change.get_group('1')
India
24/48:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Traffic_Rank')
India = data_change.get_group(1)
India
24/49:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Traffic_Rank')
India = data_change.get_group(1)
India.describe()
24/50:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Traffic_Rank')
India = data_change.get_group(1)
India
24/51:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Traffic_Rank')
India = data_change.get_group(1)
India.Website.unique()
24/52:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
24/53:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/54:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.sort_values(by=['Avg_Daily_Visitors'])
24/55:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.sort_values(by=['Avg_Daily_Visitors'], ascending = False)
24/56:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.sort_values(by=['Avg_Daily_Pageviews'], ascending = False)
24/57:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Avg_Daily_Visitors']= India['Avg_Daily_Visitors'].astype(str).astype(int)
India.sort_values(by=['Avg_Daily_Pageviews'], ascending = False)
24/58:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Avg_Daily_Visitors']= India['Avg_Daily_Visitors'].astype(str).astype('int64')
India.sort_values(by=['Avg_Daily_Pageviews'], ascending = False)
24/59:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Avg_Daily_Visitors']= India['Avg_Daily_Visitors'].astype('float').astype('int64')
India.sort_values(by=['Avg_Daily_Pageviews'], ascending = False)
24/60:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.sort_values(by=['Avg_Daily_Pageviews'], ascending = False)
24/61:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment.xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/62:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment(1)(1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/63:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/64:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.sort_values(by=['Avg_Daily_Visitors'])
24/65:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.sort_values(by=['Avg_Daily_Visitors'], ascending = False)
24/66:
import pandas as pd
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/67:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Regression = sns.regplot(x='Country_Rank', y='Avg_Daily_Visitors', data=India)
24/68:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/69:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Test = sns.regplot(x='Country_Rank', y='Facebook_Likes', data=India)
24/70:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Test = sns.regplot(x='Country_Rank', y='Facebook_Like', data='India')
24/71:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
24/72:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Test = sns.regplot(x='Country_Rank', y='Facebook_Likes', data = India)
24/73:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Test = sns.regplot(x='Country_Rank', y='Facebook_likes', data = India)
24/74:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India
29/1:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India.Facebook_likes = (India.Facebook_likes.replace(r'[KM]+$', '', regex=True).astype(float) * \ India.Facebook_likes.str.extract(r'[\d\.]+([KM]+)', expand = False).fillna(1).replace(['K','M'],[10**3,10**6]).astype(int))
29/2:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes'].replace({'K' : '*1e^3'}, regex = True).map(pd.eval).astype(int)
29/3:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes'].replace({'K' : '*1e3'}, regex = True).map(pd.eval).astype(int)
29/4:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6'}, regex = True).map(pd.eval).astype(int)
29/5:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
29/6:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
India
29/7:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes']=India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
29/8:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
India['Facebook_likes'] = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
29/9:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
29/10:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Facebook_likes
29/11:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
India
29/12:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pininterest_pins = India['Pininterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
29/13:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pininterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
29/14:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pininterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

Pininterest_pins
29/15:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pininterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

Pininterest_pins[2]
29/16:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pininterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India
29/17:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pininterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India 
India_copy = India.copy()
29/18:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India 
India_copy = India.copy()
India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
29/19:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India 
India_copy = India.copy()
India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes], axis=1)
29/20:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India 
India_copy = India.copy()
India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes], axis=1)
Test
29/21:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes], axis=1)
Test
29/22:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes], axis=1)
Test
29/23:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes, Twitter_mentions, LinkedIn_mentions, Pinterest_pins], axis=1)
29/24:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes, Twitter_mentions, LinkedIn_mentions, Pinterest_pins], axis=1)
Test
29/25:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses LinkedIn_mentions, Pinterest_pins], axis=1)
Test
29/26:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
Test = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
Test
29/27:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
print(dtypes.India_Final)
29/28:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
print(India_Final.dtypes)
29/29:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
India_Final
29/30:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins']
India_Final = India_Final.reindex(columns = Column_names)
29/31:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins']
India_Final = India_Final.reindex(columns = Column_names)
India_Final.head()
29/32:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final.head()
29/33:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final.head()
India.head()
29/34:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final.head()
India_copy.head()
29/35:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final.head()
29/36:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_copy.head()
29/37:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final.head()
29/38:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final
29/39:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final_regression = sns.regplot(x='Traffic_Rank', y= 'Avg_Daily_Visitors', data = India_Final)
29/40:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
ax = sns.regplot(x='Traffic_Rank', y= 'Avg_Daily_Visitors', data = India_Final)
29/41:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_1.corr(col_2)
print(corr)
29/42:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']
India_Final['Traffic_Rank'].astype(int)
India_Final = India_Final.reindex(columns = Column_names)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_1.corr(col_2)
print(corr)
29/43:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
India_Final = India_Final.reindex(columns = Column_names)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_1.corr(col_2)
print(corr)
29/44:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_1.corr(col_2)
print(corr)
29/45:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)
print(corr)
29/46:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

India_Final
29/47:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA
29/48:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')
29/49:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA
29/50:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

India_Final
29/51:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

India_Final
29/52:
import pandas as pd
import numpy as np 
import seaborn as sns 
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA
29/53:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA.plot(kind='Area')
29/54:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA.plot(kind='area')
29/55:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
29/56:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'])
29/57:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
29/58:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA['Country_Rank'].transpose()
29/59:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA['Country_Rank'].transpose()
DataA
29/60:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA[Country_Rank].transpose()
DataA
29/61:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)

DataA
29/62:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA[Country_Rank].transpose()
29/63:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA.transpose()
29/64:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA.transpose()
DataA
29/65:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA.transpose()
DataA.plot(kind=area)
29/66:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA = DataA.transpose()
DataA.plot(kind='area')
29/67:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA['Country_Rank']= DataA['Country_Rank'].astype(int)
DataA = DataA.transpose()
DataA.plot(kind='area')
29/68:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA['Country_Rank']= DataA['Country_Rank'].astype(int)

DataA.plot(kind='area')
29/69:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA['Country_Rank']= DataA['Country_Rank'].astype(int)

DataA
29/70:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA['Country_Rank']= DataA['Country_Rank'].astype(int)

print(dtypes.DataA)
29/71:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA['Country_Rank']= DataA['Country_Rank'].astype(int)

print(DataA.dtypes)
29/72:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)

DataA.transpose
29/73:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)

DataA.transpose()
29/74:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)

DataA.transpose()
29/75:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA
29/76:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataA
29/77:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
29/78:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
29/79:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB
29/80:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB
DataB.plot(kind='area')
29/81:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB
29/82:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB.set_index('Country_Rank')
29/83:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/84:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/85:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/86:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 100]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/87:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [200, 200]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/88:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [200, 100]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/89:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [100, 100]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/90:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [50, 50]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/91:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [50, 50]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/92:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [50, 50]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/93:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 50]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
29/94:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 50]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
plt.show()
29/95:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
plt.show()
29/96:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
plt.grid()
plt.show()
29/97:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
plt.xticks(np.arange(min(x), max(x)+1, 1.0))
plt.grid()
plt.show()
29/98:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
DataB.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/99:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
DataB.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/100:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/101:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Websites')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/102:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Website')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/103:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [20, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Country_Rank'], axis = 1)
DataB = DataB.set_index('Website')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/104:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Country_Rank'], axis = 1)
DataB = DataB.set_index('Website')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/105:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Country_Rank'], axis = 1)
DataB = DataB.set_index('Website')
DataB
29/106:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Website')
DataB
29/107:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Website')
DataB['Country_Rank']= DataB['Country_Rank'].astype(str)
29/108:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Website')
DataB['Country_Rank']= DataB['Country_Rank'].astype(str)
DataB
29/109:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Website')
DataB['Country_Rank']= DataB['Country_Rank'].astype(str)
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/110:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Website')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/111:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
plt.grid()
plt.show()
29/112:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,0) xycoords = 'data')
plt.grid()
plt.show()
29/113:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,0) xycoords = 'data', xytext=(0.8, 0.95), textcoords='axes fraction',
            arrowprops=dict(facecolor='black', shrink=0.05),
            horizontalalignment='right', verticalalignment='top',)
plt.grid()
plt.show()
29/114:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,0), xycoords = 'data', xytext=(0.8, 0.95), textcoords='axes fraction',
            arrowprops=dict(facecolor='black', shrink=0.05),
            horizontalalignment='right', verticalalignment='top',)
plt.grid()
plt.show()
29/115:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,0), xycoords = 'data', xytext=(0.8, 0.95), textcoords='axes fraction',
            horizontalalignment='right', verticalalignment='top',)
plt.grid()
plt.show()
29/116:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,0), xycoords = 'data', textcoords='axes fraction',
            horizontalalignment='right', verticalalignment='top')
plt.grid()
plt.show()
29/117:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,0), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.grid()
plt.show()
29/118:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-1), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.grid()
plt.show()
29/119:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-2), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.grid()
plt.show()
29/120:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-100), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.grid()
plt.show()
29/121:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.grid()
plt.show()
29/122:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.xticks(x,'')
plt.grid()
plt.show()
29/123:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
plt.xticks(Country_Rank,'')
plt.grid()
plt.show()
29/124:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.5,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/125:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/126:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [50, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/127:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [30, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/128:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [30, 20]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/129:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
plt.rcParams['figure.figsize'] = [30, 30]
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/130:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 8))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/131:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 6))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/132:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 4))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.show()
29/133:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 4))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.setylabel('Websites(Most Visited to Least Visited)')
plt.show()
29/134:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 4))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.sety_label('Websites(Most Visited to Least Visited)')
plt.show()
29/135:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 4))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
plt.set_ylabel('Websites(Most Visited to Least Visited)')
plt.show()
29/136:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 4))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_ylabel('Websites(Most Visited to Least Visited)')
plt.show()
29/137:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (14, 4))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/138:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (10,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/139:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
fig = plt.figure(figsize = (5,5))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/140:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib inline
fig = plt.figure(figsize = (5,5))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/141:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib inline
fig = plt.figure(figsize = (5,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/142:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib inline
fig = plt.figure(figsize = (10,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/143:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib inline
fig = plt.figure(figsize = (12,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/144:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib widget
fig = plt.figure(figsize = (12,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/145:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib notebook
fig = plt.figure(figsize = (12,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/146:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
%matplotlib inline
fig = plt.figure(figsize = (12,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/147:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (12,10))
data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/148:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,10))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/149:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()
DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()
29/150:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')
plt.show()

DataA_copy
29/151:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataA_copy
29/152:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'])
29/153:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
29/154:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC
29/155:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC.set_index('Country_Rank')
29/156:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
29/157:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
29/158:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')


DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.grid()
Graph1.set_xlabel('Websites(Most Visited to Least Visited)')
29/159:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')

#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.grid()
Graph1.set_xlabel('Websites(Most Visited to Least Visited)')

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataD
29/160:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')

#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.grid()
Graph1.set_xlabel('Websites(Most Visited to Least Visited)')

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD
29/161:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

fig = plt.figure(figsize = (20,20))

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')

#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.grid()
Graph1.set_xlabel('Websites(Most Visited to Least Visited)')

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/1:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()
Graph.set_xlabel('Websites(Most Visited to Least Visited)')

#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.grid()
Graph1.set_xlabel('Websites(Most Visited to Least Visited)')

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/2:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/3:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
Graph1.ylabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/4:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.ylabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/5:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/6:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/7:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/8:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/9:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')

India_Final
31/10:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
31/11:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')


India_Final
31/12:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')

g = sns.FacetGrid(df, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Country_Rank', 'Avg_Daily_Visitors')
g = g.map(plt.fill_between, 'Country_Rank', 'Avg_Daily_Visitors', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
 
plot.show()
31/13:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')

g = sns.FacetGrid(DataD, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Country_Rank', 'Avg_Daily_Visitors')
g = g.map(plt.fill_between, 'Country_Rank', 'Avg_Daily_Visitors', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
 
plot.show()
31/14:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Avg_Daily_Visitors')

g = sns.FacetGrid(DataD, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Country_Rank', 'Avg_Daily_Visitors')
g = g.map(plt.fill_between, 'Country_Rank', 'Avg_Daily_Visitors', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
 
plot.show()
31/15:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')

g = sns.FacetGrid(DataD, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Country_Rank', 'Facebook_likes')
g = g.map(plt.fill_between, 'Country_Rank', 'Facebook_likes', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
 
plot.show()
31/16:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')

g = sns.FacetGrid(DataD, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Country_Rank', 'Facebook_likes')
g = g.map(plt.fill_between, 'Country_Rank', 'Facebook_likes', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
 
plt.show()
31/17:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')

g = sns.FacetGrid(DataD, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Google_pluses', 'Facebook_likes')
g = g.map(plt.fill_between, 'Google_pluses', 'Facebook_likes', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
 
plt.show()
31/18:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
DataD 

g = sns.FacetGrid(DataD, col='Website', hue='Website', col_wrap=4, )
g = g.map(plt.plot, 'Google_pluses', 'Facebook_likes')
g = g.map(plt.fill_between, 'Google_pluses', 'Facebook_likes', alpha=0.2).set_titles("{col_name} Website")
g = g.set_titles("{col_name}")
plt.subplots_adjust(top=0.92)
g = g.fig.suptitle('Evolution of Avg Daily Visitors for top 10 visisted Websites')
31/19:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
DataD
31/20:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
sns.lineplot(data=DataD)
31/21:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Country_Rank')
DataD
31/22:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Website)
DataD
31/23:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD.set_index('Website')
DataD
31/24:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD = DataD.set_index('Website')
DataD
31/25:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
DataD
31/26:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
sns.lineplot(data = DataD)
31/27:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
print(DataD.dtypes)
31/28:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
print(DataD.dtypes)
31/29:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
sns.lineplot(data = DataD)
31/30:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data = DataD)
31/31:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
31/32:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
Graph3
31/33:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])

Graph3
31/34:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])

Graph3
31/35:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
Graph3.set_ylabel("")

Graph3
31/36:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
Graph3.set_xlabel("")

Graph3
31/37:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")

Graph3
31/38:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")

Graph3
31/39:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 
India_copy
31/40:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 
India_copy 
columnA = India_copy['Pinterest_pins']
columnB = India_copy['Country_Rank']
correlation = column1.corr(column_2)
correlation
31/41:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 
India_copy 
columnA = India_copy['Pinterest_pins']
columnB = India_copy['Country_Rank']
correlation = columnA.corr(columnB)
correlation
31/42:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 
India_copy 
India_copy['Country_Rank'] = India_copy['Country_Rank'].astype(int)
columnA = India_copy['Pinterest_pins']
columnB = India_copy['Country_Rank']
correlation = columnA.corr(columnB)
correlation
31/43:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_copy['Country_Rank'] = India_copy['Country_Rank'].astype(int)
columnA = India_copy['Pinterest_pins']
columnB = India_copy['Country_Rank']
correlation = columnA.corr(columnB)
correlation
31/44:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_copy['Country_Rank'] = India_copy['Country_Rank'].astype(int)
31/45:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 
India_copy
31/46:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final
31/47:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation
31/48:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/49:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 websites')
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/50:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 visited websites in India')
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/51:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/52:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/53:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/54:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/55:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter Mentions, Linkedin Mentions and Pinterest Pins for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/56:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1
31/57:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3


#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/58:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/59:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
Graph3.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4.show()
31/60:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar')
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/61:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/62:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
plt.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/63:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/64:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
Graph1.annotate('More visited site to less visited', xy=(6.28, 1), xytext=(10, 4),
            arrowprops=dict(facecolor='black', shrink=0.05)
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/65:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
Graph1.annotate('More visited site to less visited', xy=(6.28, 1), xytext=(10, 4),
            arrowprops=dict(facecolor='black', shrink=0.05)
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/66:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
Graph1.annotate('More visited site to less visited', xy=(6.28, 1), xytext=(10, 4),
            arrowprops=dict(facecolor='black', shrink=0.05)
Graph1.set_xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/67:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.annotate('www.google.co.in', xy= (0.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.youtube.com', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.google.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.facebook.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.yahoo.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.amazon.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.wikipedia.org', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.flipkart.com', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.onlinesbi.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.annotate('www.irctc.co.in', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph1.axes.get_xaxis().set_ticks([])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/68:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
loc = plticker.MultipleLocator(base=1.0)
Graph1.xaxis.set_major_locator(loc)
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/69:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])

Graph1.xaxis.set_major_locator(loc)
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/70:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])

Graph1.xaxis.set_major_locator(loc)
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/71:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/72:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 10]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("")
plt.grid()
plt.show()


#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/73:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 10]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/74:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Average Daily Visitors and Average Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/75:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)
Graph4.xaxis.set_major_locator(loc)
Graph4.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph4.axes.get_xaxis().set_ticks([])
plt.grid()
Graph4.set_xlabel("")
Graph4
31/76:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)

plt.grid()
Graph4.set_xlabel("Trends in Pinterest Pins")
Graph4
31/77:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
Graph4 = sns.lineplot(data=DataE)

plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4
31/78:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 5]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)

plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4
31/79:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 3]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/80:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India')
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/81:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 20)
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
loc = plticker.MultipleLocator(base=1.0)
Graph3.xaxis.set_major_locator(loc)
Graph3.annotate('www.google.co.in', xy= (1.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.youtube.com', xy= (2.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.google.com', xy= (3.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.facebook.com', xy= (4.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.yahoo.com', xy= (5.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.amazon.com', xy= (6.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.wikipedia.org', xy= (7.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.flipkart.com', xy= (8.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.onlinesbi.com', xy= (9.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.annotate('www.irctc.co.in', xy= (10.4,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph3.axes.get_xaxis().set_ticks([])
plt.grid()
Graph3.set_xlabel("")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/82:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 20)
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/83:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [20, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')
loc = plticker.MultipleLocator(base=1.0)
Graph.xaxis.set_major_locator(loc)
Graph.annotate('www.google.co.in', xy= (1.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.youtube.com', xy= (2.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.google.com', xy= (3.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.facebook.com', xy= (4.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.yahoo.com', xy= (5.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.amazon.com', xy= (6.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.wikipedia.org', xy= (7.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.flipkart.com', xy= (8.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.onlinesbi.com', xy= (9.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.annotate('www.irctc.co.in', xy= (10.25,-10), xycoords = 'data',
            horizontalalignment='right', verticalalignment='top')
Graph.axes.get_xaxis().set_ticks([])
Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 20)
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/84:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [5, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 20)
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/85:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [5, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/86:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)
plt.xlabel("")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/87:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/88:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/89:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/90:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)
correlation 

correlation1 = India_Final.corr()
correlation1 

#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4
31/91:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1
31/92:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1.to_excel('correlation_table.xlsx')
31/93:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1.to_csv('correlation_table.csv')
31/94:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1
correlation1.to_csv('correlation_table.csv')
31/95:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1
31/96:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1.to_clipboard()
31/97:
import pandas as pd
import numpy as np 
import seaborn as sns 
import matplotlib as mpl 
import matplotlib.pyplot as plt
import matplotlib.ticker as plticker
import numpy as np 

plt.rcParams['figure.figsize'] = [10, 10]

data = pd.read_excel("C:/Users/SARTHAK/Downloads/GGI_assignment (1) (1).xlsx")
data_change = data.groupby('Country')
India = data_change.get_group('India')
Facebook_likes = India['Facebook_likes'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Twitter_mentions = India['Twitter_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Google_pluses = India['Google_pluses'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
LinkedIn_mentions = India['LinkedIn_mentions'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)
Pinterest_pins = India['Pinterest_pins'].replace({'K' : '*1e3', 'M' : '*1e6', '-' : '0'}, regex = True).map(pd.eval).astype(int)

India_copy = India.copy()
India = India.drop(['Facebook_likes','Twitter_mentions','Google_pluses','LinkedIn_mentions','Pinterest_pins'], axis = 1)
India_Final = pd.concat([India , Facebook_likes, Twitter_mentions, Google_pluses, LinkedIn_mentions, Pinterest_pins], axis=1)
 
Column_names = ['Country_Rank', 'Website', 'Avg_Daily_Visitors', 'Avg_Daily_Pageviews', 'Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank', 'Country']

India_Final = India_Final.reindex(columns = Column_names)
India_Final['Traffic_Rank'] = India_Final['Traffic_Rank'].astype(int)
col_1 = India_Final['Traffic_Rank']
col_2 = India_Final['Avg_Daily_Visitors']
corr = col_2.corr(col_1)

#DataA and B for Twitter, Pinterest and LinkedIn
DataA = India_Final.head(10)
DataA.to_excel('GGI.xlsx')

DataA_copy = DataA.copy()

DataB = DataA.drop(['Avg_Daily_Visitors', 'Avg_Daily_Pageviews','Traffic_Rank', 'Facebook_likes', 'Google_pluses', 'Pinterest_pins'], axis = 1)
DataB = DataB.set_index('Country_Rank')
Graph = DataB.plot(kind='area')

Graph.set_title('Trends of Twitter and Linkedin Mentions for top 10 visited websites in India', fontsize = 10)
Graph.set_ylim(ymin=0)

plt.xlabel("Site Ranking in India")

plt.show()


#DataC starts -- page visited and visitors 
DataC = DataA_copy.drop(['Facebook_likes', 'Twitter_mentions', 'Google_pluses', 'LinkedIn_mentions', 'Pinterest_pins', 'Traffic_Rank'], axis = 1)
DataC = DataC.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [5, 5]
Graph1 = DataC.plot(kind='bar', color = ['pink', 'blue'])
Graph1.set_title('Avg Daily Visitors and Daily Pageviews')
plt.xlabel("Site Ranking in India")
plt.grid()
plt.show()

#DataD for Facebook and Google Plus 
DataD =  DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank', 'Pinterest_pins','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country' ], axis = 1)
DataD = DataD.set_index('Country_Rank')
Graph3 = sns.lineplot(data=DataD)
plt.grid()
Graph3.set_title('Google Plus vs Facebook')
Graph3.set_xlabel("Site Rank")
plt.show()



#Recommendations for Unacademy 


#Pinterest 
DataE = DataA_copy.drop(['Twitter_mentions', 'LinkedIn_mentions', 'Traffic_Rank','Avg_Daily_Visitors','Avg_Daily_Pageviews', 'Website','Country', 'Facebook_likes','Google_pluses' ], axis = 1)
DataE = DataE.set_index('Country_Rank')
plt.rcParams['figure.figsize'] = [10, 2]
Graph4 = sns.lineplot(data=DataE)
loc = plticker.MultipleLocator(base=1.0)


plt.grid()
Graph4.set_xlabel("Site Rank in India")
Graph4.set_title('Pinterest Pins Trends')
Graph4

India_Final['Country_Rank'] = India_Final['Country_Rank'].astype(int)
columnA = India_Final['Pinterest_pins']
columnB = India_Final['Country_Rank']
correlation = columnA.corr(columnB)


correlation1 = India_Final.corr()
correlation1.to_clipboard()
India_Final
37/1: git clone --recurse-submodules https://github.com/hollyjackson/NYT_Content_Analysis.git
37/2: git clone --recurse-submodules https://github.com/hollyjackson/NYT_Content_Analysis.git
37/3: git_clone --recurse-submodules https://github.com/hollyjackson/NYT_Content_Analysis.git
37/4: pip3 install -r requirements.txt
38/1:
import numpy as np 
import pandas as pd 
from plotaine import * 
from plotaine.data import ntcars
38/2:
import numpy as np 
import pandas as pd 
from plotnine import * 
from plotnine.data import mtcars
38/3: pip install plotnine
38/4:
import numpy as np 
import pandas as pd 
from plotnine import * 
from plotnine.data import mtcars
38/5:
import numpy as np 
import pandas as pd 
from plotnine import * 
from plotnine.data import mtcars
38/6:
import numpy as np 
import pandas as pd 
from plotnine import * 
from plotnine.data import mtcars
38/7: pip install plotnine
39/1: conda install -c conda-forge plotnine
39/2:
import pandas as pd 
import numpy as np
from plotnine import * 
from plotnine.data import mtcars
39/3: mtcars.head()
39/4: (ggplot(mtcars, aes(x='wt', y='mpg')))+geom_point()
39/5: (ggplot(mtcars, aes(x='wt', y='mpg')))+geom_point() + stat_smooth(method ='lm')
39/6: (ggplot(mtcars, aes(x='wt', y='mpg', color ='factor(gear)')))+geom_point() + stat_smooth(method ='lm')+facet_wrap('~gear')
39/7: penguin = pd.read_csv("https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/penguins.csv")
39/8: (ggplot(penguin, aes(x='bill_lenth_mm', y='bill_depth_mm', color ='species'))+
39/9: (ggplot(penguin, aes(x='bill_lenth_mm', y='bill_depth_mm', color ='species'))+geom_point()
39/10: (ggplot(penguin, aes(x='bill_lenth_mm', y='bill_depth_mm', color ='species'))+geom_point())
39/11: (ggplot(penguin, aes(x='bill_length_mm', y='bill_depth_mm', color ='species'))+geom_point())
39/12: penguin.head()
39/13: (ggplot(penguin, aes(x='species')))
39/14: (ggplot(penguin, aes(x='species')))+geom_bar()
39/15: (ggplot(penguin, aes(x='species', y='bill_length_mm')))
39/16: (ggplot(penguin, aes(x='species', y='bill_length_mm')))+geom_boxplot()
39/17: (ggplot(penguin, aes(x='species', y='bill_length_mm', fill='species')))+geom_boxplot()
39/18: (ggplot(penguin, aes(x='species', y='bill_length_mm', fill='species')))+geom_boxplot()+theme_minimal
39/19: (ggplot(penguin, aes(x='species', y='bill_length_mm', fill='species')))+geom_boxplot()+theme_minimal()
40/1: import numpy as np
40/2:
import numpy as np 
from plonine import *
41/1: import requests
41/2:
import requests 
from bs4 import BeautifulSoup
41/3:
import requests 
from bs4 import BeautifulSoup
41/4:
headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}
response = requests.get("https://www.zomato.com/bangalore/top-restaurants",headers=headers)
42/1:
import requests 
from bs4 import BeautifulSoup #Beautiful Soup is a Python library to pull data out of HTML and XML files.
42/2:
headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}
response = requests.get("https://www.zomato.com/bangalore/top-restaurants",headers=headers) #This code is used to fake the agent
43/1: 2 + 4
43/2: import requests
44/1: #functions
44/2: def sum()
44/3:
def sum(a, b) : 
    c = a+b 
    print(c)
44/4:
def sum(a, b) : 
    c = a+b 
    print(c)
44/5: sum(1,2)
44/6: def abc(x):
44/7:
def abc(x): 
    If x>0 : 
        return x 
    
    If x<0 : 
        return abs(x)
44/8:
def abc(x): 
    if x>0 : 
        return x 
    
    if x<0 : 
        return abs(x)
44/9: abc(-9)
44/10:
def abc(x): 
    if x>=0 : 
        return x 
    
    if x<0 : 
        return -x
44/11: abc(-9)
44/12: while
44/13: import time, sys
44/14:
import time, sys 
indent = 0 
indentIncreasing = True 

try : 
    while True : 
        print('' * indent, end = '')
        print('*******')
        if indentIncreasing : 
            indent = indent + 1 
            if indent = 20 
            indentIncreasing = False 
        else : 
            indent = indent - 1 
            if indent = 0 
            indentIncreasing = True 
            
except KeyboardInterrupt : 
    sys.exit()
44/15:
import time, sys 
indent = 0 
indentIncreasing = True 

try : 
    while True : 
        print('' * indent, end = '')
        print('*******')
        if indentIncreasing : 
            indent = indent + 1 
            if indent == 20 
            indentIncreasing = False 
        else : 
            indent = indent - 1 
            if indent = 0 
            indentIncreasing = True 
            
except KeyboardInterrupt : 
    sys.exit()
44/16:
import time, sys 
indent = 0 
indentIncreasing = True 

try : 
    while True : 
        print('' * indent, end = '')
        print('*******')
        if indentIncreasing : 
            indent = indent + 1 
            if indent = 20 :
            indentIncreasing = False 
        else : 
            indent = indent - 1 
            if indent = 0 :
            indentIncreasing = True 
            
except KeyboardInterrupt : 
    sys.exit()
44/17:
import time, sys 
indent = 0 
indentIncreasing = True 

try : 
    while True : 
        print('' * indent, end = '')
        print('*******')
        if indentIncreasing : 
            indent = indent + 1 
            if indent == 20 :
            indentIncreasing = False 
        else : 
            indent = indent - 1 
            if indent == 0 :
            indentIncreasing = True 
            
except KeyboardInterrupt : 
    sys.exit()
44/18:
import time, sys 
indent = 0 
indentIncreasing = True 

try : 
    while True : 
        print('' * indent, end = '')
        print('*******')
        if indentIncreasing : 
            indent = indent + 1 
            if indent == 20 :
                indentIncreasing = False 
        else : 
            indent = indent - 1 
            if indent == 0 :
            indentIncreasing = True 
            
except KeyboardInterrupt : 
    sys.exit()
44/19:
import time, sys 
indent = 0 
indentIncreasing = True 

try : 
    while True : 
        print('' * indent, end = '')
        print('*******')
        if indentIncreasing : 
            indent = indent + 1 
            if indent == 20 :
                indentIncreasing = False 
        else : 
            indent = indent - 1 
            if indent == 0 :
                indentIncreasing = True 
            
except KeyboardInterrupt : 
    sys.exit()
45/1: import time, sys
45/2:
indent1 = 0 
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

while True : #infinite loop 
    print('' * indent, end = '')
    print('******')
45/3:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for 1<i<9 : 
    
    while indent1 !=0 :   
    
        
    print('' * indent1, end = '')
    print('******', end = '')
    print('' * indent2, end = '')
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/4:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for (1<i<9) : 
    
    while indent1 !=0 :   
    
        
    print('' * indent1, end = '')
    print('******', end = '')
    print('' * indent2, end = '')
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/5:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 !=0 :   
    
        
    print('' * indent1, end = '')
    print('******', end = '')
    print('' * indent2, end = '')
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/6:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 !=0 :   
    
         print('' * indent1, end = '')
         print('******', end = '')
        print('' * indent2, end )
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/8:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 !=0 :   
        print('' * indent1, end = '')
        print('******', end = '')
        print('' * indent2, end )
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/9:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 !=0 :   
        print('' * indent1, end = '')
        print('******', end = '')
        print('' * indent2)
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/10:
indent1 = 0
indent2 = 0
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 != 0 :   
        print('' * indent1, end = '')
        print('******', end = '')
        print('' * indent2)
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/11:
indent1 = 4
indent2 = 4
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 != 0 :   
        print('' * indent1, end = '')
        print('******', end = '')
        print('' * indent2)
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/12:
import time, sys
indent = 0 # How many spaces to indent.
indentIncreasing = True # Whether the indentation is increasing or not.

try:
    while True: # The main program loop.
        print(' ' * indent, end='')
        print('********')
        time.sleep(0.1) # Pause for 1/10 of a second.

        if indentIncreasing:
            # Increase the number of spaces:
            indent = indent + 1
            if indent == 20:
                # Change direction:
                indentIncreasing = False

        else:
            # Decrease the number of spaces:
            indent = indent - 1
            if indent == 0:
                # Change direction:
                indentIncreasing = True
except KeyboardInterrupt:
    sys.exit()
45/13:
indent1 = 4
indent2 = 4
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 != 0 :   
        print(' ' * indent1, end = '')
        print('******', end = '')
        print(' ' * indent2)
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/14: print(''*4)
45/15:
print(' '*4)
print('****')
45/16:
print(' '*4, end = '')
print('****')a
45/17:
print(' '*4, end = '')
print('****')
45/18:
print(''*4, end = '')
print('****')
45/19:
indent1 = 4
indent2 = 4
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

for i in range(1,9) : 
    
    while indent1 != 0 :   
        print(' ' * indent1, end = '')
        print('******', end = '')
        print(' ' * indent2)
    
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
45/20:
indent1 = 4
indent2 = 4
indentIncreasing = True 

#10 rows 
#for 1<i<11 
# i =1 , no of indents either side = 4 
# i = 2, no of indents either side = 3 and 4 
# i = 3 , no of indents either side = 3 
# i = 4 , no of indents either side = 2 and 3 
# i=5, no of indents either side = 2 

while indent1 != 0 :
    
    for i in range(1,9) : 
        print(' ' * indent1, end = '')
        print('******', end = '')
        print(' ' * indent2)
    
    if i%2 == 0 : #when i is even 
        indent1 = indent1
        indent2 = indent2 - 1
    else : #when i is odd
        indent1 = indent1 - 1 
        indent2 = indent2
        
    i = i+1
46/1: import pandas as pd
46/2: df = pd.read_csv("C:\Users\SARTHAK\Documents\housing.csv")
46/3: df = pd.read_csv(r"C:\Users\SARTHAK\Documents\housing.csv")
46/4: df.head()
46/5: print('This dataset represents the characteristics of population and housing for each block group in California. A block group is the smallest geographical unit for which the US Census Bureau publishes sample data')
46/6: print('This dataset represents the characteristics of population and real estate for each block group in California. A block group is the smallest geographical unit for which the US Census Bureau publishes sample data')
46/7:
print('This dataset represents the characteristics of population and real estate for each block group in California. A block group is the smallest geographical unit for which the US Census Bureau publishes sample data')

print('Our aim is to predict the median housing price in any district')
46/8:
df.head()
df.info()
46/9:
df.head()
df.info()
df.duplicated()
46/10:
df.head()
df.info()
df.duplicated().unique()
46/11:
#EDA
df.head()
df.info()
df.duplicated().unique()
df.value_counts()
46/12:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
46/13:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()
46/14:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as ply
46/15:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist()
46/16:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(figsize = (20,15))
46/17:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, gsize = (20,15))
46/18:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))
46/19:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as ply 
import numpy as np
46/20:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
46/21:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[train_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]
46/22:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[train_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3)
46/23:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3)
46/24: train_set.head()
46/25:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3)

len(train_set)
46/26:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3)

len(train_set)
len(test_set)
46/27:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3)

len(train_set)
len(test_set)
46/28:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 

housing_with_id['id'] = housing['longitude']*1000 + housing['lattitude']


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3, 'id')
46/29:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 

df_with_id['id'] = df['longitude']*1000 + df['lattitude']


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3, 'id')
46/30:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 

df_with_id['id'] = df['longitude']*1000 + df['latitude']


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df, 0.3, 'id')
46/31:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


df_with_id['id'] = df['longitude']*1000 + df['latitude']


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df_with_id, 0.3, 'id')
46/32:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


df_with_id['id'] = df.reset_index()


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df_with_id, 0.3, 'index')
46/33:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 


df_with_id = df.reset_index()


def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df_with_id, 0.3, 'index')
46/34:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as ply 
import numpy as np
from zlib import crc32 #to prevent the machine from reloading a new dataset each time we refresh
46/35:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df_with_id, 0.3, 'index')
46/36:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




def split_train_test(data, test_ratio) : 
    random_indices = np.random.permutation(len(data)) 
    test_set_size = int(len(data) * test_ratio)
    test_indices = random_indices[:test_set_size]
    train_indices = random_indices[test_set_size:]
    return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = split_train_test(df_with_id, 0.3)
46/37:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as ply 
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from skleaarn.model_selection import train_test_split
46/38:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as ply 
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split
46/39:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = train_test_split(df, 0.3, random_state = 42)
46/40:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)
46/41:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#Step - 4(b) : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_indom'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
46/42:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#Step - 4(b) : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_indome'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
46/43:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#Step - 4(b) : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
46/44:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#Step - 4(b) : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()
46/45:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as ply 
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit
46/46:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
46/47:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
strat_test_set['income_category'].hist()
46/48:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
strat_test_set['income_category'].hist()

for set_ in strat(strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)
46/49:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)
46/50:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
46/51:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude')
46/52:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1)
46/53:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1)
46/54:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
#stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1)
46/55:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1)
46/56:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            s = housing['population']/100, label = 'population' figsize = (10,7), 
            c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True)
46/57:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            s = housing['population']/100, label = 'population', figsize = (10,7), 
            c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True)
46/58:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            s = df['population']/100, label = 'population', figsize = (10,7), 
            c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True)
46/59:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit
46/60:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            s = df['population']/100, label = 'population', figsize = (10,7), 
            c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True)
46/61:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            s = df['population']/100, label = 'population', figsize = (10,7), 
            c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            )
46/62:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

df_copy = strat_train_set.copy()
df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            label = 'population', figsize = (10,7), 
            c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            )
46/63:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()
46/64:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix
46/65:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age']
scatter_matrix(df[features], figsize = (12,8))
50/1:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

df_features.info()
50/2:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age']
scatter_matrix(df[features], figsize = (12,8))
50/3:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
50/4: df = pd.read_csv(r"C:\Users\SARTHAK\Documents\housing.csv")
50/5:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))
50/6:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age']
scatter_matrix(df[features], figsize = (12,8))
50/7:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

df_features.info()
50/8:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

df_features.info()

df_features.dropna(subset = 'total_bedrooms')
50/9:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

df_features.info()

df_features.dropna(subset = ['total_bedrooms'])
50/10:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])
50/11:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

df_features.info()
50/12:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity')
imputer.fit(df_features_num)
50/13:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.inputs import SimpleImputer #Useful for replacing missing values with a number.
50/14:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
50/15:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity')
imputer.fit(df_features_num)
50/16:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num)
50/17:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
50/18:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num)
50/19:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num)
X
50/20:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns)
50/21:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns)
df_train_transform.info()
50/22:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
50/23:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.head()
50/24:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()
50/25:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder
50/26:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

cat_encoder = OneHotEncoder()
df_features_cat_encoded = cat_encoder.fit_transform(df_features_cat)
df_features_cat_encoded
50/27:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

onehotencoder1 = OneHotEncoder(categorical_features = [0])
df_features_cat_encoded = cat_encoder.fit_transform(df_features_cat)
df_features_cat_encoded
50/28:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

onehotencoder1 = OneHotEncoder(categories = [0])
df_features_cat_encoded = cat_encoder.fit_transform(df_features_cat)
df_features_cat_encoded
51/1:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder
51/2: df = pd.read_csv(r"C:\Users\SARTHAK\Documents\housing.csv")
51/3:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))
51/4:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age']
scatter_matrix(df[features], figsize = (12,8))
51/5:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

onehotencoder1 = OneHotEncoder(categories = [0])
df_features_cat_encoded = cat_encoder.fit_transform(df_features_cat)
df_features_cat_encoded
51/6:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

onehotencoder1 = OneHotEncoder(categories = [0])
df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
df_features_cat_encoded
51/7:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])
51/8:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

df_features_cat_encoded
51/9:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])
51/10:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin
51/11:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

#Step - 5(c) : Add new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
51/12:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

#Step - 5(c) : Add new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributeAdder(add_bedrooms_per_room = False)
df_features_num_new = attribute_adder.transform(df_features_num.values)
51/13:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

#Step - 5(c) : Add new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
df_features_num_new = attribute_adder.transform(df_features_num.values)
51/14:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

#Step - 5(c) : Add new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
df_features_num_new = attribute_adder.transform(df_features_num.values)

df_features_num_new.head()
51/15:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

#Step - 5(c) : Add new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
df_features_num_new = attribute_adder.transform(df_features_num.values)

df_features_num_new
51/16:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))

df['rooms_per_household'] = df['total_rooms']/df['households']
51/17:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))

df['rooms_per_household'] = df['total_rooms']/df['households']

df['population_per_household'] = df['population']/df['households']
df['bedrooms_per_rooms'] = df['total_bedrooms']/df['total_rooms']
51/18:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))

df['rooms_per_household'] = df['total_rooms']/df['households']

df['population_per_household'] = df['population']/df['households']
df['bedrooms_per_rooms'] = df['total_bedrooms']/df['total_rooms']

df.describe()
51/19:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age']
scatter_matrix(df[features], figsize = (12,8))
51/20:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age', 'rooms_per_household', 'bedrooms_per_room', 'population_per_household']
scatter_matrix(df[features], figsize = (12,8))
51/21:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 

df.corr()

features = ['median_house_value', 'total_rooms', 'median_income', 'housing_median_age', 'rooms_per_household', 'bedrooms_per_rooms', 'population_per_household']
scatter_matrix(df[features], figsize = (12,8))
51/22:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 


features = ['median_house_value', 'median_income' 'rooms_per_household', 'bedrooms_per_rooms', 'population_per_household']
scatter_matrix(df[features], figsize = (12,8))
51/23:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 


features = ['median_house_value', 'median_income', 'rooms_per_household', 'bedrooms_per_rooms', 'population_per_household']
scatter_matrix(df[features], figsize = (12,8))
51/24:
#Step - 4 : Model Preparation 

#Step - 4(a) : Splitting of data 




# manually : 
#def split_train_test(data, test_ratio) : 
    #random_indices = np.random.permutation(len(data)) 
    #test_set_size = int(len(data) * test_ratio)
    #test_indices = random_indices[:test_set_size]
    #train_indices = random_indices[test_set_size:]
    #return data.iloc[train_indices], data.iloc[test_indices]

# sklearn : 
#train_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)

#stratified : Check if the training data is representative of the sample 

df['income_category'] = pd.cut(df['median_income'], bins = [0., 1.5, 3, 4.5, 6., np.inf], labels = [1,2,3,4,5])
df['income_category'].hist()

split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)
for train_index, test_index in split.split(df, df['income_category']) : 
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]
    
stratified_proportion = strat_test_set['income_category'].hist()

for set_ in (strat_train_set, strat_test_set) : 
    set_.drop ('income_category', axis = 1, inplace = True)

    
    
#Step - 4(b) : Exploring training dataset

#df_copy = strat_train_set.copy()
#df_copy.plot(kind = 'scatter', x = 'longitude', y='latitude', alpha = 0.1, 
            #label = 'population', figsize = (10,7), 
            #c = 'median_housing_value', cmap = plt.get_cmap('jet'), colorbar = True,
            #)

#There is some issue with above code. Not working - check out other ways too.

#Step - 4(c) : Exploring correlations 


#Way - 1 : 
#features = ['median_house_value', 'median_income', 'rooms_per_household', 'bedrooms_per_rooms', 'population_per_household']
#scatter_matrix(df[features], figsize = (12,8))

#Way - 2 : 
corr = df.corr()
corr['median_house_value'].sort_values(ascending = False)
51/25:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

imputer = SimpleImputer(strategy = 'median')
df_features_num = df_features.drop('ocean_proximity', axis = 1)
imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
imputer.statistics_
X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])

#Step - 5(note) : Automate the addition of new features if applicable 

#rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

#class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    #def __init__(self, add_bedrooms_per_room = True) : 
        #self.add_bedrooms_per_room = add_bedrooms_per_room 
    #def fit(self, X, y = None) : 
        #return self 
    #def transform(self, X, y= None) : 
        #rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        #population_per_household = X[:, population_ix]/X[:, households_ix]
        #if self.add_bedrooms_per_room : 
            #bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            #return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        #else : 
            #return np.c_[X, rooms_per_household, population_per_household]
        
#attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new
51/26:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler
51/27:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScalar())
])

df_features_num_tr = num_pipeline.fit_transform(df_features_num)
51/28:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])

df_features_num_tr = num_pipeline.fit_transform(df_features_num)
51/29:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])

df_features_num_tr = num_pipeline.fit_transform(df_features_num)

df_features_num_tr.head()
51/30:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer
51/31:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']

full_pipeline = ColumnTransformer([
    ('num', num_pipeline, num_attributes)
    ('cat', OneHotEncoder(), cat_attributes)
])
51/32:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']

num_attributes 

#full_pipeline = ColumnTransformer([
   # ('num', num_pipeline, num_attributes)
   # ('cat', OneHotEncoder(), cat_attributes)
#])
51/33:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']
 

full_pipeline = ColumnTransformer([
   ('num', num_pipeline, num_attributes)
   ('cat', OneHotEncoder(), cat_attributes)
])
51/34:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']
 

full_pipeline = ColumnTransformer([
   ('num', num_pipeline, num_attributes),
   ('cat', OneHotEncoder(), cat_attributes)
])
51/35:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']
 

full_pipeline = ColumnTransformer([
   ('num', num_pipeline, num_attributes),
   ('cat', OneHotEncoder(), cat_attributes)
])

housing_prepared = full_pipeline.fit_transform(df_features)
51/36:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']
 

full_pipeline = ColumnTransformer([
   ('num', num_pipeline, num_attributes),
   ('cat', OneHotEncoder(), cat_attributes)
])

housing_prepared = full_pipeline.fit_transform(df_features)

housing_prepared
51/37:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']
 

full_pipeline = ColumnTransformer([
   ('num', num_pipeline, num_attributes),
   ('cat', OneHotEncoder(), cat_attributes)
])

housing_prepared = full_pipeline.fit_transform(df_features)
51/38:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
51/39:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_labels)
51/40:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)
51/41:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)
51/42:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

lin_reg.predict(evalyation_prepared)
51/43:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

lin_reg.predict(evaluation_prepared)
51/44: df.head()
51/45:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
51/46:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions = lin_reg.predict(evaluation_prepared)

lin_rmse = sqrt(mean_squared_error(df_label, predictions)
51/47:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions = lin_reg.predict(evaluation_prepared)

lin_rmse = sqrt(mean_squared_error(df_label, predictions))
51/48:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions = lin_reg.predict(evaluation_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions))
51/49:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions = lin_reg.predict(housing_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions))
51/50:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions = lin_reg.predict(housing_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions))

print(lin_rmse)
51/51:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error 
from sklearn.tree import DecisionTreeRegressor
51/52:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions = lin_reg.predict(housing_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
51/53:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(housing_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(housing_prepared, df_label) 

predictions_dtr = tree_reg.predict(housing_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse)
51/54:
#Step - 6 : Training and evaluating the dataset


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(housing_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(housing_prepared, df_label) 

predictions_dtr = tree_reg.predict(housing_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting.
51/55:
#Step - 6 : Training and evaluating the dataset

housing_prepared = df_prepared 


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting.
51/56:
#Step - 6 : Training and evaluating the dataset

housing_prepared = df_prepared 


#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting.
51/57:
#Step - 5 : Prepare the data

#Step - 5(a) : Data Cleaning. Note - data cleaning is always done on training data to reduce chances of overfitting

df_features= strat_train_set.drop('median_house_value', axis = 1)
df_label = strat_train_set['median_house_value'].copy()

#Ways to do it in increasing order of power 

#Way1 : df_features.dropna(subset = ['total_bedrooms'])

#Way 2 : Through SimpleImputer function 

#imputer = SimpleImputer(strategy = 'median')
#df_features_num = df_features.drop('ocean_proximity', axis = 1)
#imputer.fit(df_features_num) #Computes the median of each numerical attribute and stores it in imputer.statistics_
#imputer.statistics_
#X = imputer.transform(df_features_num) #This replaces all missing values with median calculated above. 

#df_train_transform = pd.DataFrame(X, columns = df_features_num.columns) #Creates the final transformed dataframe that we will be using.


#Step - 5(b) : Handling text and categorical attributes 

df_features_cat = df_features['ocean_proximity']
df_features_cat.unique()

#Way - 1 : Give each category a numerical value 

# df_features_cat_encoded = ordinal_encoder.fit_transform(df_features_cat)


#Way - 2 : Give the value 1, to those in the cattegory '<1H Ocean', and 0 to those who are not, similary do so for other categories. 

#This can be achieved through the OneHotEncoder package of skicit learning. 

#onehotencoder1 = OneHotEncoder(categories = [0])
#df_features_cat_encoded = OneHotEncoder.fit_transform(df_features_cat)
#df_features_cat_encoded

#Way - 3 : Through pd.get_dummies 

#df_features_cat_encoded = pd.get_dummies (df_features_cat, columns = ['ocean_proximity'])


#(note) : Automate the addition of new features if applicable 

rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin) : 
    def __init__(self, add_bedrooms_per_room = True) : 
        self.add_bedrooms_per_room = add_bedrooms_per_room 
    def fit(self, X, y = None) : 
        return self 
    def transform(self, X, y= None) : 
        rooms_per_household = X[:, rooms_ix]/X[:, households_ix]
        population_per_household = X[:, population_ix]/X[:, households_ix]
        if self.add_bedrooms_per_room : 
            bedrooms_per_room = X[:, bedrooms_ix]/X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else : 
            return np.c_[X, rooms_per_household, population_per_household]
        
attribute_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)
#df_features_num_new = attribute_adder.transform(df_features_num.values)

#df_features_num_new


#Step - 5(c) : Feature Scaling 


#Way - 1 : Standardization using StandardScaler from sklearn.preprocessing

#Way - 2 : MinMax using MinMax Scaler 



#TRANSFORMATION PIPELINES

#1. We will use transformation pipelines to combine step a,note and c

#All but the last method in the pipeline must be transfomers, ie must contain a fit_transform method 
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')), #transformer, ie must contain a fit_transform method
    ('attribute_adder', CombinedAttributesAdder()), #transformer, ie must contain a fit_transform method
    ('std_scaler', StandardScaler())
])


#2. We will use the column transformer pipeline to apply all necessary transformations on the dataset together 

num_attributes = list(df_features_num)
cat_attributes = ['ocean_proximity']
 

full_pipeline = ColumnTransformer([
   ('num', num_pipeline, num_attributes),
   ('cat', OneHotEncoder(), cat_attributes)
])

df_prepared = full_pipeline.fit_transform(df_features)
51/58:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting.
51/59:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error 
from sklearn.tree import DecisionTreeRegressor 
from sklearn.model_selection import cross_val_score |
51/60:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error 
from sklearn.tree import DecisionTreeRegressor 
from sklearn.model_selection import cross_val_score
51/61:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-scores)
51/62:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores)
51/63:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores)


tree_rmse_scores
51/64:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.sd()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
51/65:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.sd()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
display_scores(tree_rmse_scores)
51/66:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
display_scores(tree_rmse_scores)
51/67:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error 
from sklearn.tree import DecisionTreeRegressor 
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
51/68:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
    
display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
51/69:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
    
display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_scores(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(cross_val_scores_forest) 

display_scores(forest_reg_scores)
51/70:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
    
display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_scores(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

display_scores(forest_reg_scores)
51/71:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
    
display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_score(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

display_scores(forest_reg_scores)
51/72:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', tree_rmse_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
    
#display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_score(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

display_scores(forest_reg_scores)
51/73:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', forest_reg_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)
    
    
#display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_score(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

display_scores(forest_reg_scores)
51/74:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)


    
    
#display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_score(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', forest_reg_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)

display_scores(forest_reg_scores)
51/75:
#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)


    
    
#display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_score(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', forest_reg_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)

display_scores(forest_reg_scores)
51/76:

#Step - 6 : Training and evaluating the dataset




#Linear Regression Model 

lin_reg = LinearRegression()
lin_reg.fit(df_prepared, df_label)

evaluation_data = df_features.iloc[:5]
evaluation_label = df_label.iloc[:5]
evaluation_prepared = full_pipeline.transform(evaluation_data)

predictions_lr = lin_reg.predict(df_prepared)

lin_rmse = np.sqrt(mean_squared_error(df_label, predictions_lr))

print(lin_rmse) #This is an example of model underfitting, as the predicted price error is way too high. 



#Decision Tree Regressor 

tree_reg = DecisionTreeRegressor()
tree_reg.fit(df_prepared, df_label) 

predictions_dtr = tree_reg.predict(df_prepared)
tree_rmse = np.sqrt(mean_squared_error(df_label, predictions_dtr))

print(tree_rmse) #This is an example of overfitting. We will use Cross Validation for better evaluation 


cross_val_scores_tree = cross_val_score(tree_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10) #Creates 10 subsets of training data and evaluates the decision tree model 10 times, by training the data on 9 folds.
tree_rmse_scores = np.sqrt(-cross_val_scores_tree)


    
    
#display_scores(tree_rmse_scores) #Decision Tree performs worse than linear regression

#This suggests that the decision tree overfits the model worse than linear regression Underfits the model. 

#Random Forest Regressor 

forest_reg = RandomForestRegressor()
forest_reg.fit(df_prepared, df_label)

predictions_forest = forest_reg.predict(df_prepared)
cross_val_scores_forest = cross_val_score(forest_reg, df_prepared, df_label, scoring = 'neg_mean_squared_error', cv = 10)
forest_reg_scores = np.sqrt(-cross_val_scores_forest) 

def display_scores(scores) : 
    mean = scores.mean()
    standard_deviation = scores.std()
    
    print('Scores :', forest_reg_scores)
    print('Mean :', mean)
    print('Standard Deviation :', standard_deviation)

display_scores(forest_reg_scores)
51/77: print(snbjsx)
52/1:
#Factorial through for loop 

def fact(n) : 
    
    
    for i in range(1, n+1 ) : 
        value = *i 
        
        return(value)
52/2:
#Factorial through for loop 

def fact(n) : 
    
    
    for i in range(1, n+1 ) : 
        value *= i 
        
        return(value)
52/3:
#Factorial through for loop 

def fact(n) : 
    
    
    for i in range(1, n+1 ) : 
        value *= i 
        
        return(value)
    
fact(10)
52/4:
#Factorial through for loop 

def fact(n) : 
    
    value = 1 
    
    for i in range(1, n+1 ) : 
        value *= i 
        
        return(value)
    
fact(10)
52/5:
#Factorial through for loop 

def fact(n) : 
    
    value = 1 
    
    for i in range(2, n+1 ) : 
        value *= i 
        
        return(value)
    
fact(10)
52/6:
#Factorial through for loop 

def fact(n) : 
    
    value = 1 
    
    for i in range(2, n+1) : 
        value *= i 
        
        
        return value
    
fact(10)
52/7:
def factorial(n):
       
    res = 1
      
    for i in range(2, n+1):
        res *= i
    return res

factorial(10)
52/8:
#Factorial through for loop 

def fact(n) : 
    
    value = 1 
    
    for i in range(2, n+1) : 
        value *= i 
        return value
    
fact(10)
52/9:
#Factorial through for loop 

def fact(n) : 
    
    value = 1 
    
    for i in range(2, n+1): 
        value *= i 
    return value
    
fact(10)
52/10:
#factorial using while loop 

def factorial(n) : 
    
    i = 1
    
    while i < n :
    return i*n
52/11:
#factorial using while loop 

def factorial(n) : 
    
    i = 1
    
    while i < n :
        return i*n
52/12: factorial(5)
52/13:
#factorial using while loop 

def factorial(n) : 
    
    i = 1
    value = 1
    
    while i < n+1 :
        value = i*value
        i = i+1
        
    return value
52/14: factorial(5)
52/15: factorial(10)
52/16: factorial(1)
52/17: factorial(3)
52/18:
#factorial using while loop 

def factorial(n) : 
    
    i = 1
    value = 1
    
    while i < n+1 :
        value = i*value
        i = i+1
        
    return value
52/19: factorial(3)
52/20: factorial(6)
52/21:
#Fibonacci Sequence 

def fib(n) : 
    
    if n = 1 : 
        return 1 
    if n = 2 : 
        return 2 
    else :
 
    current value = 2
    previous value = 1 
    
    while i < n : 
    new value = current value + previous value 
    current value = new value 
    previous value = current value 
    i = i+1 
    
    return new value
52/22:
#Fibonacci Sequence 

def fib(n) : 
    
    if (n = 1) : 
        return 1 
    if (n = 2) : 
        return 2 
    else :
 
    current value = 2
    previous value = 1 
    
    while i < n : 
    new value = current value + previous value 
    current value = new value 
    previous value = current value 
    i = i+1 
    
    return new value
52/23:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 1 
    if n == 2 : 
        return 2 
    else :
 
    current value = 2
    previous value = 1 
    
    while i < n : 
    new value = current value + previous value 
    current value = new value 
    previous value = current value 
    i = i+1 
    
    return new value
52/24:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 1 
    if n == 2 : 
        return 2 
    else :
        current value = 2
        previous value = 1 
    
    while i < n : 
    new value = current value + previous value 
    current value = new value 
    previous value = current value 
    i = i+1 
    
    return new value
52/25:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 1 
    if n == 2 : 
        return 2 
    else :
        current_value = 2
        previous_value = 1 
    
    while i < n : 
    new value = current_value + previous_value 
    current_value = new_value 
    previous_value = current_value 
    i = i+1 
    
    return new_value
52/26:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 1 
    if n == 2 : 
        return 2 
    else :
        current_value = 2
        previous_value = 1 
    
    while i < n : 
        new value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/27:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 1 
    if n == 2 : 
        return 2 
    else :
        current_value = 2
        previous_value = 1 
    
    while i < n : 
        new_value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/28: fib(4)
52/29:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 1 
    if n == 2 : 
        return 2 
    else :
        current_value = 2
        previous_value = 1 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/30: fib(4)
52/31:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 0 
    if n == 2 : 
        return 1
    else :
        current_value = 2
        previous_value = 1 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/32: fib(4)
52/33:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 0 
    if n == 2 : 
        return 1
    else :
        current_value = 1
        previous_value = 1 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/34: fib(4)
52/35:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 0 
    if n == 2 : 
        return 1
    else :
        current_value = 0
        previous_value = 0 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/36: fib(4)
52/37:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 0 
    if n == 2 : 
        return 1
    else :
        current_value = 1
        previous_value = 0 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value 
        current_value = new_value 
        previous_value = current_value 
        i = i+1 
    
    return new_value
52/38: fib(4)
52/39:
#Fibonacci Sequence 

def fib(n) : 
    
    if n == 1 : 
        return 0 
    if n == 2 : 
        return 1
    else :
        current_value = 1
        previous_value = 0 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value  
        previous_value = current_value 
        current_value = new_value
    
    return new_value
52/40: fib(4)
53/1:
def fib(n) : 
    
    if n == 1 : 
        return 0 
    if n == 2 : 
        return 1
    else :
        current_value = 1
        previous_value = 0 
        i = 1
    
    while i < n : 
        new_value = current_value + previous_value  
        previous_value = current_value 
        current_value = new_value
    
    return new_value
53/2: fib(4)
56/1: import psycopg2 as pg2
56/2: pip install psycopg2
56/3: import psycopg2 as pg2
56/4: conn = pg2.connect(database='postgres', user='postgres',password='password')
56/5: conn = pg2.connect(database='postgres', user='postgres',password='Deathlyh1@')
56/6:
# Establish connection and start cursor to be ready to query
cur = conn.cursor()
56/7:
# Pass in a PostgreSQL query as a string
cur.execute("SELECT * FROM payment")
56/8: conn = pg2.connect(database='postgres', user='postgres',password='Deathlyh1@')
56/9:
# Establish connection and start cursor to be ready to query
cur = conn.cursor()
56/10:
# Pass in a PostgreSQL query as a string
cur.execute("SELECT * FROM payment")
56/11:
# Pass in a PostgreSQL query as a string
cur.execute('SELECT * FROM payment')
56/12:
# Pass in a PostgreSQL query as a string
cur.execute('SELECT * FROM payment')
56/13:
# Pass in a PostgreSQL query as a string
cur.execute('SELECT * FROM payment')
57/1:
#EDA
df.head()
df.info()
df.duplicated().unique()
df['ocean_proximity'].value_counts()
df.describe()


df.hist(bins = 50, figsize = (20,15))

df['rooms_per_household'] = df['total_rooms']/df['households']
df['population_per_household'] = df['population']/df['households']
df['bedrooms_per_rooms'] = df['total_bedrooms']/df['total_rooms']

df.describe()
57/2:
import pandas as pd 
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from zlib import crc32 #to prevent the machine from loading a new dataset each time we refresh
from sklearn.model_selection import train_test_split 
from sklearn.model_selection import StratifiedShuffleSplit 
from pandas.plotting import scatter_matrix #Very useful fpr visualizing correlations
from sklearn.impute import SimpleImputer #Useful for replacing missing values with a number.
from sklearn.preprocessing import OrdinalEncoder#To give each category a numerical value 
from sklearn.preprocessing import OneHotEncoder #To create binary dummy variables 
from sklearn.base import BaseEstimator, TransformerMixin 
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler #For standardization 
from sklearn.compose import ColumnTransformer 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error 
from sklearn.tree import DecisionTreeRegressor 
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
58/1: 2+5
60/1:
print('What is your name?')

input(name)

print('Ahoy,') name + '!'
60/2:
name = input('What is your name?')

print('Ahoy,', name + '!')
60/3:
name = input('What is your name?')

print('Ahoy,', name +'!')
60/4:
name = input(['What is your name?'])

print('Ahoy,', name +'!')
60/5:
name = input('What is your name?')

print('Ahoy,', name +'!')
60/6:
name = input('What is your name?')

print('Ahoy,', name +'!')
61/1:
s = 'jackie will budget for the most expensive zoology equipment'
print(s.len().unique())
61/2:
s = 'jackie will budget for the most expensive zoology equipment'
len(s)
61/3:
s = 'jackie will budget for the most expensive zoology equipment'
unqiue(len(s))
61/4:
s = 'jackie will budget for the most expensive zoology equipment'
len(unique(s))
61/5:
s = 'jackie will budget for the most expensive zoology equipment'
unique(s)
61/6:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
unique(s)
61/7:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
unique(s)
61/8:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
s.unique()
61/9:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
np.unique(s)
61/10:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
len(np.unique(s))
61/11:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s)
61/12:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s)
len(set(s))
61/13:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s)
len(set(s))
61/14:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s)
61/15:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s) - set('')
61/16:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s) - set('')
61/17:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s).difference(set(''))
61/18:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s) - set([''])
61/19:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s) - set([''])
61/20:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s) - set([' '])
61/21:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
set(s) - set(' ')
61/22:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
new_s = set(s) - set(' ')
61/23:
import numpy as np 
s = 'jackie will budget for the most expensive zoology equipment'
new_s = set(s) - set(' ')
len(new_s)
61/24:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']
ls.join()
61/25:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']
ls.join('')
61/26:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']
''.join(ls)
61/27:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']
' '.join(ls)
61/28:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls)
ls_update.strip()
61/29:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls)
ls2 = ls_update.strip()
ls2.lower()
61/30:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls)
ls2 = ls_update.strip()
ls2.lower().capitalize()
61/31:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls)
ls2 = ls_update.strip()
ls2.lower().capitalize().replace('!', '')
61/32:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls)
ls2 = ls_update.strip()
ls2.lower().capitalize().replace('!', '') + '!'
61/33:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls).lower().capitalize().replace('!', '') + '!'
61/34:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls).lower().capitalize().replace('!', '') + '!'
print(ls_update)
61/35:
ls = ['  ThiS', 'SenTence', 'NEEDS', 'bEttEr!', 'foRmatting']

ls_update = ' '.join(ls).strip().lower().capitalize().replace('!', '') + '!'
print(ls_update)
65/1:
new_string = 'Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'
65/2:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''
65/3:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string)
65/4:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

set(new_string)
65/5:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

new_string.split
65/6:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

print(new_string.split)
65/7:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

split(new_string)
65/8:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split())
65/9:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split())

check = 'This- is. a check!'
len(check.split())
65/10:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

len(new_string.split().unique())
65/11:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

set(new_string)
65/12:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

set(new_string.split())
65/13:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check) - set('-')
65/14:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-'))
65/15:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_dict = {'a' : new_string.count('a'), 'the' : new_string.count('the'), 'and' : new_string.count('and') , 'man :' new_string.count('man'), 'time :' new_string.count('time')}
65/16:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_dict = {"a" : new_string.count('a'), "the" : new_string.count('the'), "and" : new_string.count('and') , "man :" new_string.count('man'), "time :" new_string.count('time')}
65/17:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count('wrong')

new_dict = {"a" : new_string.count('a'), "the" : new_string.count('the'), "and" : new_string.count('and') , "man :" new_string.count('man'), "time :" new_string.count('time')}
65/18:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.split().count('wrong')

new_dict = {"a" : new_string.count('a'), "the" : new_string.count('the'), "and" : new_string.count('and') , "man :" new_string.count('man'), "time :" new_string.count('time')}
65/19:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.split().count('wrong')
65/20:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count('wrong')
65/21:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count('a')
65/22:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count('a ')
65/23:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
65/24:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count('a ')
65/25:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')
65/26:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
65/27:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
split
65/28:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
split.sort()
65/29:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
split.sort().head()
65/30:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
head(split.sort())
65/31:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
print(split.sort())
65/32:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
split
65/33:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
split.unique()
65/34:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = new_string.split()
split.distinct()
65/35:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = set(new_string.split())
65/36:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = set(new_string.split())
split
65/37:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = set(new_string.split())
sorted(split)
65/38:
new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ')
new_string.count(' the ')

split = set(new_string.split())
sorted(split - set('-'))
67/1:
list = [1, 2, 3] # Note the color of "list" - Python recognizes this but you are redefining it!

#Altho list is a keyword, we have overwritten it using code. Thus we cannot use it anymore. 

list((10, 20, 30)) # The in-built function will no longer work
67/2:
# Exercise 1: Make three new strings from the first and last, 
# second and second to last, and third and third to last letters 
# in the string below. Print the three strings.

p = 'redder'
p_1 = p[1:len(p)+1]
67/3:
# Exercise 1: Make three new strings from the first and last, 
# second and second to last, and third and third to last letters 
# in the string below. Print the three strings.

p = 'redder'
p_1 = p[0:len(p)+1]
p_2 = p[1:-1]
p_3 = p[2:-2]
print(p_1)
print(p_2)
print(p_3)
67/4:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[1:8] + string1[9:22] + string1[23:]
67/5:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[1:8] + string1[9:22] + string1[23:]
67/6:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[1:8] + string1[9:22] + string1[23:]
67/7:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[1:8] + string1[9:22] + string1[23:]
string2
67/8:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[0:8] + string1[9:22] + string1[23:]
string2
67/9:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[0:8] + string1[9:22] + string1[23:]
string2
string1[22]
67/10:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[0:8] + string1[9:22] + string1[23:]
string2
67/11:
# Exercise 1: Make three new strings from the first and last, 
# second and second to last, and third and third to last letters 
# in the string below. Print the three strings.

p = 'redder'
p_1 = p[0] + p[-1]
p_2 = p[1] + p[-2]
p_3 = p[2] + p[-3]
print(p_1, p_2, p_3)
67/12:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string2 = string1[0:7] + string1[8:21] + string1[22:]
string2
67/13:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string_new = string1[0:7] + string1[8:21] + string1[22:]
string_new
67/14:
# Exercise 2: Make a new string that is the same as string1 but 
# with the 8th and 22nd characters missing.

string1 = 'I cancelled my travelling plans.'
string1_new = string1[0:7] + string1[8:21] + string1[22:]
string1_new
67/15:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace('  ', ' ').capitalize()
67/16:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace(' ', '').capitalize()
67/17:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace(' ', '').capitalize()
67/18:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace('  ', ' ')
67/19:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace('  ', ' ').replace('.', '')
67/20:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace('  ', ' ').replace('.', '').replace('-', '')
67/21:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.replace('  ', ' ').replace('.', '').replace('-', '.')
67/22:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1_a = string1.replace('  ', ' ').replace('.', '').replace('-', '.').replace('\n', '.')
67/23:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1_a = string1.replace('  ', ' ').replace('.', '').replace('-', '.').replace('\n', '.')
string1_a
67/24:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1_a = string1.replace('  ', ' ').replace('.', '').replace('-', '.').replace('\n', '.')
string1_a.replace(' this', 'This').replace(' .', '.')
67/25:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
list(s)
67/26:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.replace('"', '')
67/27:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
67/28:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s[2]
67/29:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
67/30:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s[1:-1]
67/31:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
67/32:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1_a = string1.replace('  ', ' ').replace('.', '').replace('\n', '.')
string1_a.replace(' this', 'This').replace(' .', '.')
67/33:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1_a = string1.strip().replace('  ', ' ').replace('.', '')
67/34:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '')
67/35:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '').capitalize()
67/36:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '').capitalize().replace('i', 'I') + '.'
67/37:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '').capitalize().replace(' i', 'I') + '.'
67/38:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '').capitalize().replace(' i ', 'I') + '.'
67/39:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '').capitalize().replace(' i ', 'I ') + '.'
67/40:
# Exercise 3: Remove the trailing white space in the string below, 
# replace all double spaces with single space, and format to a sentence 
# with proper punctuation. Print the resulting string.

string1 = '  this  is a very badly.  formatted string -  I would  like to make it cleaner\n'
string1.strip().replace('  ', ' ').replace('.', '').capitalize().replace(' i ', ' I ') + '.'
67/41:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
67/42:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s
67/43:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
67/44:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s[0]
67/45:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s[1]
67/46:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s[2]
67/47:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s
67/48:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split()
s.pop(0, -1)
67/49:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.split().pop(0)
67/50:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
print(s.split().pop(0))
67/51:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.lstrip('[').rstrip(']')
67/52:
# Exercise 4: Convert the string below to a list

s = "['apple', 'orange', 'pear', 'cherry']"
s.lstrip('[').rstrip(']').replace("''", '').strip(' ')
67/53:
# Exercise 5: Reverse the strings below.

s1 = 'stressed'
s2 = 'drawer'

s1[::-1]
67/54:
# Exercise 5: Reverse the strings below.

s1 = 'stressed'
s2 = 'drawer'

print(s1[::-1], s2[::-1])
73/1:
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500])
72/1:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 
print(txt)
72/2:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 
txt.split()
73/2: string = 'I am a great-handsome man.'
73/3:
string = 'I am a great-handsome man.'
string.split()
73/4:
string = 'I 'am' a great-handsome man.'
string.split()
73/5:
string = 'I "am" a great-handsome man.'
string.split()
73/6:
string = 'I "am" a great-handsome man. Look at me - be bawling'
string.split()
73/7:
string = "Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well."
string.split()
73/8:
string = '''omeone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''
len(string.split())
73/9:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''
len(string.split('\n'))
73/10:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

string.split('\n')
73/11:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

string.split('','\n')
73/12:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

string.split('\n')
73/13:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

string.split()
73/14:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()
73/15:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

for i in len(our_list) : 
    return our_list[i] = '-'
73/16:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

our_list.remove('-')
73/17:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

our_list.remove('-')

len(our_list)
73/18:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s!= '-']
73/19:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s!= '-']
len(new_list)
73/20:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s!= '-', '\n']
len(new_list)
73/21:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s!= '-' & s!= '\n']
73/22:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' & s!= '\n')]
73/23:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '\n')]
73/24:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '\n')]
len(new_list)
73/25:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '\n')]
new_list
73/26:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...')]
new_list
73/27:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...')]
len(new_list)
73/28:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...')]
len(new_list)
73/29:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...')]
73/30:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...')]
new_list
73/31:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,')]
new_list
73/32:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,')]
len(new_list)
73/33:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,')]
len(new_list)
73/34:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,')]
new_list
73/35:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '..., "')]
new_list
73/36:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '..., "')]
new_list
73/37:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]
new_list
73/38:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]
len(new_list)
73/39:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]
new_list
73/40:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]
new_list.isalnum()
73/41:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = our_list.replace('-', '')
73/42:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_lis2 = string.split().replace('-', '')
73/43:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_lis2 = string.split().replace('-', ' ')
73/44:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_lis2 = string.split().replace('-', ' ')
73/45:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_lis2 = string.replace('-', ' ')
73/46:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')
73/47:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')
len(new_list2.strip())
73/48:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')
new_list2
73/49:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')
new_list2.strip()
73/50:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')

new_list2.strip()
73/51:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')

new_list2.strip()
73/52:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')

new_list2.split()
73/53:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', ' ').replace('...', ' ')

len(new_list2.split())
73/54:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '')

len(new_list2.split())
73/55:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '')

len(new_list2.split())
73/56:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '')

len(new_list2.split())
73/57:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '')

len(new_list2.split())
73/58:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '')

len(new_list2.split())
73/59:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '')

new_list2.split()
73/60:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '').replace(',', '')

new_list2.split()
73/61:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '').replace(',', '')

new_list2.split()
73/62:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '').replace(',', '')

len(new_list2.split())
73/63:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '').replace(',', '').replace('.', '')

len(new_list2.split())
73/64:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if (s!= '-' and s!= '...,"')]

new_list2 = string.replace('-', '').replace('...', '').replace('"', '').replace(',', '').replace('.', '')

len(new_list2.split())
72/3:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
txt.isalnum()
72/4:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
txt.isalpha()
73/65:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/66:
import string

new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ') #Answer to Q3
new_string.count(' the ')

split = set(new_string.split()) #Answer to Q4
sorted(split - set('-'))
73/67:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/68:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/69:
import string

new_string = '''Someone must have been telling lies about Josef K., he knew he had
done nothing wrong but, one morning, he was arrested.  Every day at
eight in the morning he was brought his breakfast by  Mrs. Grubach's
cook - Mrs. Grubach was his landlady - but today she didn't come.  That
had never happened before.  K. waited a little while, looked from his
pillow at the old woman who lived opposite and who was watching him with
an inquisitiveness quite unusual for her, and finally, both hungry and
disconcert'''

len(new_string) #This counts the number of characters in the string. 

#Characters includes the following : 
# NewLine 
# Punctuation Marks '"", -, ., '
# 

len(new_string.split()) #Answer to Q1

check = set(new_string.split())
len(check - set('-')) #Answer to Q2 

new_string.count(' a ') #Answer to Q3
new_string.count(' the ')

split = set(new_string.split()) #Answer to Q4
sorted(split - set('-'))
73/70:
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/71: results = string.punctuation
73/72: results = string.punctuation
73/73: import string
73/74:
import string 
result = string.punctuation
73/75:
import string 
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/76:
import string 
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/77:
import string 
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()

new_list = [s for s in our_list if s not in string.punctuation]
73/78:
import string 
string = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()
results = string.punctuation

new_list = [s for s in our_list if s not in results]
73/79:
import string 
result = string.punctuation
our_list = string.split()
73/80:
import string 
result = string.punctuation
our_list = string1.split()
73/81:
import string 
string1 = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string.split()
results = string.punctuation

new_list = [s for s in our_list if s not in results]
73/82:
import string 
string1 = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string1.split()

new_list = [s for s in our_list if s not in results]
73/83:
import string 
string1 = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

our_list = string1.split()

new_list = [s for s in our_list if s not in '-']
73/84:
import string 
string1 = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

result = string.punctuation

our_list = string1.split()

new_list = [s for s in our_list if s not in result]
73/85:
import string 
string1 = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

result = string.punctuation

our_list = string1.split()

new_list = [s for s in our_list if s not in result]
len(new_list)
73/86:
import string 
string1 = '''Someone must have been telling lies about Josef K., \n
he knew he had done nothing wrong but, one morning, he was arrested.  Every day at \n
eight in the morning he was brought his breakfast by  Mrs. Grubach's \n
cook - Mrs. Grubach was his landlady - but today she didn't come.  That \n
had never happened before.  K. waited a little while, looked from his \n
pillow at the old woman who lived opposite and who was watching him with \n
an inquisitiveness quite unusual for her, and finally, both hungry and \n
disconcerted, rang the bell.  There was immediately a knock at the door \n
and a man entered.  He had never seen the man in this house before.  He \n
was slim but firmly built, his clothes were black and close-fitting, \n
with many folds and pockets, buckles and buttons and a belt, all of \n
which gave the impression of being very practical but without making it \n
very clear what they were actually for.  "Who are you?" asked K., \n
sitting half upright in his bed.  The man, however, ignored the question \n
as if his arrival simply had to be accepted, and merely replied, "You \n
rang?"  "Anna should have brought me my breakfast," said K.  He tried to \n
work out who the man actually was, first in silence, just through \n
observation and by thinking about it, but the man didn't stay still to \n
be looked at for very long.  Instead he went over to the door, opened it \n
slightly, and said to someone who was clearly standing immediately \n
behind it, "He wants Anna to bring him his breakfast."  There was a \n
little laughter in the neighbouring room, it was not clear from the \n
sound of it whether there were several people laughing.  The strange man \n
could not have learned anything from it that he hadn't known already, \n
but now he said to K., as if making his report "It is not possible." \n
"It would be the first time that's happened," said K., as he jumped out \n
of bed and quickly pulled on his trousers.  "I want to see who that is \n
in the next room, and why it is that Mrs. Grubach has let me be \n
disturbed in this way."  It immediately occurred to him that he needn't \n
have said this out loud, and that he must to some extent have \n
acknowledged their authority by doing so, but that didn't seem important \n
to him at the time.  That, at least, is how the stranger took it, as he \n
said, "Don't you think you'd better stay where you are?"  "I want \n
neither to stay here nor to be spoken to by you until you've introduced \n
yourself."  "I meant it for your own good," said the stranger and opened \n
the door, this time without being asked.  The next room, which K. \n
entered more slowly than he had intended, looked at first glance exactly \n
the same as it had the previous evening.  It was Mrs. Grubach's living \n
room, over-filled with furniture, tablecloths, porcelain and \n
photographs.  Perhaps there was a little more space in there than usual \n
today, but if so it was not immediately obvious, especially as the main \n
difference was the presence of a man sitting by the open window with a \n
book from which he now looked up.  "You should have stayed in your room! \n
Didn't Franz tell you?"  "And what is it you want, then?" said K., \n
looking back and forth between this new acquaintance and the one named \n
Franz, who had remained in the doorway.  Through the open window he \n
noticed the old woman again, who had come close to the window opposite \n
so that she could continue to see everything.  She was showing an \n
inquisitiveness that really made it seem like she was going senile. "I \n
want to see Mrs. Grubach ...," said K., making a movement as if tearing \n
himself away from the two men - even though they were standing well away \n
from him - and wanted to go.  "No," said the man at the window, who \n
threw his book down on a coffee table and stood up.  "You can't go away \n
when you're under arrest."  "That's how it seems," said K.  "And why am \n
I under arrest?" he then asked.  "That's something we're not allowed to \n
tell you.  Go into your room and wait there.  Proceedings are underway \n
and you'll learn about everything all in good time.  It's not really \n
part of my job to be friendly towards you like this, but I hope no-one, \n
apart from Franz, will hear about it, and he's been more friendly \n
towards you than he should have been, under the rules, himself.  If you \n
carry on having as much good luck as you have been with your arresting \n
officers then you can reckon on things going well with you."  K. wanted \n
to sit down, but then he saw that, apart from the chair by the window, \n
there was nowhere anywhere in the room where he could sit.  "You'll get \n
the chance to see for yourself how true all this is," said Franz and \n
both men then walked up to K.  They were significantly bigger than him, \n
especially the second man, who frequently slapped him on the shoulder. \n
The two of them felt K.'s nightshirt, and said he would now have to wear \n
one that was of much lower quality, but that they would keep the \n
nightshirt along with his other underclothes and return them to him if \n
his case turned out well.'''

result = string.punctuation

our_list = string1.split()

new_list = [s for s in our_list if s not in result]
new_list
73/87: from string import ascii letters
73/88: from string import ascii_letters
73/89:
from string import ascii_letters 

letters = set(ascii_letters + ' ')
73/90:
from string import ascii_letters 

letters = set(ascii_letters + ' ')
letters
72/5:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too.
72/6:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
72/7:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch
72/8:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
72/9:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list]
72/10:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude.
72/11:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
72/12:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']
72/13:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(lxt_list_clean)
print(total_words)
72/14:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(txt_list_clean)
print(total_words)
72/15:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(txt_list_clean)
print(total_words)

txt
72/16:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(txt_list_clean)
print(total_words)

txt_list_clean()
72/17:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(txt_list_clean)
print(total_words)

txt_list_clean
72/18:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(txt_list_clean)
print(total_words)

set(txt_list_clean)
72/19:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 

unique_ch = set(txt.split())
unique_ch #This is a way for us to check what all characters to exclude. 

txt_list = txt.split()
txt_list_clean = [s for s in txt_list if s != '-' and s != '...,"']

total_words = len(txt_list_clean)
print(total_words)
72/20:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

unique_ch
72/21:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string
72/22:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

unique_words = set()
for line in txt : 
    line = " ".join([s for s in line if s not in string.punctuation])
    unique_words.update(line)
72/23:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

unique_words = set()
for line in txt : 
    line = " ".join([s for s in line if s not in string.punctuation])
    unique_words.update(line)
    
unique_words
72/24:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

unique_words = set()
for line in txt : 
    line = "".join([s for s in line if s not in string.punctuation])
    unique_words.update(line)
    
unique_words
72/25:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

unique_words = set()
for line in txt : 
    line = "".join([s for s in line if s not in string.punctuation])
    line = line.split()
    unique_words.update(line)
    
unique_words
72/26:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

unique_words = set()
for line in txt : 
    line = "".join([s for s in line if s not in string.punctuation])
    line = [word.lower() for word in line.split()]
    unique_words.update(line)
    
unique_words
72/27:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanuum = txt.translate(None, string.punctuation)
72/28:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanuum = txt.translate(str.maketrans('', string.punctuation))
72/29:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanuum = txt.translate(str.maketrans('', '', string.punctuation))
72/30:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanuum = txt.translate(str.maketrans('', '', string.punctuation))

txt_alphanum
72/31:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))

txt_alphanum
72/32:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))

unqiue_words = set(txt_alphanum.split())
72/33:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))

unqiue_words = set(txt_alphanum.split())
unique_words
72/34:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))

txt_alphanum.split()
72/35:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanu.lowercase()
72/36:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lowercase()
72/37:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
72/38:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
txt_alphanum_lower
72/39:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
txt_alphanum_lower.split()
72/40:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
set(txt_alphanum_lower.split())
72/41:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
unique_words = len(set(txt_alphanum_lower.split()))
72/42:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
unique_words = len(set(txt_alphanum_lower.split()))
print(unique_words)
72/43:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
total_words = len(txt_alphanum_lower.split())
unique_words = len(set(txt_alphanum_lower.split()))
print(unique_words)
72/44:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
total_words = len(txt_alphanum_lower.split())
unique_words = len(set(txt_alphanum_lower.split()))
print('Total words :' total_words)
print(unique_words)
72/45:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
total_words = len(txt_alphanum_lower.split())
unique_words = len(set(txt_alphanum_lower.split()))
print('Total words :' total_words)
print('Unique words :' unique_words)
72/46:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
total_words = len(txt_alphanum_lower.split())
unique_words = len(set(txt_alphanum_lower.split()))
print(total_words)
print(unique_words)
72/47:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum_lower = txt_alphanum.lower()
total_words = len(txt_alphanum_lower.split())
unique_words = len(set(txt_alphanum_lower.split()))
print(total_words)
print(unique_words)
72/48:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
72/49:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
txt_alphanum
72/50:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())
72/51:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())
print(total_words)
72/52:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())
print(total_words)

txt_alphanum.split()
72/53:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())
print("The total number of words in the text are :" total_words)
72/54:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())
print("The total number of words in the text are :" + total_words)
72/55:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are :" total_words)
72/56:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are :" + str(total_words))
72/57:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are :" + \t str(total_words))
72/58:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are :" + /t str(total_words))
72/59:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are : " + str(total_words))
72/60:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

txt_alphanum_lower = txt_alphanum.lower()
unique_words = len(set(txt_alphanum_lower.split()))

print("The total number of unique words in the text are : " + str(unique_words))
72/61: set(txt_alphanum_lower.split())
72/62:
set(txt_alphanum_lower.split())
txt_alphanum
72/63:
set(txt_alphanum_lower.split())
txt_alphanum.split()
72/64:
unique_words = set()

for line in txt:
    words = ''.join(filter(lambda x: x.isalpha() or x.isspace(), line)).split()
    unique_words.update(words)
72/65:
unique_words = set()

for line in txt:
    words = ''.join(filter(lambda x: x.isalpha() or x.isspace(), line)).split()
    unique_words.update(words)

    len(unique_words)
72/66:
unique_words = set()

for line in txt:
    words = ''.join(filter(lambda x: x.isalpha() or x.isspace(), line)).split()
    unique_words.update(words)

len(unique_words)
72/67:
# Enter your answer to Problem 3 here. 

word_count_txt = dict{'the' : txt_alphanum_lower.count('the')}
72/68:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the')}
72/69:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the')}
word_count_txt['the']
72/70:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum.count('a')}
word_count_txt['the']
72/71:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum.count('a')}
word_count_txt['a']
72/72:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count('a')}
word_count_txt['a']
72/73:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count('a')}
word_count_txt['a']
72/74:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count('a')}
word_count_txt['a']
72/75:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count('A')}
word_count_txt['a']
72/76:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count('ab')}
word_count_txt['a']
72/77:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count('ab')}
word_count_txt['a']

txt_alphanum_lower
72/78:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count('the'), 'a' : txt_alphanum_lower.count(' ab ')}
word_count_txt['a']
72/79:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count(' the '), 'a' : txt_alphanum_lower.count(' a ')}
word_count_txt['a']
72/80:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count(' the '), 'a' : txt_alphanum_lower.count(' a ')}
word_count_txt['the']
72/81:
# Enter your answer to Problem 3 here. 

word_count_txt = {'the' : txt_alphanum_lower.count(' the '), 'a' : txt_alphanum_lower.count(' a ')}
word_count_txt['a']
72/82:
# Enter your answer to Problem 3 here. 


txt_alphanum_lower.split() = word_list
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a')}
word_count_txt['a']
72/83:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a')}
word_count_txt['a']
72/84:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a')}
word_count_txt['the']
72/85:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}
word_count_txt['the']
72/86:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

word_count_txt
72/87:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key, value in word_count_txt : 
    print key, value
72/88:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key, value in word_count_txt : 
    print (key, value)
72/89:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (i : word_count_txt[i] \n)
72/90:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (i ':' word_count_txt[i] \n)
72/91:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key ':' word_count_txt[key] \n)
72/92:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key : word_count_txt[key] \n)
72/93:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key, word_count_txt[key] \n)
72/94:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key, word_count_txt[key])
72/95:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key, ':' word_count_txt[key])
72/96:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key, ':', word_count_txt[key])
72/97:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key,':', word_count_txt[key])
72/98: word_list.count('k')
72/99: word_list
72/100:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split(
72/101:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
72/102:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
len(word_list_unique)
72/103:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)
72/104:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

word_list_unique_sorted
72/105:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

word_list_unique_sorted[10]
72/106:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

word_list_unique_sorted[0:11]
72/107:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

word_list_unique_sorted[0:10]
72/108: word_list_unique_sorted[len(word_list_unique_sorted : -10)]
72/109: word_list_unique_sorted[len(word_list_unique_sorted) : -10]
72/110: word_list_unique_sorted[-10 : len(word_list_unique_sorted)]
72/111: word_list_unique_sorted[-10 : len(word_list_unique_sorted)].reverse()
72/112: word_list_unique_sorted.reverse()
72/113: word_list_unique_sorted.reverse()
72/114: print(word_list_unique_sorted.reverse())
72/115:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

word_list_unique_sorted[0:10]
72/116: print(word_list_unique_sorted.reverse())
72/117:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print(word_list_unique_sorted)
72/118: print(word_list_unique_sorted.reverse())
72/119: rev = word_list_unique_sorted.reverse()
72/120:
rev = word_list_unique_sorted.reverse()
rev
72/121:
rev = word_list_unique_sorted.reverse()
print(rev)
72/122:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print(word_list_unique_sorted[0:10])
72/123:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('alphabetic order :', word_list_unique_sorted[0:10]
     'reverse alphabetic order :', word_list_unique_sorted[::-1])
72/124:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('alphabetic order :', word_list_unique_sorted[0:10], \n
      'reverse alphabetic order :', word_list_unique_sorted[::-1])
72/125:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('alphabetic order :', word_list_unique_sorted[0:10], '\n'
      'reverse alphabetic order :', word_list_unique_sorted[::-1])
72/126:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('alphabetic order :', word_list_unique_sorted[0:10], '\n'
      'reverse alphabetic order :', word_list_unique_sorted[:10:-1])
72/127:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('alphabetic order :', word_list_unique_sorted[0:10], '\n'
      'reverse alphabetic order :', word_list_unique_sorted[:-10:-1])
72/128:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('alphabetic order :', word_list_unique_sorted[0:10], '\n'
      'reverse alphabetic order :', word_list_unique_sorted[:-11:-1])
72/129: word_list_unique_sorted.reverse()
72/130:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic order :', word_list_unique_sorted[0:10], '\n'
      'Reverse alphabetic order :', word_list_unique_sorted[:-11:-1])
72/131:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic order :', word_list_unique_sorted[:-11:-1])
72/132:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/133:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/134:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt.alphanum.lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/135:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/136:
# Enter your answer to Problem 4 here. 

word_list_unique = set(txt.lower().split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/137:
# Enter your answer to Problem 4 here. 

avoid = '", \, ., ;'

txt.translate(str.maketranslate('', '', avoid))

word_list_unique = set(txt.lower().split()) - set('"', '-', '.', '')
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/138:
# Enter your answer to Problem 4 here. 

avoid = '", \, ., ;'

txt.translate(str.maketrans('', '', avoid))

word_list_unique = set(txt.lower().split()) - set('"', '-', '.', '')
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/139:
# Enter your answer to Problem 4 here. 

avoid = '", \, ., ;'

txt.translate(str.maketrans('', '', avoid))

word_list_unique = set(txt.lower().split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/140:
# Enter your answer to Problem 4 here. 

avoid = '", \, ., ;'

txt_q4 = txt.translate(str.maketrans('', '', avoid))

word_list_unique = set(txt_q4.lower().split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/141:
# Enter your answer to Problem 4 here. 

avoid = '", \, ., ;'

txt_q4 = txt.translate(str.maketrans(' ', ' ', avoid))

word_list_unique = set(txt_q4.lower().split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/142:
# Enter your answer to Problem 4 here. 

avoid = ", ., 

txt_q4 = txt.translate(str.maketrans('', '', avoid))

word_list_unique = set(txt_q4.lower().split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/143:
# Enter your answer to Problem 4 here. 

avoid = '''", ., ;  ''' 

txt_q4 = txt.translate(str.maketrans('', '', avoid))

word_list_unique = set(txt_q4.lower().split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
72/144:
# Enter your answer to Problem 4 here. 


word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
74/1: txt.isnum()
74/2:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are : " + str(total_words))
74/3: txt.isnum()
74/4:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

txt_alphanum_lower = txt_alphanum.lower()
unique_words = len(set(txt_alphanum_lower.split()))

print("The total number of unique words in the text are : " + str(unique_words))
74/5:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key,':', word_count_txt[key])
74/6:
# Enter your answer to Problem 4 here. 


word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
74/7:
# Enter your answer to Problem 4 here. 


word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], 
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
74/8:
# Enter your answer to Problem 4 here. 


word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
75/1:
# Open the file and get the text into a string variable called txt
with open('kafka_trial.txt') as f:
    txt = f.read()
print(txt[:500]) # Show the first 500 characters of the txt variable

# Enter your answer to Problem 1 below. 

#We check if the string contains any characters apart from alphabets and numbers using isalnum()
is_alpha_numeric = txt.isalnum()
print(is_alpha_numeric)

#Thus we know that the text contains other characters too. 
import string 

txt_alphanum = txt.translate(str.maketrans('', '', string.punctuation))
total_words = len(txt_alphanum.split())

print("The total number of words in the text are : " + str(total_words))
75/2:
# Enter your answer to Problem 2 here. Note that you can reuse code
# from any code cells above, as long as you have run the code 
# previously in the current kernel session.

txt_alphanum_lower = txt_alphanum.lower()
unique_words = len(set(txt_alphanum_lower.split()))

print("The total number of unique words in the text are : " + str(unique_words))
75/3:
# Enter your answer to Problem 3 here. 


word_list = txt_alphanum_lower.split()
word_count_txt = {'the' : word_list.count('the'), 'a' : word_list.count('a'), 'and' : word_list.count('and'), 'man' : word_list.count('man'), 'time' : word_list.count('time')}

for key in word_count_txt : 
    print (key,':', word_count_txt[key])
75/4:
# Enter your answer to Problem 4 here. 


word_list_unique = set(txt_alphanum_lower.split())
word_list_unique_sorted = sorted(word_list_unique)

print('Alphabetic Order :', word_list_unique_sorted[0:10], '\n'
      'Reverse Alphabetic Order :', word_list_unique_sorted[:-11:-1])
76/1:
# Write a program that takes input X from the user about their 
# favorite dessert and responds "I love X too!", "Oh no, I can't stand X!", 
# or "Oh really, I've never had X!" depending on whether 
# the input is in my_faves and my_hates

my_faves = ['ice cream', 'cake']
my_hates = ['rice pudding', 'spotted dick', 'mince pie', 'lardy cake', 'syllabub']

your_fave = input('What is your favorite dessert? ')

if your_fav in my_faves : 
    print('I love', x ,'too')
elif your_fav in my_hates : 
    print('Cant stand', x)
else : 
    print('Ive never had', x)
76/2:
# Write a program that takes input X from the user about their 
# favorite dessert and responds "I love X too!", "Oh no, I can't stand X!", 
# or "Oh really, I've never had X!" depending on whether 
# the input is in my_faves and my_hates

my_faves = ['ice cream', 'cake']
my_hates = ['rice pudding', 'spotted dick', 'mince pie', 'lardy cake', 'syllabub']

your_fave = input('What is your favorite dessert? ')

if your_fav in my_faves : 
    print('I love', your_fav ,'too')
elif your_fav in my_hates : 
    print('Cant stand', your_fav)
else : 
    print('Ive never had', your_fav)
76/3:
# Write a program that takes input X from the user about their 
# favorite dessert and responds "I love X too!", "Oh no, I can't stand X!", 
# or "Oh really, I've never had X!" depending on whether 
# the input is in my_faves and my_hates

my_faves = ['ice cream', 'cake']
my_hates = ['rice pudding', 'spotted dick', 'mince pie', 'lardy cake', 'syllabub']

your_fave = input('What is your favorite dessert? ')

if your_fav in my_faves : 
    print('I love', your_fave ,'too')
elif your_fav in my_hates : 
    print('Cant stand', your_fave)
else : 
    print('Ive never had', your_fave)
76/4:
# Write a program that takes input X from the user about their 
# favorite dessert and responds "I love X too!", "Oh no, I can't stand X!", 
# or "Oh really, I've never had X!" depending on whether 
# the input is in my_faves and my_hates

my_faves = ['ice cream', 'cake']
my_hates = ['rice pudding', 'spotted dick', 'mince pie', 'lardy cake', 'syllabub']

your_fave = input('What is your favorite dessert? ')

if your_fave in my_faves : 
    print('I love', your_fave ,'too')
elif your_fave in my_hates : 
    print('Cant stand', your_fave)
else : 
    print('Ive never had', your_fave)
76/5:
mylist1 = ['a', 'b', 'c', 'd']
mylist2 = [1, 2, 3, 4]
for i in range(len(mylist1)):
     print(mylist1[i] + str(mylist2[i]), end='')
76/6:
mylist1 = ['a', 'b', 'c', 'd']
mylist2 = [1, 2, 3, 4]
for i in range(len(mylist1)):
     print(mylist1[i] + str(mylist2[i]), end=' ')
76/7:
mylist1 = ['a', 'b', 'c', 'd']
mylist2 = [1, 2, 3, 4]
for i in range(len(mylist1)):
     print(mylist1[i] + str(mylist2[i]), end=',')
76/8:
mylist1 = ['a', 'b', 'c', 'd']
mylist2 = [1, 2, 3, 4]
for i in range(len(mylist1)):
     print(mylist1[i] + str(mylist2[i]), end=', ')
76/9:
mylist1 = ['a', 'b', 'c', 'd']
mylist2 = [1, 2, 3, 4]
for i in range(len(mylist1)):
     print(mylist1[i] + str(mylist2[i]), end=' ')
76/10:
for i in range(1,5) : 
        print ('*'*i)
76/11:
for i in range(1,6) : 
        print ('*'*i)
76/12:
i=1 

while i=5 : 
    print('*' * i)
    i += 1
76/13:
i=1 

while (i=5) : 
    print('*' * i)
    i += 1
76/14:
i=1 

while i==5 : 
    print('*' * i)
    i += 1
76/15:
i=1 

while i==5 : 
    print('*' * i)
    i += 1
76/16:
i=1 

while i==5 : 
    print('*' * i)
    i += 1
76/17:
i=1 

while i==5 : 
    print('*' * i)
    i += 1
79/1:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = []
for i in new_list : 
    if (new_list[i]+1) % 3 == 0 : 
        new_list.apppend('boo')
    else new_list.append(i+1)
79/2:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = []
for i in new_list : 
    if (new_list[i]+1) % 3 == 0 : 
        new_list.apppend('boo')
    else :
        new_list.append(i+1)
79/3:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = []
for i in new_list : 
    if (new_list[i]+1) % 3 == 0 : 
        new_list.apppend('boo')
    else :
        new_list.append(i+1)

new_list
79/4:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(0,101))
79/5:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(0,101))
new_list
79/6:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))
new_list
79/7:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))
for index in new_list : 
    if index % 3 == 0 :
        new_list[i] = 'boo'
79/8:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))
for index in new_list : 
    if index % 3 == 0 :
        new_list[index] = 'boo'
79/9:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index] = 'boo'
79/10:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index] = 'boo'

print(new_list)
79/11:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'

print(new_list)
79/12:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'

new_list2 = ['boo' if i%3 = 0 else i for i in range(1,101)]
print(new_list2)
79/13:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'

new_list2 = ['boo' if i%3 == 0 else i for i in range(1,101)]
print(new_list2)
79/14:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'

new_list2 = ['boo' if i%3 == 0 else i for i in range(1,101)]
print(new_list2)

new_list3 = []

for i in range(1,101) : 
    if i%3 != 0 : 
        new_list3.append(i)
    else : 
        new_list3.append('boo')
79/15:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'

new_list2 = ['boo' if i%3 == 0 else i for i in range(1,101)]


new_list3 = []

for i in range(1,101) : 
    if i%3 != 0 : 
        new_list3.append(i)
    else : 
        new_list3.append('boo')
print(new_list3)
79/16:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'

new_list2 = ['boo' if i%3 == 0 else i for i in range(1,101)]


new_list3 = []

for i in range(1,101) : 
    if i%3 != 0 : 
        new_list3.append(i)
    else : 
        new_list3.append('boo')
        
print(new_list3)
79/17:
# Exercise 1: Create a list that contains all integers from 1 to 100 (inclusive), 
# except that it has the string 'boo' for every integer that is divisible by 3 
# Your list should look like: [1, 2, 'boo', 4, 5, 'boo', 7, 8, 'boo', 10, ...]

# ADVANCED: Try and complete the task with a list comprehension

#Method 1
new_list  = list(range(1,101))

for index in range(1,100) : 
    if index % 3 == 0 : 
        new_list[index - 1] = 'boo'
        
#Method 2 - List Comprehension
new_list2 = ['boo' if i%3 == 0 else i for i in range(1,101)]


#Method 3 - Most efficient
new_list3 = []

for i in range(1,101) : 
    if i%3 != 0 : 
        new_list3.append(i)
    else : 
        new_list3.append('boo')
79/18:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]

summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i
79/19:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]

summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i 
summ()
79/20:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]

summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i 
summ
79/21:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
 
#Method 1
summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i 
summ

#Method 2

sum2 = sum(i for i in lst if i%2 == 0)
79/22:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
 
#Method 1
summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i 
summ

#Method 2

sum2 = sum(i for i in lst if i%2 == 0)
sum2
79/23:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
 
#Method 1
summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i 

#Method 2

sum2 = sum(i for i in lst if i%2 == 0)
sum2
79/24:
# Exercise 2: Sum the even integers from the list below.
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
 
#Method 1
summ = 0 

for i in lst : 
    if i%2 == 0 : 
        summ += i 

#Method 2

sum2 = sum(i for i in lst if i%2 == 0)
79/25:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n^2 for n in lst]
79/26:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n^^2 for n in lst]
79/27:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n*n for n in lst]
79/28:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n*n for n in lst]
lst2
79/29:
# Exercise 4: Consider the lists x and y below. Using a list comprehension,
# create a list that contains all combinations of (elem_x, elem_y) 
# such that elem_x + elem_y = 6
# Your answer should look as follows: [(0, 6), (1, 5), (2, 4), (3, 3)]
x = [0, 1, 2, 3]
y = [3, 4, 5, 6]

lst_new = [(a,b) for a,b in x,y if a+b =6]
79/30:
# Exercise 4: Consider the lists x and y below. Using a list comprehension,
# create a list that contains all combinations of (elem_x, elem_y) 
# such that elem_x + elem_y = 6
# Your answer should look as follows: [(0, 6), (1, 5), (2, 4), (3, 3)]
x = [0, 1, 2, 3]
y = [3, 4, 5, 6]

lst_new = [(a,b) for a in x for b in y if a+b =6]
79/31:
# Exercise 4: Consider the lists x and y below. Using a list comprehension,
# create a list that contains all combinations of (elem_x, elem_y) 
# such that elem_x + elem_y = 6
# Your answer should look as follows: [(0, 6), (1, 5), (2, 4), (3, 3)]
x = [0, 1, 2, 3]
y = [3, 4, 5, 6]

lst_new = [(a,b) for a in x for b in y if a+b == 6]
79/32:
# Exercise 4: Consider the lists x and y below. Using a list comprehension,
# create a list that contains all combinations of (elem_x, elem_y) 
# such that elem_x + elem_y = 6
# Your answer should look as follows: [(0, 6), (1, 5), (2, 4), (3, 3)]
x = [0, 1, 2, 3]
y = [3, 4, 5, 6]

lst_new = [(a,b) for a in x for b in y if a+b == 6]
lst_new
79/33:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], [i for i in sequence if i != 0 and i!= 1 and i!= 2]]
79/34:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2
79/35:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n*n for n in lst if type(i) == int]
lst2
79/36:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n*n for n in lst if type(i) == int]
lst2
79/37:
# Exercise 3: Using a list comprehension, create a new list containing 
# the squares of the integers in the list below
lst = [1, 3, 2, 4.5, 7, 8, 10, 3, 5, 4, 7, 3.33]
lst2 = [n*n for n in lst if type(n) == int]
lst2
79/38:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2
79/39:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


ans = [list(range(i,4) for i in range 4)]
79/40:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


ans = [list(range(i,4) for i in range(4))]
79/41:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


ans = [list(range(i,4) for i in range(4)]
ans
79/42:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


ans = [list(range(i,4) for i in range(4))]
ans
79/43:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


ans = [list(range(i,4) for i in range(4))]
print(ans)
79/44:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


ans = [list(range(1,4) for i in range(4))]
print(ans)
79/45:
# Exercise 5: Using nested list comprehensions and range(), create a list 
# that looks as follows: [[0, 1, 2, 3], [1, 2, 3], [2, 3], [3]]

sequence = range(0,4)

lst_new2 = [[i for i in sequence], [i for i in sequence if i != 0], 
            [i for i in sequence if i!=0 and i!= 1], 
            [i for i in sequence if i != 0 and i!= 1 and i!= 2]]

lst_new2


#Check the answers for this one
80/1:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
80/2:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
txt
80/3:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
print(txt[:500])
80/4:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
print(txt[:500])

lst = []

for line in open('ca-GrQc.txt', 'r'): 
    do lst.append([line[1] : line[3]])
80/5:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
print(txt[:500])

lst = []

for line in open('ca-GrQc.txt', 'r'): 
    lst.append([line[1] : line[3]])
80/6:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
print(txt[:500])

lst = []

for line in open('ca-GrQc.txt', 'r'): 
    lst.append([line[1] ':' line[3]])
80/7:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
print(txt[:500])

lst = []

for line in open('ca-GrQc.txt', 'r'): 
    lst.append([line[1], ':', line[3]])
80/8:
# Enter your answer to Problem 1 here. 
with open('ca-GrQc.txt') as f : 
    txt = f.read()
    
print(txt[:500])

lst = []

for line in open('ca-GrQc.txt', 'r'): 
    lst.append([line[1], ':', line[3]])
lst
80/9:
# Enter your answer to Problem 1 here. 


lst = []

for line in open('ca-GrQc.txt', 'r')[4:]: 
    print(line)
80/10:
# Enter your answer to Problem 1 here. 


lst = []

for line in open('ca-GrQc.txt', 'r'): 
    print(line)
80/11:
# Enter your answer to Problem 1 here. 


lst = []

for line in next(open('ca-GrQc.txt', 'r')): 
    print(line)
80/12:
# Enter your answer to Problem 1 here. 


lst = []

for line in open('ca-GrQc.txt', 'r'): 
    print(line)
80/13:
# Enter your answer to Problem 1 here. 


lst = []

for line in open('ca-GrQc.txt', 'r'): 
    print(line[4:])
80/14:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r')[4:) ]: 
             print(line)
80/15:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r')[4: ]): 
             print(line)
80/16:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r')[4:]): 
             print(line)
80/17:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r'))[4:]: 
             print(line)
80/18:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r')) :
    next(line) 
    print(line)
80/19:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r')) :
    print(line)
80/20:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r'))[4:] :
    print(line)
80/21:
# Enter your answer to Problem 1 here. 


lst = []

for line in (open('ca-GrQc.txt', 'r'))[4::] :
    print(line)
80/22:
# Enter your answer to Problem 1 here. 


lst = []

for line, index in (open('ca-GrQc.txt', 'r')) :
    if line[index] > 4
    print(line)
80/23:
# Enter your answer to Problem 1 here. 


lst = []

for line, index in (open('ca-GrQc.txt', 'r')) :
    if line[index] > 4 :
    print(line)
80/24:
# Enter your answer to Problem 1 here. 


lst = []

for line, index in (open('ca-GrQc.txt', 'r')) :
    if line[index] > 4 :
        print(line)
80/25:
# Enter your answer to Problem 1 here. 


lst = []

for line, index in open('ca-GrQc.txt', 'r') :
    if line[index] > 4 :
        print(line)
80/26:
# Enter your answer to Problem 1 here. 


with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    for line in f : 
        print(f)
80/27:
# Enter your answer to Problem 1 here. 


with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    for line in f : 
        print(line)
80/28:
# Enter your answer to Problem 1 here. 


with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        print(line)
80/29:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_part = line.partition('\t')
        line.append([line_part[0], ':', line_part[1]])
80/30:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        line.split()
        print(line)
80/31:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        print(line.split())
80/32:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_lst = line.split()
        lst.append(line_lst[0], ':', line_lst[1])
80/33:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_lst = line.split()
        lst.append(line_lst)
80/34:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_lst = line.split()
        lst.append(line_lst)

print(lst)
80/35:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_lst = line.split()
        lst.append(line_lst)

print(lst)
80/36:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_lst = line.split().asnumeric()
        lst.append(line_lst)

print(lst)
80/37:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line]
        lst.append(line_lst)

print(lst)
80/38:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t']
        lst.append(line_lst)

print(lst)
80/39:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        lst.append(line_lst)

print(lst)
80/40:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
80/41:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t']
80/42:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        print(line)
80/43:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)
80/44:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

        print(lst)
82/1:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

lst
82/2:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        print(line_list)
82/3:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        [int(x) for x in line_lst if x != '\t' and x != '\n']
        print(line_list)
82/4:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        [int(x) for x in line_list if x != '\t' and x != '\n']
        print(line_list)
82/5:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        print(line_list)
82/6:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_lst)
82/7:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)
82/8:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst)
82/9:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst, end = '')
82/10:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst, end = ' ')
82/11:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst, end = '\n')
82/12:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst, end = ',')
82/13:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst)
80/45:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

print(lst)
80/46:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

print(lst)
80/47:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

lst
80/48:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

lst
80/49:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    for line in f : 
        [int(x) for x in line if x != '\t' and x != '\n']
        line_list = line.split()
        lst.append(line_list)

lst
    
    5+6
82/14:
# Enter your answer to Problem 2 here. 

for line in f : 
    print(line)
82/15:
# Enter your answer to Problem 2 here. 

authors_lst = [lst[1[1]]]
82/16:
# Enter your answer to Problem 2 here. 

authors_lst = [edge[1] for edge in lst]
82/17:
# Enter your answer to Problem 2 here. 

authors_lst = [edge[1] for edge in lst]
authors_lst
82/18:
# Enter your answer to Problem 2 here. 

authors_lst = [edge[0] for edge in lst]
authors_lst
82/19:
# Enter your answer to Problem 2 here. 

authors_lst = [edge[0] for edge in lst]
authors_lst.unique()
82/20:
# Enter your answer to Problem 2 here. 

authors_lst = set([edge[0] for edge in lst])
82/21:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
82/22:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
authors_lst
82/23:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
82/24:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are', len(authors_lst))
82/25:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are', ':', len(authors_lst))
82/26:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
82/27:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
{key, value for key, value in authors_lst}
82/28:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key, value for key, value in authors_lst}
82/29:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : value for key, value in authors_lst}
82/30:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : value for key in authors_lst}
82/31:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : {} for key in authors_lst}
82/32:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : {} for key in authors_lst}
print(authors_dct)
82/33:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}
print(authors_dct)
82/34:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}
print(authors_dct[key])
82/35:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}
print(authors_dct[0])
82/36:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.items : 
    print [key]
82/37:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.items() : 
    print [key]
82/38:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.items() : 
    print (key)
82/39:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.keys() : 
    print (key)
82/40:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.keys() : 
    print ([key])
82/41:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.keys() : 
    print list(key)
82/42:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

for key in authors_dct.keys() : 
    print (list(key))
82/43:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_dct.keys()
82/44:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = authors_dct.keys()
82/45:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = authors_dct.keys()
print(authors_dct[10])
82/46:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = authors_dct.keys()
print(authors_dct[0:10])
82/47:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = authors_dct.keys()
print(authors_lst_from_dct[0:10])
82/48:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = authors_dct.keys()
print(authors_lst_from_dct[0:10])
82/49:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = authors_dct.keys()
print(authors_lst_from_dct)
82/50:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = list(authors_dct.keys())
print(authors_lst_from_dct)
82/51:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])
print('Total number of authors in the dataset are :', len(authors_lst))
authors_dct = {key : [] for key in authors_lst}

authors_lst_from_dct = list(authors_dct.keys())
print(authors_lst_from_dct[0:10])
82/52:
# Enter your answer to Problem 3 here. 

[authors_dct[keys] = 1 for keys in authors_dct]
82/53:
# Enter your answer to Problem 3 here. 

[authors_dct[keys] = 1 for keys in authors_dct.keys()]
82/54:
# Enter your answer to Problem 3 here. 

{authors_dct[keys] = 1 for keys in authors_dct.keys()}
82/55:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    print(keys)
82/56:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct[keys] = 1
82/57:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct[keys] = 1
authors_dct
82/58:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    
authors_dct = {authors_dct[keys] = 1 for keys in authors_dct}
82/59:
# Enter your answer to Problem 3 here. 

    
authors_dct = {authors_dct[keys] = 1 for keys in authors_dct}
82/60:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct[keys] = [element[1] for element in list if element[0] = keys]
82/61:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct[keys] = [element[1] for element in list if element[0] == keys]
82/62:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct[keys] = element[1] for element in list if element[0] == keys
82/63:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct[keys] = [element[1] for element in list if element[0] == keys]
82/64:
# Enter your answer to Problem 3 here. 

for keys in authors_dct : 
    authors_dct.update({keys : [element[1] for element in list if element[0] == keys]})
82/65:
# Enter your answer to Problem 3 here. 

authors_dct.update({keys : [element[1] for element in list if element[0] == keys]})
82/66:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in list if element[0] == keys] for keys in authors_dct}
82/67:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys] for keys in authors_dct}
82/68:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys] for keys in authors_dct}
authors_dct
82/69:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys] for keys in authors_dct}
authors_dct
82/70:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys] for keys in authors_dct}
authors_dct
83/1:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys] for keys in authors_dct}
authors_dct
83/2:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst)
83/3:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])

print('Total number of authors in the dataset are :', len(authors_lst))

authors_dct = {key : [] for key in authors_lst}
authors_lst_from_dct = list(authors_dct.keys())
print(authors_lst_from_dct[0:10])
83/4:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys] for keys in authors_dct}
authors_dct
83/5:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys and element[1] != keys] for keys in authors_dct}
authors_dct
83/6:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}
authors_dct
83/7:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}
authors_dct[0:10]
83/8:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

authors_dct.items(10)
83/9:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dict[keys] for keys in authors_lst[0:10]]
83/10:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dict[keys] for keys in authors_lst[0:10]]
print(coauthors_lst)
83/11:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dct[keys] for keys in authors_lst[0:10]]
print(coauthors_lst)
84/1:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f)
    
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst)
84/2:
# Enter your answer to Problem 2 here. 

authors_lst = list(set([edge[0] for edge in lst]))
print(authors_lst[0:10])

print('Total number of authors in the dataset are :', len(authors_lst))

authors_dct = {key : [] for key in authors_lst}
authors_lst_from_dct = list(authors_dct.keys())
print(authors_lst_from_dct[0:10])
84/3:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dct[keys] for keys in authors_lst[0:10]]
print(coauthors_lst)
84/4:
# Enter your answer to Problem 4 here. 

max(coauthors)
84/5:
# Enter your answer to Problem 4 here. 

max(coauthors_lst)
84/6:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
84/7:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])

max_coauthors
84/8:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
        print(key : max_coauthors)
84/9:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
        print(key, ':', max_coauthors)
84/10:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
    
print(key, ':', max_coauthors)
84/11:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors :', max_coauthors)
84/12:
# Enter your answer to Problem 4 here. 

max_coauthors = 0 

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/13:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dct[keys] for keys in authors_lst[0:10]]
print(coauthors_lst)

authors_dct[26196]
84/14:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dct[keys] for keys in authors_lst[0:10]]
print(coauthors_lst)

authors_dct[26196]
84/15:
# Enter your answer to Problem 3 here. 

authors_dct = {keys : [element[1] for element in lst 
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors_lst = [authors_dct[keys] for keys in authors_lst[0:10]]
print(coauthors_lst)
84/16: authors_dct[26196]
84/17: len(authors_dct[26196])
84/18:
for key in authors_dct : 
    print(key)
84/19:
# Enter your answer to Problem 4 here. 

max_coauthors = None

for key in authors_dct : 
    if len(authors_dct[key]) >= max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/20:
# Enter your answer to Problem 4 here. 

max_coauthors = None

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/21: max(coauthors_lst)
84/22:
max_value = 0 
for lst in coauthors_lst : 
    if len(lst) >= max_value : 
        max_value = len(lst)
84/23:
max_value = 0 
for lst in coauthors_lst : 
    if len(lst) >= max_value : 
        max_value = len(lst)

        print(max_value)
84/24:
max_value = 0 
for lst in coauthors_lst : 
    if len(lst) >= max_value : 
        max_value = len(lst)

print(max_value)
84/25:
max_value = 0 
for lst in [authors_dct[keys] for keys in authors_lst] : 
    if len(lst) >= max_value : 
        max_value = len(lst)

print(max_value)
84/26:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key])
        max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/27:
max_value = 0 
for lst in [authors_dct[keys] for keys in authors_lst] : 
    if len(lst) >= max_value : 
        max_value = len(lst)
        author_ID = keys

print(max_value)
print(len(authors_dct[26196]))
84/28:
max_value = 0 
for lst in [authors_dct[keys] for keys in authors_lst] : 
    if len(lst) >= max_value : 
        max_value = len(lst)
        

print(max_value)
print(len(authors_dct[26196]))
84/29:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key]) and max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/30:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key]) 
        max_coauthors_author = key
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/31:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key]) 
        
max_coauthors_author = [key for key in authors_dct if authors_dct[key] = max_coauthors]
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/32:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key]) 
        
max_coauthors_author = [key for key in authors_dct if authors_dct[key] == max_coauthors]
    
print('The author with ID', key, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/33:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key]) 
        max_coauthors_author = key
    
print('The author with ID', max_coauthors_authors, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/34:
# Enter your answer to Problem 4 here. 

max_coauthors = 0

for key in authors_dct : 
    if len(authors_dct[key]) > max_coauthors : 
        max_coauthors = len(authors_dct[key]) 
        max_coauthors_author = key
    
print('The author with ID', max_coauthors_author, 'has the maximum number of coauthors in the given text:', max_coauthors)
84/35:
max_value = 0 
for lst in [authors_dct[keys] for keys in authors_lst] : 
    if len(lst) >= max_value : 
        max_value = len(lst)
        

print(max_value)
print(len(authors_dct[21012]))
84/36:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f) #Credits for the next() fn : https://stackoverflow.com/questions/40403971/skip-multiple-rows-in-python
    
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst)
84/37:
# Enter your answer to Problem 1 here. 

lst = []
with open('ca-GrQc.txt', 'r') as f : 
    next(f)
    next(f)
    next(f)
    next(f) #Credits for the next() fn : https://stackoverflow.com/questions/40403971/skip-multiple-rows-in-python
    
    for line in f : 
        line_list = line.split()
        line_list = [int(x) for x in line_list if x != '\t' and x != '\n']
        lst.append(line_list)

print(lst[:10])
85/1:
# Write a function that reverses a string, e.g. "now" -> "won".
# Then call the function to reverse each of the strings in the list.

to_reverse = ['doc', 'keep', 'lap', 'lever', 'nap', 'nip', 'war']

def reverse_function(string) :
    return string.reverse()
85/2:
# Write a function that reverses a string, e.g. "now" -> "won".
# Then call the function to reverse each of the strings in the list.

to_reverse = ['doc', 'keep', 'lap', 'lever', 'nap', 'nip', 'war']

def reverse_function(string) :
    return string.reverse()

[reverse_function(string) for string in to_reverse]
85/3:
# Write a function that reverses a string, e.g. "now" -> "won".
# Then call the function to reverse each of the strings in the list.

to_reverse = ['doc', 'keep', 'lap', 'lever', 'nap', 'nip', 'war']

def reverse_function(string) :
    return string[::-1]

[reverse_function(string) for string in to_reverse]
85/4:
def find_char(astring, achar, start=0, end):
    """Find and return the index of achar in astring.
    Return None if achar does not occur in astring.
    """
    i = start
    if end == None:
        end = len(astring)

    found = False
    while i < end and not found:
        if astring[i] == achar:
            found = True
        else:
            i += 1
            
    if found:
        return i
    
    return None


mystring = "What goes around comes around."

print(find_char(mystring, 'e', start=2, 24))
85/5:
def find_char(astring, achar, start=0, end = None):
    """Find and return the index of achar in astring.
    Return None if achar does not occur in astring.
    """
    i = start
    if end == None:
        end = len(astring)

    found = False
    while i < end and not found:
        if astring[i] == achar:
            found = True
        else:
            i += 1
            
    if found:
        return i
    
    return None


mystring = "What goes around comes around."

print(find_char(mystring, 'e', start=2, 24))
86/1:
def power(x,p) : 
    if p == 0 
    return 1
    
    else : 
    return x * pow(x, p-1)
86/2:
def power(x,p) : 
    if p == 0 :
    return 1
    
    else : 
    return x * pow(x, p-1)
86/3:
def power(x,p) : 
    if p == 0 :
        return 1
    
    else : 
        return x * pow(x, p-1)
86/4:
def power(x,p) : 
    if p == 0 :
        return 1
    
    else : 
        return x * pow(x, p-1)
power(2,4)
86/5:
def power(x,p) : 
    if p == 0 :
        return 1
    
    else : 
        return x * pow(x, p-1)
power(2,8)
86/6:
def power(x,p) : 
    if p == 0 :
        return 1
    
    else : 
        return x * pow(x, p-1)
power(4,4)
87/1:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = [0]*int(len(alist))  # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/2:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = (0)*len(alist)  # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/3:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = 0*len(alist)  # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/4:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = 0*(alist)  # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/5:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = 0*(alist)  # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/6:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = 0*(alist)
    return alist# Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/7:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = 0 * (alist)
    return alist# Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/8:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    alist = 0 * (alist)
    return alist# Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/9:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    return 0 * (alist)# Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/10:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    return [0] * (alist)# Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/11:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    return [0] * alist # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/12:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    return [0]*len(alist) # Creates a new local reference for alist

mylist = [1, 2, 3]
zero_list(mylist)
print(mylist)
87/13:
# Exercise 1: Why isn't this code working?

def zero_list(alist):
    """Takes a list and returns another list of the same length 
    that looks like [0, 0, 0, ...].
    """
    return [0]*len(alist) # Creates a new local reference for alist

mylist = [1, 2, 3]
zerolist = zero_list(mylist)
print(zerolist)
87/14:
# Exercise 3: Rewrite the code above using functions 
# to make it easier to read.

x = (1,1)
y = (5,4)

def area(a,b) : 
    """
    
    """
    radius_sq = (a[0] - b [0])**2 + (a[1] - b[1])**2 
    area = 3.14 * radius_sq
    sq_side = area * 0.5
    return radius_sq, sq_side
87/15:
# Exercise 3: Rewrite the code above using functions 
# to make it easier to read.

x = (1,1)
y = (5,4)

def area(a,b) : 
    """
    
    """
    radius_sq = (a[0] - b [0])**2 + (a[1] - b[1])**2 
    area = 3.14 * radius_sq
    sq_side = area * 0.5
    return radius_sq, sq_side

area(x,y)
87/16:
# Exercise 3: Rewrite the code above using functions 
# to make it easier to read.

x = (1,1)
y = (5,4)

def area(a,b) : 
    """
    
    """
    radius_sq = (a[0] - b [0])**2 + (a[1] - b[1])**2 
    area = 3.14 * radius_sq
    sq_side = area ** 0.5
    return radius_sq, sq_side

area(x,y)
87/17:
# Exercise 3: Rewrite the code above using functions 
# to make it easier to read.

x = (1,1)
y = (5,4)

def area(a,b) : 
    """
    
    """
    radius_sq = (a[0] - b [0])**2 + (a[1] - b[1])**2 
    area = 3.14 * radius_sq
    sq_side = area ** 0.5
    return radius_sq, sq_side

area(x,y)

#Bruh
87/18:
# Exercise 4: Using a function and a list comprehension, 
# create a new list that has the numbers from testlist 
# if they are positive and None otherwise

testlist = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]

def pos_or_neg(x) : 
    if x>0 : 
        return x 
    else : 
        return 

lst_ex4 = [pos_or_neg(x) for x in testlist]
print(lst_ex4)
87/19:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    for i in range(1, len(a)) : 
        if b[i] == 0 : 
            return 
        else : 
            return a[i]/b[i]
        
ans = [list_div(a,b) for a,b in testlist1, testlist2]
87/20:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    for i in range(1, len(a)) : 
        if b[i] == 0 : 
            return 
        else : 
            return a[i]/b[i]
        
ans = [list_div(a,b) for a in testlist1 and b in testlist2]
87/21:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(x,y) for x in testlist1 and y in testlist2]
87/22:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(x,y) for x,y in testlist1, testlist2]
87/23:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(x,y) for x in testlist1, y in testlist2]
87/24:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(testlist1[i],testlist2[i]) for i in range(1, len(testlist1))]
87/25:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(testlist1[i],testlist2[i]) for i in range(1, len(testlist1))]
print(ans)
87/26:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(a = testlist1[i], b = testlist2[i]) for i in range(1, len(testlist1))]
print(ans)
87/27:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b == 0 : 
        return 
    else : 
        return a/b
        
ans = [list_div(a = testlist1[i], b = testlist2[i]) for i in range(1, len(testlist1))]
print(ans)
87/28:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b != 0 : 
        return a/b
    else : 
        return 
    
    
ans = [list_div(a = testlist1[i], b = testlist2[i]) for i in range(1, len(testlist1))]
print(ans)
87/29:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b != 0 : 
        return a/b
    else : 
        return 
    
    
ans = [list_div(a = testlist1[i], b = testlist2[i]) for i in range(0, len(testlist1))]
print(ans)
87/30:
# Exercise 5: Using a function and a list comprehension, create 
# a new list that includes the result from dividing each number 
# from testlist1 by the corresponding number in testlist2; 
# For the cases when the divisor is 0, the new list should include None

testlist1 = [-1, 0, 2, 178, -17.2, 12, -2, -3, 12]
testlist2 = [0, 5, 0, 2, 12, 0.5, 0, 0.25, 0]

def list_div(a,b) : 
    if b != 0 : 
        return a/b
    else : 
        return 
    
    
ans = [list_div(testlist1[i], testlist2[i]) for i in range(0, len(testlist1))]
print(ans)
87/31:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x))
        if x[i] == x[::-1][i] : 
            return Yes 
    
    else : 
        return No
87/32:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return Yes 
    
    else : 
        return No
87/33:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return Yes 
    
    else : 
        return No

is_palindrome(dad)
87/34:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return Yes 
    
    else : 
        return No

is_palindrome('dad')
87/35:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
    
    else : 
        return 'No'

is_palindrome('dad')
87/36:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
    
    else : 
        return 'No'

is_palindrome('red')
87/37:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
    
    else : 
        return 'No'

is_palindrome('red')
87/38:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
    
    else : 
        return 'No'

is_palindrome('red')
87/39:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
        return 'No'

is_palindrome('red')
87/40:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('red')
87/41:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('ded')
87/42:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('redder')
87/43:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('nurses')
87/44:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('run')
87/45:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('rr')
87/46:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/47:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x.replace(' ', '')
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/48:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x.replace(' ', '')
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/49:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x.replace(' ', '')
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/50:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x.replace(" ", "")
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/51:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x = x.replace(" ", "")
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/52:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x = x.replace(" ", "")
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/53:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x = x.replace(" ", "")
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/54:
# Exercise 6: Write a Python function that checks if a string 
# is a palindrome. A palindrome is a word or a phrase that reads 
# the same backward as forward. For example, redder, nurses run, dad...

def is_palindrome(x) : 
    x = x.replace(" ", "").lower()
    for i in range(len(x)) :
        if x[i] == x[::-1][i] : 
            return 'Yes' 
        else : 
            return 'No'

is_palindrome('Was it a car or a cat I saw')
87/55: 'a' == 'A'
88/1:
# We will first import the modules we need
# Edit this cell if you prefer to use alternative modules or libraries

# You will need the math module to estimate the square root.
# To get the square root of num, use math.sqrt(num)
import math
import csv
import random
88/2:
# Enter your answer to Problem 1 below. 

def get_distance(list1, list2) : 
    ''' 
    Gives the magnitude of shortest distance between two points in n-dimensional space
    Assumes two lists of length n
    Returns the shortest distance
    '''
    summ = 0
    
    while i < len(list1) : 
        s = list1[i]**2 - list2[i]**2 
        summ += s 
        i += 1
        
    return math.sqrt(summ)
88/3:
# Enter your answer to Problem 1 below. 

def get_distance(list1, list2) : 
    ''' 
    Gives the magnitude of shortest distance between two points in n-dimensional space
    Assumes two lists of length n
    Returns the shortest distance
    '''
    summ = 0
    
    while i < len(list1) : 
        s = list1[i]**2 - list2[i]**2 
        summ += s 
        i += 1
        
    return math.sqrt(summ)

get_distance([0,3,0], [4,0,0])
88/4:
# Enter your answer to Problem 1 below. 

def get_distance(list1, list2) : 
    ''' 
    Gives the magnitude of shortest distance between two points in n-dimensional space
    Assumes two lists of length n
    Returns the shortest distance
    '''
    summ = 0
    while i < len(list1) : 
        s = list1[i]**2 - list2[i]**2 
        summ += s 
        i += 1
        
    return math.sqrt(summ)

get_distance([0,3,0], [4,0,0])
88/5:
# Enter your answer to Problem 1 below. 

def get_distance(list1, list2) : 
    ''' 
    Gives the magnitude of shortest distance between two points in n-dimensional space
    Assumes two lists of length n
    Returns the shortest distance
    '''
    summ = 0
    i = 0
    while i < len(list1) : 
        s = list1[i]**2 - list2[i]**2 
        summ += s 
        i += 1
        
    return math.sqrt(summ)

get_distance([0,3,0], [4,0,0])
88/6:
# Enter your answer to Problem 1 below. 

def get_distance(list1, list2) : 
    ''' 
    Gives the magnitude of shortest distance between two points in n-dimensional space
    Assumes two lists of length n
    Returns the shortest distance
    '''
    summ = 0
    i = 0
    while i < len(list1) : 
        s = (list1[i] - list2[i])**2 
        summ += s 
        i += 1
        
    return math.sqrt(summ)

get_distance([0,3,0], [4,0,0])
88/7:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]
test_lst[1][1]


# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    return
88/8:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]
test_lst[1][1]


# Enter your answer to Problem 2 below.
88/9:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]
test_lst[1][2]


# Enter your answer to Problem 2 below.
88/10:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]
test_lst[1][2]


# Enter your answer to Problem 2 below.
88/11:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]
test_lst[1][2]


# Enter your answer to Problem 2 below.
88/12:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]
test_lst[1]


# Enter your answer to Problem 2 below.
88/13:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]

#(0[0] + 1[0] + 2[0] + 3[0] + ... + len(lst)[0])/len(lst)
#(0[1] + 1[1] + 2[1] + ... + len(lst)[1])/len(lst)
.
.
.
#(0[len(lst[1])] + ... + len(lst)[len(lst[1])])/len(lst)

# Enter your answer to Problem 2 below. 
def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
        for i in range(len(lst[0])) :
            for j in range(len(lst) :
                summ = 0 
                summ += j[i]
                           
                avg = summ/len(lst)
                           centroid.append(avg)
        
        
        
    return centroid
88/14:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]

#(0[0] + 1[0] + 2[0] + 3[0] + ... + len(lst)[0])/len(lst)
#(0[1] + 1[1] + 2[1] + ... + len(lst)[1])/len(lst)
.
.
.
#(0[len(lst[1])] + ... + len(lst)[len(lst[1])])/len(lst)

# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
        for i in range(len(lst[0])) :
            for j in range(len(lst) :
                summ = 0 
                summ += j[i]
                           
                avg = summ/len(lst)
                           centroid.append(avg)
        
        
        
    return centroid
88/15:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
        for i in range(len(lst[0])) :
            for j in range(len(lst) :
                summ = 0 
                summ += j[i]
                           
                avg = summ/len(lst)
                           centroid.append(avg)
        
        
        
    return centroid
88/16:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
    for i in range(len(lst[0])) :
        for j in range(len(lst) :
            summ = 0 
            summ += j[i]
                           
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid
88/17:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
    for i in range(len(lst[0])) :
        for j in range(len(lst)) :
            summ = 0 
            summ += j[i]
                           
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid
88/18:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
    for i in range(len(lst[0])) :
        for j in range(len(lst)) :
            summ = 0 
            summ += j[i]
                           
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/19:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
    for i in range(len(lst[0])) :
        for j in range(len(lst)) :
            summ = 0 
            summ += lst[j][i]
                           
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/20:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
     
    for i in range(len(lst)) :
        for j in range(len(lst[0])) :
            summ = 0 
            summ += lst[i][j]
                           
        avg = summ/len(lst)
        centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/21:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
     
    for i in range(len(lst)) :
        for j in range(len(lst[0])) :
            summ += lst[i][j]
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/22:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
     
    for i in range(len(lst[0])) :
        for j in range(len(lst)) :
            summ += lst[j][i]
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/23:
lst = []
lst.append(i for i in range(3))
88/24:
lst = []
lst.append(i for i in range(3))
lst
88/25:
lst = []
lst.append(i for i in range(3))
print(lst)
88/26:
lst = []
for i in range(3) :
lst.append(i)
print(lst)
88/27:
lst = []
for i in range(3) :
    lst.append(i)
print(lst)
88/28:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
     
    for i in range(len(lst[0])) :
        
        for j in range(len(lst)) :
            summ += lst[j][i]
            
            
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/29:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    j = 0
     
    while i < len(lst[0]) :
        
        while j < lst :
            summ += lst[j][i]
            
            
            avg = summ/len(lst)
            centroid.append(avg)
        
        
        
    return centroid 

get_centroid(test_lst)
88/30:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    j = 0
     
    while i < len(lst[0]) :
        
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            i += 1
        
        
        
    return centroid 

get_centroid(test_lst)
88/31:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            i += 1
        
        
        
    return centroid 

get_centroid(test_lst)
88/32:
lst = []
for i in range(3) :
    lst.append(i)
print(lst)

lst[1][1]
88/33:
lst = []
for i in range(3) :
    lst.append(i)
print(lst)

lst[1]
88/34:
lst = []
for i in range(3) :
    lst.append(i)
print(lst)

lst = [1, [2,3]]
lst[1,0]
88/35:
lst = []
for i in range(3) :
    lst.append(i)
print(lst)

lst = [1, [2,3]]
lst[1][0]
88/36:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            i += 1
        
        
        
    return centroid 

get_centroid(test_lst)
88/37:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
        
        
        
    return centroid 

get_centroid(test_lst)
88/38:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
    return centroid 

get_centroid(test_lst)
88/39:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    summ = 0 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
    return centroid 

get_centroid(test_lst)
88/40:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = [] 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        summ = 0
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
    return centroid 

get_centroid(test_lst)
88/41:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = [] 
    i = 0 
    
     
    while i < len(lst[0]) :
        
        j = 0
        summ = 0
        
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
    return centroid 

get_centroid(test_lst)
88/42:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) :
        
        j = 0
        summ = 0
        
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
    
    return centroid 

get_centroid(test_lst)
88/43: lst = [1,2,3]
88/44:
lst = [1,2,3]
len(lst)
88/45:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) :
        
        j = 0
        summ = 0
        
        while j < len(lst) :
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            i += 1
    
    return centroid 

get_centroid(test_lst)
88/46:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
        j = 0 
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            
            
        i += 1
        return centroid
88/47:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
        j = 0 
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid(test_lst)
88/48:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
        j = 0 
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([0,0], [1,1])
88/49:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
        j = 0 
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/50:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
        j = 0 
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            centoid.append(summ)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/51:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
        j = 0 
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            centroid.append(summ)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/52:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
         
        summ = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            centroid.append(summ)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/53:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
         
        summ = 0
        j = 0
        while j < len(lst) : 
            summ += lst[j][i]
            j += 1
            
            centroid.append(summ)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/54:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
         
        summ = 0
        j = 0
        while j < len(lst) : 
            summ = summ + lst[j][i]
            j += 1
            
            centroid.append(summ)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/55:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
         
        summ = 0
        j = 0
        while j < len(lst) : 
            summ = summ + (lst[j])[i]
            j += 1
            
            centroid.append(summ)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/56:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst[0]) : 
        
         
        summ = 0
        j = 0
        while j < len(lst) : 
            summ = summ + (lst[j])[i]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/57:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst) : 
        
         
        summ = 0
        j = 0
        while j < len(lst[0]) : 
            summ = summ + (lst[i])[j]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
            
            
        i += 1
        return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/58:
lst = [[1,2,3], [1,2]]
len(lst[0])
88/59:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    i = 0 
    while i < len(lst) : 
        
         
        summ = 0
        j = 0
        while j < len(lst[0]) : 
            summ = summ + lst[i][j]
            j += 1
            
            avg = summ/len(lst)
            centroid.append(avg)
            
    i += 1
        
    return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/60:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    for i in range(len(lst[0])) : 
        
        centroid[i] = sum(lst[j][i] for j in range(len(lst)))
        
    return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/61:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    
    for i in range(len(lst[0])) : 
        
        centroid[i] = lst[i]
        
    return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/62:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    n = len(lst[0])
    
    for i in range(n) : 
        
        centroid[i] = lst[i]
        
    return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/63:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    n = len(lst[0])
    
    for i in range(n) : 
        
        centroid[i] = [lst[j][i] for j in range(len(lst))]
        
    return centroid 
    
    
get_centroid([[0,0], [1,1]])
88/64:
# We will first import the modules we need
# Edit this cell if you prefer to use alternative modules or libraries

# You will need the math module to estimate the square root.
# To get the square root of num, use math.sqrt(num)
import math
import csv
import random
import numpy
88/65:
# We will first import the modules we need
# Edit this cell if you prefer to use alternative modules or libraries

# You will need the math module to estimate the square root.
# To get the square root of num, use math.sqrt(num)
import math
import csv
import random
import numpy as np #Used numpy in Q2 for converting lists into arrays and doing array-wise operations. I was unable to do it efficiently using iterations.
88/66:
# We will first import the modules we need
# Edit this cell if you prefer to use alternative modules or libraries

# You will need the math module to estimate the square root.
# To get the square root of num, use math.sqrt(num)
import math
import csv
import random
import numpy as np #Used numpy in Q2 for converting lists into arrays and doing array-wise operations. I was unable to do it efficiently using iterations.
88/67:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    
    len(lst[0]) = n #n dimensional list
    
    for i in range(n) : 
        centroid[i] = np.mean(lst)

        return centroid
88/68:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    
    n = len(lst[0]) #n dimensional list
    
    for i in range(n) : 
        centroid[i] = np.mean(lst)

        return centroid
88/69:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    
    n = len(lst[0]) #n dimensional list
    
    for i in range(n) : 
        centroid[i] = np.mean(lst)

        return centroid 

centroid(test_lst)
88/70:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    centroid = []
    n = len(lst[0]) #n dimensional list
    
    for i in range(n) : 
        centroid[i] = np.mean(lst)

        return centroid 

get_centroid(test_lst)
88/71:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    
    arr = [np.array(l) for l in lst] #Convert all lists into arrays 
    centroid = [np.mean(x) for x in zip(*arr)]
88/72:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    
    arr = [np.array(l) for l in lst] #Convert all lists into arrays 
    centroid = [np.mean(x) for x in zip(*arr)]
    return centroid 

get_centroid(test_lst)
88/73:
# Enter your answer to Problem 3 here. 

df = read.csv('Wholesale customers data.csv')
88/74:
# Enter your answer to Problem 3 here. 

df = read_csv('Wholesale customers data.csv')
89/1:
# We will first import the modules we need
# Edit this cell if you prefer to use alternative modules or libraries

# You will need the math module to estimate the square root.
# To get the square root of num, use math.sqrt(num)
import math
import csv
import random
import numpy as np #Used numpy in Q2 for converting lists into arrays and doing array-wise operations. I was unable to do it efficiently using iterations.
89/2:
# Enter your answer to Problem 1 below. 

def get_distance(list1, list2) : 
    ''' 
    Gives the magnitude of shortest distance between two points in n-dimensional space
    Assumes two lists of length n
    Returns the shortest distance
    '''
    summ = 0
    i = 0
    while i < len(list1) : 
        s = (list1[i] - list2[i])**2 
        summ += s 
        i += 1
        
    return math.sqrt(summ)

get_distance([0,3,0], [4,0,0])
89/3:
test_lst = [[0,0,0], [0,0,1], [0,1,0], [1,0,0], 
            [0,1,1], [1,0,1], [1,1,0], [1,1,1]]



# Enter your answer to Problem 2 below. 

def get_centroid(lst) : 
    ''' 
    Calculates the centroid of a collection of n-dimensional points 
    Takes a list as an argument, where each coorinate is an n-dimensional list
    Returns a list consisting of the coordinates of centroid 
    '''
    
    arr = [np.array(l) for l in lst] #Convert all lists into arrays 
    centroid = [np.mean(x) for x in zip(*arr)] #zip() function creates tuples of length n with respective entries at symmetric positions for each of the lists. 
    return centroid 

get_centroid(test_lst)
89/4:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', newline = '') as data : 
    for row in csv.reader(data) : 
        print(data)
89/5:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    for row in csv.reader(data) : 
        print(data)
89/6:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data) : 
    for row in df : 
        print(row)
89/7:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data)  
    for row in df : 
        print(row)
89/8:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data, numeric = csv.QUOTE_NONNUMERIC)  
    for row in df : 
        print(row)
89/9:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data, num = csv.QUOTE_NONNUMERIC)  
    for row in df : 
        print(row)
89/10:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC)  
    for row in df : 
        print(row)
89/11:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC)  
    for row in df : 
        print(row)
89/12:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data : 
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC)  
    next(df)
    for row in df : 
        print(row)
89/13:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data :  
    next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df : 
        print(row)
89/14:
# Enter your answer to Problem 3 here. 

with open('Wholesale customers data.csv', 'r') as data :  
    next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df : 
        print(row[2:])
89/15:
# Enter your answer to Problem 3 here. 

def get_data(file) :

with open(file, 'r') as data :  
    next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df : 
        print(row[2:])
89/16:
# Enter your answer to Problem 3 here. 

def get_data(file) :
    with open(file, 'r') as data :  
    next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df : 
        print(row[2:])
89/17:
# Enter your answer to Problem 3 here. 

def get_data(file) :
    with open(file, 'r') as data :  
        next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df : 
        print(row[2:])
89/18:
# Enter your answer to Problem 3 here. 

def get_data(file) :
    
    with open(file, 'r') as data :  
        next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df.head(2) : 
        print(row[2:])
89/19:
# Enter your answer to Problem 3 here. 

def get_data(file) :
    
    with open(file, 'r') as data :  
        next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df.head(2) : 
        print(row[2:])

get_data('Wholesale customers data.csv')
89/20:
# Enter your answer to Problem 3 here. 


    
    with open('Wholesale costumers data.csv', 'r') as data :
        
        next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df.head(2) : 
        print(row[2:])
89/21:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale costumers data.csv', 'r') as data :
        
        next(data)
    df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df.head(2) : 
        print(row[2:])
89/23:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale costumers data.csv', 'r') as data :
        
        next(data)
        df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
    
    for row in df.head(2) : 
        print(row[2:])
89/25:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale costumers data.csv', 'r') as data :
        
        next(data)
        df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df.head(2) : 
        print(row[2:])
89/26:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale costumers data.csv', 'r') as data :
        
        next(data)
        df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df.head(2) : 
            print(row[2:])
89/27:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as data :
        
        next(data)
        df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df.head(2) : 
            print(row[2:])
89/28:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df = csv.reader(data, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df : 
            print(row[2:])
89/29:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df : 
            print(row[2:])
89/30:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df_reader : 
            print(row[2:])
89/31:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df_reader : 
        data = row[2:]
89/32:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df_reader : 
            data = row[2:]
89/33:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        for row in df_reader : 
            data = row[2:]
            
data
89/34:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        for row in df_reader : 
            print(row[2:])
89/35:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        df_reader
89/36:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        print(df_reader)
89/37:
# Enter your answer to Problem 3 here. 


    
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC)
89/38:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        return data
89/39:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        return data
89/40:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        return
89/41:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        for rows in data : 
            return data[2:]
    
get_data('Wholesale customers data.csv')
89/42:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        for rows in data : 
            print(rows[2:])
    
get_data('Wholesale customers data.csv')
89/43:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        return data
    
for rows in get_data('Wholesale customers data.csv') :
    print(rows[2:])
89/44:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open('Wholesale customers data.csv', 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        for row in data : 
            print(row[2:])
89/45:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        data = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        for row in data : 
            print(row[2:])
            
get_data('Wholesale customers data.csv')
89/46:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        for row in df_reader : 
            print(row[2:])
            
get_data('Wholesale customers data.csv')
89/47:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader]
        return df_list
89/48:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader]
        return df_list
    
get_data('Wholesale customers data.csv')
89/49:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader]
        return df_list
    
data = get_data('Wholesale customers data.csv')
89/50:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader]
        return df_list
    
data = get_data('Wholesale customers data.csv')
prin(data[0:2])
89/51:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    '''
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader]
        return df_list
    
data = get_data('Wholesale customers data.csv')
print(data[0:2])
89/52:
# Enter your answer to Problem 3 here. 


def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader] #To remove the first two columns
        return df_list
    
data = get_data('Wholesale customers data.csv')
print(data[0:2])
89/53:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    """
    Assumes a list of n-dimensional points and integer k representing number of desired clusters
    Returns a list of k clusters, each of which is a list of points (each of which is a list of coordinates) and 
     list of the centroids for each of the k clusters. 
    """
    
    # Select k random points to use as initial centroids
    init = random.sample(points, k) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    #clusters = [[] for i in init]
    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    #centroids = [i for i in init]
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/54:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    """
    Assumes a list of n-dimensional points and integer k representing number of desired clusters
    Returns a list of k clusters, each of which is a list of points (each of which is a list of coordinates) and 
     list of the centroids for each of the k clusters. 
    """
    
    # Select k random points to use as initial centroids
    init = random.sample(points, k) 
    init 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    #clusters = [[] for i in init]
    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    #centroids = [i for i in init]
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/55:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
    init = random.sample(points, k) 
    init 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    #clusters = [[] for i in init]
    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    #centroids = [i for i in init]
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/56:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(points, k) 
init 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    #clusters = [[] for i in init]
    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    #centroids = [i for i in init]
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/57:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
init 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    #clusters = [[] for i in init]
    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    #centroids = [i for i in init]
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/58:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    #centroids = [i for i in init]
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/59:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/60:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data))
print(i)
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/61:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
print(i)
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/62:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    print(i)
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/63:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    min[get_distance(data[i], centroid[j]) for j in range(len(centroid[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/64:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    min[get_distance(data[i], centroid[sj]) for j in range(len(centroid[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/65:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    lst = [get_distance(data[i], centroids[j]) for j in range(len(centroid[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/66:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    lst = [get_distance(data[i], centroids[j]) for j in range(len(centroids[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/67:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    if i<=j
    lst = [get_distance(data[i], centroids[j]) for j in range(len(centroids[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/68:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    if i<=j :
    lst = [get_distance(data[i], centroids[j]) for j in range(len(centroids[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/69:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) :
    if i<=j :
        lst = [get_distance(data[i], centroids[j]) for j in range(len(centroids[0]))]
    
    
    
    
    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/70:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    print([get_distance(data[i], centroids[j]) for j in range(3)])


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/71:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = [get_distance(data[i], centroids[j]) for j in range(3)]
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/72:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = [get_distance(data[i], centroids[j]) for j in range(3)]
    
    new_list
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/73:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = [get_distance(data[i], centroids[j]) for j in range(3)]
    
    new_lst
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/74:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = []
    new_lst2 = new_lst.append[get_distance(data[i], centroids[j]) for j in range(3)]
    
    new_lst2
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/75:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = []
    new_lst2 = new_lst.append[get_distance(data[i], centroids[j]) for j in range(3)]
    
    new_lst2
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/76:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = []
    new_lst2 = new_lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
    new_lst2
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/77:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    new_lst = []
    new_lst2 = new_lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
    print(new_lst2)
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/78:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    print([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/79:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    print(list([get_distance(data[i], centroids[j]) for j in range(3)]))
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/80:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    print(([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/81:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    print([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/82:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    print(i, ':', [get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/83:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    lst = [get_distance(data[i], centroids[j]) for j in range(3)]
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/84:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    lst = [get_distance(data[i], centroids[j]) for j in range(3)]
    
    lst
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/85:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    lst = [get_distance(data[i], centroids[j]) for j in range(3)]
    

print(lst)
    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/86:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    lst = []
    lst = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    


    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/87:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    lst = []
    lst = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
print(lst)
    


    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/88:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    
    lst = []
    lst2 = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/89:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    
    lst = []
    lst2 = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
print(lst2)




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/90:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    
    lst = []
    lst2 = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
lst2[0]




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/91:
new_list = []
new_list.append([1,1])
89/92:
new_list = []
new_list.append([1,1])
new_list
89/93:
new_list = []
new_list.append([i for i in range(3)])
89/94:
new_list = []
new_list.append([i for i in range(3)])

new_list
89/95:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
while i <= (len(data)) : 
    
    lst = []
    lst2 = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
    i += 1
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/96:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
i = 0
while i <= (len(data)) : 
    
    lst = []
    lst2 = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
    i += 1
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/97:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
i = 0
while i <= (len(data)) : 
    
    lst = []
    lst2 = lst.append([get_distance(data[i], centroids[j]) for j in range(3)])
    
    i += 1
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/98:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

    for i in range(len(data)) : 
        print([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/99:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

for i in range(len(data)) : 
    print([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/100:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

for i in range(len(data)) : 
    [get_distance(data[i], centroids[j]) for j in range(3)]
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/101:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

for i in range(len(data)) : 
    print([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/102:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

for i in range(len(data)) : 
    list([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/103:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

for i in range(len(data)) : 
    new_lst = list([get_distance(data[i], centroids[j]) for j in range(3)])
    
    
print(new_lst)
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/104:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for i in range(len(data)) : 
    lst.append([get_distance(data[i], centroids[j])  for j in range(3)])
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/105:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for i in range(len(data)) : 
    lst.append([get_distance(data[i], centroids[j])  for j in range(3)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/106:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for i in range(len(data)) : 
    lst.append([get_distance(data[i], centroids[j])  for j in range(8)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/107:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for i in range(len(data)) : 
    lst.append([get_distance(data[i], centroids[j])  for j in range(7)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/108:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for i in range(len(data)) : 
    lst.append([get_distance(data[i], centroids[j])  for j in range(2)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/109:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for i in range(len(data)) : 
    lst.append([get_distance(data[i], centroids[j])  for j in range(4)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/110:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for j in range(4 : 
    lst.append([get_distance(data[i], centroids[j])  for i in range(5)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/111:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    

lst = []

for j in range(4) : 
    lst.append([get_distance(data[i], centroids[j])  for i in range(5)])
    
print(lst)
    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/112:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
n = len(data)
lst = []
for i in range(n) : 
     lst.append([get_distance(data[i], centroid[j]) for j in range(3)])


    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/113:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
n = len(data)
lst = []
for i in range(n) : 
     lst.append([get_distance(data[i], centroids[j]) for j in range(3)])


    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/114:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
n = len(data[0]) #List of n dimensions
lst = []
for i in range(len(data)) : 
     lst.append([get_distance(data[i], centroids[j]) for j in range()])




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/115:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
n = len(data[0]) #List of n dimensions
lst = []
for i in range(len(data)) : 
     lst.append([get_distance(data[i], centroids[j]) for j in range(n)])




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/116:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for point in data : 
    print(point)


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/117:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for point in data : 
    dist = []
    for i in centroids : 
        dist.append(get_distance(point, centroids[i]))


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/118: len(data)
89/119:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for point in data : 
    dist = []
    for i in len(centroids) : 
        dist.append(get_distance(point, centroids[i]))


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/120:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in data : 
    dist = []
    for j in len(centroids) : 
        dist.append(get_distance(data[i[, centroids[j]))


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/121:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in data : 
    dist = []
    for j in len(centroids) : 
        dist.append(get_distance(data[i], centroids[j]))


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/122:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in len(data) : 
    dist = []
    for j in len(centroids) : 
        dist.append(get_distance(data[i], centroids[j]))


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/123:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    dist = []
    for j in range(len(centroids)) : 
        dist.append(get_distance(data[i], centroids[j]))


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/124:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    dist = []
    for j in range(len(centroids)) : 
        dist.append(get_distance(data[i], centroids[j]))
        
print(dist)


#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/125:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    dist = []
    for j in range(len(centroids)) : 
        min_dist = dist.append(get_distance(data[i], centroids[j]))
        

        



#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/126:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    dist = []
    for j in range(len(centroids)) : 
        min_dist = dist.append(get_distance(data[i], centroids[j]))

min_dist
        

        



#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/127:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for i in range(len(data)) : 
    dist = []
    for j in range(len(centroids)) : 
        min_dist = dist.append(get_distance(data[i], centroids[j]))

print(min_dist)
        

        



#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/128:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for point in data : 
    dist = []
    for j in range(len(centroids)) : 
        min_dist = dist.append(get_distance(point, centroids[j]))

        

        



#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/129:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for point in data : 
    dist = []
    for j in range(len(centroids)) : 
        min_dist = dist.append(get_distance(point, centroids[j]))
        
print(min_dist)
        

        



#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/130:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
init = random.sample(data, 3) 
print(init) 
    #k random points (1,2,3,....k)

    # Create a list of k lists to contain the points assigned to each cluster.  
    
clusters = [[] for i in init]
print(clusters)

    #k clusters so k lists
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
centroids = [i for i in init]
print(centroids)
    #Already assigned centroids 
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
for point in data : 
    dist = []
    for j in range(len(centroids)) : 
        min_dist = dist.append(get_distance(point, centroids[j]))
        
for row in min_dist : 
    print(row)
        

        



#Above code gives an error 'list index out of range. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

#After this code, I would use : 
#




    
    
    




    
    
    


    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/131:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
    
    # Select k random points to use as initial centroids
#init = random.sample(points, k) 
#print(init) 

    # Create a list of k lists to contain the points assigned to each cluster.  
    
#clusters = [[] for i in init]


   
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
#centroids = [i for i in init]
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
#for point in points : 
    #dist = []
    #for j in range(len(centroids)) : 
        #dist_updated = dist.append(get_distance(point, centroids[j]))
        
#Above code gives an error 'list index out of range'. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

 

    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
# After this, I would use : 
# clusters.append([i : dist[i] == min(dist[i]) for i in range(len(dist))] 
# This will return a list of the clusters for each element


    

    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
89/132:
# Enter your answer to Problem 4 in-between the code and comments below. 

#def kmeans(points, k):
    
"""
Assumes a list of n-dimensional points and integer k representing number of desired clusters
Returns a list of k clusters, each of which is a list of points (each of which is a list of coordinates) and  list of the centroids for each of the k clusters. 
"""


    
    # Select k random points to use as initial centroids
#init = random.sample(points, k) 
#print(init) 

    # Create a list of k lists to contain the points assigned to each cluster.  
    
#clusters = [[] for i in init]


   
    
    # Create a list to keep the centroids of the k clusters. 
    # For now, this list will contain the points from init.
    
#centroids = [i for i in init]
    
    # You now need to assign each point to the cluster 
    # with the closest centroid. Use the get_distance function 
    # you wrote in Problem 1 for this.
    
#for point in points : 
    #dist = []
    #for j in range(len(centroids)) : 
        #dist_updated = dist.append(get_distance(point, centroids[j]))
        
#Above code gives an error 'list index out of range'. I wanted to create a matrix with each row representing a list of 
#the distances between the row vector in data, and the three centroids. 

 

    # You should then update the variable "clusters" to be 
    # the new clustering and update the variable "centroids" 
    # to contain the centroids of the clusters in this new clustering.
    # Use the function you wrote in Problem 2 to estimate the centroids.
    
# After this, I would use : 
# clusters.append([i : dist[i] == min(dist[i]) for i in range(len(dist))] 
# This will return a list of the clusters for each element


    

    
    # Repeat the process described above for 100 iterations. 
    # The idea is that each new repetition refines the clustering 
    # because it starts from the centroids of the previous clustering. 
    # If we repeat the process long enough, the assignment to 
    # clusters and the centroids will become stable.
90/1:
from datetime import date

class Person(object):
        
    def __init__(self, f_name, l_name):
        """Creates a person using first and last names."""
        self.first_name = f_name
        self.last_name = l_name
        self.birthdate = None
    
    def get_name(self):
        """Gets self's full name."""
        return self.first_name + ' ' + self.last_name
    
    def get_age(self):
        """Gets self's age in years."""
        return date.today().year - self.birthdate.year
    
    def set_birthdate(self, dob):
        """Assumes dob is of type date.
        Sets self's birthdate to dob.
        """
        self.birthdate = dob
    
    def __str__(self):
        """Returns self's full name."""
        return self.first_name + ' ' + self.last_name
    
p1 = Person('Greta', 'Thunberg')
p1.set_birthdate(date(2003, 1, 3))
print(p1, p1.get_age())
90/2:
class Person(object):
        
    def __init__(self, f_name, l_name):
        """Creates a person using first and last names."""
        self.first_name = f_name
        self.last_name = l_name
        self.birthdate = None
    
    def get_name(self):
        """Gets self's full name."""
        return self.first_name + ' ' + self.last_name
    
    def get_age(self):
        """Gets self's age in years."""
        return date.today().year - self.birthdate.year
    
    def set_birthdate(self, dob):
        """Assumes dob is of type date.
        Sets self's birthdate to dob.
        """
        self.birthdate = dob
    
    def __str__(self):
        """Returns self's full name."""
        return self.get_name()
    
    def __lt__(self, other):
        """Returns True if self's last name precedes other's last name
        in alphabethical order. If they are equal, compares first names.
        """
        if self.last_name == other.last_name:
            return self.first_name < other.first_name
        return self.last_name < other.last_name
    
p1 = Person('Greta', 'Thunberg')
p2 = Person('Taylor', 'Swift')
print(p1 < p2)

lst = sorted([p1, p2])
print([str(i) for i in lst])
90/3: p1.get_name().split()[0]  # Or write a new method get_first_name()
90/4:
# Update the class below to include the attribute occupation.
# Then write a get method and a set method for occupation.

class Person(object):
        
    def __init__(self, f_name, l_name):
        """Creates a person using first and last names."""
        self.first_name = f_name
        self.last_name = l_name
        self.birthdate = None
        self.occupation = None
    
    def get_name(self):
        """Gets self's full name."""
        return self.first_name + ' ' + self.last_name
    
    def get_age(self):
        """Gets self's age in years."""
        return date.today().year - self.birthdate.year
    
    def set_birthdate(self, dob):
        """Assumes dob is of type date.
        Sets self's birthdate to dob.
        """
        self.birthdate = dob
    
    def __str__(self):
        """Returns self's full name."""
        return self.get_name()
    
    def __lt__(self, other):
        """Returns True if self's last name precedes other's last name
        in alphabethical order. If they are equal, compares first names.
        """
        if self.last_name == other.last_name:
            return self.first_name < other.first_name
        return self.last_name < other.last_name
    
    def set_occupation(self, occ): 
        '''
        Assumes occ is of type string
        Sets self's occupation to occ
        '''
        self.occupation = occ
        
    def get_occupation(self) : 
        '''
        gets self's occupation
        '''
        return self.occupation
    
p1 = Person('Greta', 'Thunberg')
p1.set_occupation('Teacher')
p1.get_occupation
90/5:
# Update the class below to include the attribute occupation.
# Then write a get method and a set method for occupation.

class Person(object):
        
    def __init__(self, f_name, l_name):
        """Creates a person using first and last names."""
        self.first_name = f_name
        self.last_name = l_name
        self.birthdate = None
        self.occupation = None
    
    def get_name(self):
        """Gets self's full name."""
        return self.first_name + ' ' + self.last_name
    
    def get_age(self):
        """Gets self's age in years."""
        return date.today().year - self.birthdate.year
    
    def set_birthdate(self, dob):
        """Assumes dob is of type date.
        Sets self's birthdate to dob.
        """
        self.birthdate = dob
    
    def __str__(self):
        """Returns self's full name."""
        return self.get_name()
    
    def __lt__(self, other):
        """Returns True if self's last name precedes other's last name
        in alphabethical order. If they are equal, compares first names.
        """
        if self.last_name == other.last_name:
            return self.first_name < other.first_name
        return self.last_name < other.last_name
    
    def set_occupation(self, occ): 
        '''
        Assumes occ is of type string
        Sets self's occupation to occ
        '''
        self.occupation = occ
        
    def get_occupation(self) : 
        '''
        gets self's occupation
        '''
        return self.occupation
    
p1 = Person('Greta', 'Thunberg')
p1.set_occupation('Teacher')
p1.get_occupation()
92/1:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
92/2:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
ex.list.member(2)
92/3:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
ex_list.member(2)
92/4:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
ex_list.member(2)
print(ex_list)
92/5:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
ex_list.member([11,2,3])
print(ex_list)
92/6:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
ex_list.member([11,2,3])
92/7:
# 3. Example Class (Guttag, 2013)

class IntList(object):
    """A IntList is a list of integers"""
    # Infomation about the implementation (not the abstraction)
    # The value of the list is represented by a list of ints. self.vals.
    
    def __init__(self):
        """Create a empty list of integers""" 
        self.vals = []
        
    def insert(self, e):
        """Assumes that e is a int and inserts e into self"""
        if e not in self.vals:
            self.vals.append(e)
            
    def member(self, e):
        """Assumes e is a int and returns True if e is in self, otherwise False"""
        return e in self.vals  
    
    def remove(self, e):
        """Assumes e is an int and removes e from self
        Raises a ValueError if e is not in self"""
        try:
            self.vals.remove(e)
        except:
            raise ValueError(str(e) + " Not found")
            
    def getMembers(self):
        """Returns a list containing the elems of self.
        Nothing can be assumed about the order of elements"""
        return list(self.vals)
            
    def __str__(self):
        """Returns a string representation of self"""
        return str(self.vals)
    
ex_list = [11,2,3]
ex_list = IntList()
ex_list.insert(2)
ex_list.remove(5)
93/1:
# Enter your answer to Problem 2 below.

def UndirectedNetwork(nodes): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def __add_node__(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes['node_id'] = []
93/2:
# Enter your answer to Problem 2 below.

def UndirectedNetwork(nodes): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def __add_node__(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
UndirectedNetwork.add_node(123)
93/3:
# Enter your answer to Problem 2 below.

def UndirectedNetwork(nodes): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
UndirectedNetwork.add_node(123)
93/4:
# Enter your answer to Problem 2 below.

def UndirectedNetwork(nodes): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
nodes = UndirectedNetwork()
        
nodes.add_node(123)
93/5:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(nodes): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/6:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self, nodes): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/7:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/8:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.add(node_id, Null)
        
Nodes = UndirectedNetwork()
        
Nodes.Add_node(123)
93/9:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.Add(node_id, Null)
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/10:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.Add(node_id, Null)
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/11:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes.Add(node_id, Null);
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/12:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes[node_id] = Null
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/13:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes[node_id] = None
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/14:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
93/15:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.get_node_ids()
93/16:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.get_node_ids()  
Nodes.get_node_neighbors()
93/17:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
93/18:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return (keys for keys in self.nodes.keys())
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
93/19:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return list(self.nodes.keys())
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
93/20:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        for keys in self.nodes : 
            return keys
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
93/21:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return self.nodes.keys
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
93/22:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
95/1: 4.3 - 3.41
95/2: 18.86-15.98
95/3: 5657-4792
95/4: 5657 + (5657/3)
95/5: 1500 * (1.2/2500)
95/6: 0.34 * 126244.72
95/7: 17011/0.03
95/8: (7011/0.03) * 0.05
95/9: (17011/0.03) * 0.05
95/10: 0.05 * 12200
95/11: 610 - (3/4*610)
95/12: 1007980 * 1.2 /10
95/13: (1540360 * 0.9)/5
95/14: (1540360 * 0.1)/5
95/15: (1540360 * 0.1)
95/16: 440906/1224740
95/17: 0.26 * 0.25
95/18: 0.065 * 210478
96/1:
for i in edge:
    if i[0] != i[1]
    edge_dic2.setdefault(i[0], []).append(i[1])
print(edge_dic2)
edge_dic3=edge_dic2
96/2:
for i in edge:
    if i[0] != i[1] :
    edge_dic2.setdefault(i[0], []).append(i[1])
print(edge_dic2)
edge_dic3=edge_dic2
96/3:
for i in edge:
    if i[0] != i[1] :
        edge_dic2.setdefault(i[0], []).append(i[1])
print(edge_dic2)
edge_dic3=edge_dic2
96/4:
# Enter your answer to Problem 1 here. 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)   
edge = list(edge)
edge[0:10]
96/5:
# Enter your answer to Problem 2 here. 

edge1=[]
for i in edge :
    j = i[0]
    edge1.append(j)
    
edge2 = set(edge1)
edge2 = list(edge2)
edge2[0:10]
96/6:
len(edge2)
# answer : 5242
96/7:
edge_dic2 = {}
for i in edge2 :
    edge_dic2[i] = []
96/8:
edge_dic2_values_list = list(edge_dic2.values())
edge_dic2_values_list[0:10]
96/9:
for i in edge:
    if i[0] != i[1] :
        edge_dic2.setdefault(i[0], []).append(i[1])
print(edge_dic2)
edge_dic3=edge_dic2
97/1:
# Enter your answer to Problem 4 below. 


class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = UndirectedNetwork1()
        self.susceptible_nodes = []
97/2:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = UndirectedNetwork1()
        self.susceptible_nodes = [i for i in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
97/3:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
97/4:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = UndirectedNetwork1()
        self.susceptible_nodes = [i for i in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/5:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = UndirectedNetwork()
        self.susceptible_nodes = [i for i in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/6:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
97/7:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = UndirectedNetwork()
        self.susceptible_nodes = [i for i in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/8:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [i for i in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/9:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in self.network()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/10:
a = {1:2, 3:4}
[i for i in a]
97/11:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in Nodes]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/12:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return print(self)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
97/13:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return print(self)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
Nodes
97/14:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return print(self)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
97/15:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return print(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
97/16:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return self.nodes
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
97/17:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        print(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
97/18:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
97/19:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
Nodes
97/20:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
str(Nodes)
97/21:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return self.nodes.values()
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
97/22:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in Nodes]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/23:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in print(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/24:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in Nodes]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/25:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(self.network), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/26:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(Nodes), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/27:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(liststr((Nodes)), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/28:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(str((Nodes)), self.n)
        return len(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(1)
97/29:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(str((Nodes)), self.n)
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(1)
97/30:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(list(str((Nodes)), self.n))
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(1)
97/31:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str((Nodes), self.n))
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(1)
97/32:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str((Nodes), str(self.n)))
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(1)
97/33:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str((Nodes), n))
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(1)
97/34:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(1)
97/35:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/36:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = self.infected_nodes.append(random.sample(str(Nodes), n))
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/37:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/38:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(len(self.random_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/39:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes = infected_nodes.append(ramdom_nodes)
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/40:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes = self.infected_nodes.append(ramdom_nodes)
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/41:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes = self.infected_nodes.append(self.ramdom_nodes)
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/42:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes = self.infected_nodes.append(self.ramdom_nodes)
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/43:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes = self.infected_nodes.append(self.random_nodes)
        print(len(self.infected_nodes))
        
Model = SIModel()
Model.__initialize__(2)
97/44:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes = self.infected_nodes.append(self.random_nodes)
        print(self.infected_nodes)
        
Model = SIModel()
Model.__initialize__(2)
97/45:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(self.random_nodes)
        
Model = SIModel()
Model.__initialize__(2)
98/1:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return (values for values in self.nodes.values())
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        
Nodes.add_node(123)
Nodes.add_node(145)
Nodes.get_node_ids()
print(Nodes)
98/2:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return self.nodes.keys()
    
    def get_node_neighbors(self): 
        return (values for values in self.nodes.values())
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/3:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return (keys for keys in self.nodes.keys())
    
    def get_node_neighbors(self): 
        return (values for values in self.nodes.values())
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/4:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return (keys for keys in self.nodes.keys())
    
    def get_node_neighbors(self): 
        print (values for values in self.nodes.values())
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/5:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return (keys for keys in self.nodes.keys())
    
    def get_node_neighbors(self): 
        generator = (values for values in self.nodes.values())
        return generator 
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/6:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return (keys for keys in self.nodes.keys())
    
    def get_node_neighbors(self): 
        generator = (values for values in self.nodes.values())
        return self.generator 
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/7:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        return (keys for keys in self.nodes.keys())
    
    def get_node_neighbors(self): 
        generator = self.nodes.values()
        for i in generator : 
            print(i)
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/8:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            print(i)
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/9:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            return i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/10:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/11:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        ""
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/12:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        self.nodes[ego_id] = self.alter_id
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.get_node_ids()
98/13:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        self.nodes[ego_id] = self.alter_id
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
98/14:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        self.nodes[ego_id] = self.alter_id
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
print(Nodes)
98/15:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        self.nodes[ego_id] = self.alter_id
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/16:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        self.nodes[ego_id] = self.alter_id
        self.nodes[alter_id] = self.ego_id
      
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/17:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
        self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/18:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
        
        
        
    def get_node_ids(self) : 
        generator = self.nodes.keys()
        for i in generator : 
            yield i
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/19:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return self.nodes
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/20:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/21:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return self.susceptible_nodes

        
Model = SIModel()
Model.__initialize__(2)
98/22:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return self.susceptible_nodes

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/23:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/24:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/25:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in Nodes]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/26:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = self.network()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/27:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = self.network.keys()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/28:
# Enter your answer to Problem 4 below. 
import random

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = self.network.keys()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/29:
# Enter your answer to Problem 4 below. 
import random

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = self.network()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/30:
# Enter your answer to Problem 4 below. 
import random

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in dict(str(Nodes))]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/31:
# Enter your answer to Problem 4 below. 
import random

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/32:
# Enter your answer to Problem 4 below. 
import random

class SIModel(Object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/33:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/34:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in ast.literal_eval(str(Nodes))]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        #self.random_nodes = random.sample(str(Nodes), n)
        #print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(2)
print(Model)
98/35:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in ast.literal_eval(str(Nodes))]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/36:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/37:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(self.network, n)
        print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/38:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(self.network.keys(), n)
        print(self.random_nodes)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/39:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.random_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/40:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes), str(self.infected_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/41:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_neighbors(123, 344)
print(Nodes)
98/42:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes() : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        return self.n 
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes), str(self.infected_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/43:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes() : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        return self.n 
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
98/44:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes() : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        return self.n 
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
Model.update
98/45:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes() : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
Model.update
98/46:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes() : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
Model.update()
98/47:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in set(self.susceptible_nodes()) : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
Model.update()
98/48:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in set(self.susceptible_nodes) : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
Model.update()
98/49:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in set(self.susceptible_nodes) : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.__initialize__(1)
print(Model)
Model.update()
98/50:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in set(self.susceptible_nodes) : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
98/51:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in set(self.susceptible_nodes) : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
98/52:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes = random.sample(self.network.keys(), n)
        print(self.n)
        
    def update(self) : 
        """
        """
        for i in set(self.susceptible_nodes) : 
            if i in self.infected_nodes : 
                self.infected_nodes.append(self.network[i])
                self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
98/53:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/54:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id 
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
        else : 
            self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/55:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = [ego_id]
        self.alter_id = [alter_id]
        for i in self.ego_id : 
            if i in self.nodes.keys() :
            self.nodes[ego_id] = self.alter_id
            else : 
            self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/56:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = [ego_id]
        self.alter_id = [alter_id]
        for i in self.ego_id : 
            if i in self.nodes.keys() :
                self.nodes[ego_id] = self.alter_id
            else : 
                self.nodes[alter_id] = self.ego_id
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/57:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = [ego_id]
        self.alter_id = [alter_id]
        for i in self.ego_id : 
            if i in self.nodes.keys() :
                self.ego_id.append(self.alter_id)
            else : 
                self.alter_id.append(self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/58:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = [ego_id]
        self.alter_id = [alter_id]
        for i in self.ego_id : 
            if i in self.nodes.keys() :
                self.ego_id.append(self.nodes[i])
            else : 
                self.alter_id.append(self.nodes[i])
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/59:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        for i in self.ego_id : 
            if i in self.nodes.keys() :
                self.nodes.update(i = self.alter_id)
            else : 
                self.nodes.update(i = self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/60:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update(i = self.alter_id)
        else : 
            self.nodes.update(i = self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/61:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update(self.ego_id = self.alter_id)
        else : 
            self.nodes.update(self.alter_id = self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/62:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update(ego_id = self.alter_id)
        else : 
            self.nodes.update(alter_id = self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/63:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update(self.ego_id = self.alter_id)
        else : 
            self.nodes.update(self.alter_id = self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/64:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id = self.alter_id})
        else : 
            self.nodes.update({self.alter_id = self.ego_id})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/65:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : self.alter_id})
        else : 
            self.nodes.update({self.alter_id : self.ego_id})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/66:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    self.ego_id_list = []
    self.alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : 
                               self.alter_id_list.append(self.alter_id)})
        else : 
            self.nodes.update({self.alter_id : 
                               self.ego_id_list.append(self.ego_id)})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/67:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : 
                               alter_id_list.append(self.alter_id)})
        else : 
            self.nodes.update({self.alter_id : 
                              ego_id_list.append(self.ego_id)})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/68:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : 
                               self.alter_id_list.append(self.alter_id)})
        else : 
            self.nodes.update({self.alter_id : 
                              self.ego_id_list.append(self.ego_id)})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/69:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id 
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : 
                               self.alter_id_list.append(self.alter_id)})
        else : 
            self.nodes.update({self.alter_id : 
                              self.ego_id_list.append(self.ego_id)})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
98/70:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = None
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : self.alter_id_list})
        else : 
            self.nodes.update({self.alter_id : self.ego_id_list})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/1:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : self.alter_id_list})
        else : 
            self.nodes.update({self.alter_id : self.ego_id_list})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/2:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : self.alter_id_list})
        else : 
            self.nodes.update({self.alter_id : self.ego_id_list})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_nodes(123)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/3:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : self.alter_id_list})
        else : 
            self.nodes.update({self.alter_id : self.ego_id_list})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_node(123)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/4:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes.update({self.ego_id : self.alter_id})
        else : 
            self.nodes.update({self.alter_id : self.ego_id})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/5:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes = self.nodes.update({self.ego_id : self.alter_id})
        else : 
            self.nodes = self.nodes.update({self.alter_id : self.ego_id})
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/6:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    ego_id_list = []
    alter_id_list = []
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        self.ego_id_list.append(self.ego_id)
        self.alter_id_list.append(self.alter_id)
        if self.ego_id in self.nodes.keys() :
            self.nodes[self.ego_id].append(self.alter_id)
        else : 
            self.nodes[self.alter_id].append(self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
99/7:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        if self.ego_id in self.nodes.keys() :
            self.nodes[self.ego_id].append(self.alter_id)
        else : 
            self.nodes[self.alter_id].append(self.ego_id)
      
    
    def get_node_neighbors(self): 
        return self.nodes.values()
        
    
    def __str__(self) : 
        return str(self.nodes)
    
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/1:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        try :
        self.nodes[self.ego_id].append(self.alter_id)
        self.nodes[self.alter_id].append(self.ego_id)
        except : 
            raise KeyError('ID not in nodes')
     
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with'.len(self.nodes)
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/2:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id
        try :
            self.nodes[self.ego_id].append(self.alter_id)
            self.nodes[self.alter_id].append(self.ego_id)
        except : 
            raise KeyError('ID not in nodes')
     
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with'.len(self.nodes)
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/3:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with'.len(self.nodes)
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/4:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with', len(self.nodes)
        
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/5:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with'
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/6:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return self.nodes
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/7:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/8:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
Nodes.add_neighors(344, 123)
print(Nodes)
100/9:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
Nodes.add_neighbors(344, 123)
print(Nodes)
100/10:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)

print(Nodes)
100/11:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
Nodes.add_neighbors(344, 123)

print(Nodes)
100/12:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
Nodes.add_neighbors(344, 123)
Nodes.get_node_ids
100/13:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
Nodes.add_neighbors(344, 123)
Nodes.get_node_ids()
100/14:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
Nodes.add_neighbors(344, 123)
Nodes.get_node_neighbors()
100/15:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(self.nodes)
    
Nodes = UndirectedNetwork()
        

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_node(123)
100/16:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork()
100/17:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork()

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
101/1:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)
edge1=[]
for i in edge :
    j = i[0]
    edge1.append(j)

Nodes = UndirectedNetwork()
    
Nodes.add_node(edge1)
Nodes.add_neighbors(edge)
Nodes.get_node_ids
Nodes.get_node_neighbors
101/2:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with', str(len(self.nodes))
101/3:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)
edge1=[]
for i in edge :
    j = i[0]
    edge1.append(j)

Nodes = UndirectedNetwork()
    
Nodes.add_node(edge1)
Nodes.add_neighbors(edge)
Nodes.get_node_ids
Nodes.get_node_neighbors
101/4:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)
edge1=[]
for i in edge :
    j = i[0]
    edge1.append(j)

Nodes = UndirectedNetwork()
    
edge1
101/5:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)
edge1=[]
for i in edge :
    j = i[0]
    edge1.append(j)

Nodes = UndirectedNetwork()
    
for i in edge1 : 
    Nodes.add_node(i)
101/6:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)
edge1=[]
for i in edge :
    j = i[0]
    edge1.append(j)

Nodes = UndirectedNetwork()
    
for i in edge1 : 
    Nodes.add_node(i)

edge
101/7:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

edge_authors=[]

for i in edge :
    j = i[0]
    edge1.append(j)

Nodes = UndirectedNetwork()
    
for i in edge1 : 
    Nodes.add_node(i)

authors_dct = {key : [] for key in edge_authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

print(authors_dct)
101/8:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

edge_authors=[]

for i in edge :
    j = i[0]
    edge_authors.append(j)

Nodes = UndirectedNetwork()
    
for i in edge1 : 
    Nodes.add_node(i)

authors_dct = {key : [] for key in edge_authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

print(authors_dct)
101/9:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)

Nodes = UndirectedNetwork()
    
for i in edge1 : 
    Nodes.add_node(i)

authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]
101/10:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)
101/11:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)
    
print(Nodes)
101/12:
a = {a : 1, b : 2}
len(a)
101/13:
a = {'x' : 1, 'b' : 2}
len(a)
101/14:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return 'Undirected network with', str(int(len(self.nodes)))
101/15:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)
    
print(Nodes)
101/16:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
101/17:
text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]




Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)
    
print(Nodes)
101/18:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in edge : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/19:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in len(edge) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/20:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/21:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/22:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return self.nodes[:10]
101/23:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/24:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return list(self.nodes.items())[:5]
101/25:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/26:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/27:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(list(self.nodes.items())[:5])
101/28:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/29:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes())
101/30:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes()))
101/31:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/32:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
101/33:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/34: # Enter your answer to Problem 4 below.
101/35:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return "Undirected Network with" + str(len(self.nodes))
101/36:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/37:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return "Undirected Network with",  str(len(self.nodes)), "Nodes"
101/38:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/39:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
      
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return "Undirected Network with " +  str(len(self.nodes)) + " Nodes"
101/40:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
100/18:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        try :
        self.n = n
        self.infected_nodes.append(random.sample(self.network.keys(), n))
        print(self.n)
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/19:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
        print(self.n)
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        print(self.n)
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/20:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
        print(self.n)
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/21:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/22:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in list(self.network)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/23:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = set(ast.literal_eval(str(Nodes)))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/24:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/25:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = ast.literal_eval(str(Nodes))
        self.susceptible_nodes = [keys for keys in self.network.keys()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/26:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork()

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/27:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in self.network.keys()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/28:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in self.network]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/29:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork()

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 
Nodes.__init__
100/30:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork()

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 
Nodes.__init__()
100/31:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self): 
        """
        takes node_id and returns its neighbors one at a time
        """
        generator_edges = (values for values in self.nodes.values()) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork()

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/32:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/33:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        
        try :
            self.infected_nodes.append(random.sample(self.network.keys(), self.n))
            return self.n
        except : 
            raise ValueError('n exceeds number of nodes')
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/34:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.network.keys(), self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/35:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network[i] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/36:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes)
100/37:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 
Nodes.get_node_neighbors(123)
100/38:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/39:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self) : 
        """
        """
        self.network = Nodes
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in [self.network.get_node_neighbors(i)] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/40:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork()
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in [self.network.get_node_neighbors(i)] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel()
Model.initialize(1)
Model.update()
print(Model)
100/41:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork()
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in [self.network.get_node_neighbors(i)] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/42:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in [self.network.get_node_neighbors(i)] :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/43:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [self.network.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/44:
generator1 = (0,1,2,4)
for i in generator1 : 
    print i
100/45:
generator1 = (0,1,2,4)
for i in generator1 : 
    print (i)
100/46:
def generator() :
    generator1 = (0,1,2,4)
    for i in generator1 : 
        print (i)
100/47:
def generator() :
    generator1 = (0,1,2,4)
    for i in generator1 : 
        print (i) 
        
generator
100/48:
def generator() :
    generator1 = (0,1,2,4)
    for i in generator1 : 
        print (i) 
        
generator()
100/49:
def generator() :
    generator1 = (0,1,2,4)
    for i in generator1 : 
        print (i) 
        
for j in generator() : 
    print(j)
100/50:
def generator() :
    generator1 = (0,1,2,4)
    for i in generator1 : 
        print (i) 
        
for j in generator1() : 
    print(j)
100/51:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 
for i in Nodes.get_node_neighbors(123) : 
    print(i)
100/52:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/53:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

class(Nodes.get_node_neighbors(123))
100/54:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

type(Nodes.get_node_neighbors(123))
100/55:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[node_id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/56:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/57:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(self,i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/58:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/59:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(self,i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/60:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(self,i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/61:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(self,i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(j)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/62:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, UndirectedNetwork) : 
        """
        """
        self.network = UndirectedNetwork
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(self, i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/63:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids(self.network)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
            
        
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in UndirectedNetwork.get_node_neighbors(self, i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
                    self.n += 1
                
        return self.n
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/64:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids(self.network)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
Model.update()
print(Model)
100/65:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [UndirectedNetwork.get_node_ids(self.network)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
            
        
        
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/66:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/67:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print (k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        for v in generator_edges : 
            print (v)
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/68:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/69:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/70:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = self.network.get_node_ids()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/71:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = list(self.network.get_node_ids())
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/72:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = list(self.network.get_node_ids())
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/73:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = list(UndirectedNetwork.get_node_ids())
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/74:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(UndirectedNetwork) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = list(UndirectedNetwork.get_node_ids(self))
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/75:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = self.network.keys()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel()
SIModel.__init__(Nodes)
Model.initialize(1)
print(Model)
100/76:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = self.network.keys()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/77:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = self.network.get_node_ids()
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/78:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = list(self.network.get_node_ids())
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/79:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/80:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            return yield k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        for v in generator_edges : 
            return yield v
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/81:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            yield k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        for v in generator_edges : 
            yield v
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
102/1:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object): 
    """
    Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self):       
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes.append(self.random_nodes)
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __update__(self) : 
        """
        iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.infected_nodes:
            if i in self.susceptible_nodes: 
                self.infected_nodes.append(i)
            else : 
                pass
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __run__(self) : 
        """
        repeats update until all nodes are infected or until update has been run 30 times
        """
        for j in range(30) :
            self.update()
            print(self.num_infected)
            
    def __str__(self) : 
        """
        the number of infected nodes
        """
        return str(self.num_infected)
102/2:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object): 
    """
    Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self):       
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes.append(self.random_nodes)
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __update__(self) : 
        """
        iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.infected_nodes:
            if i in self.susceptible_nodes: 
                self.infected_nodes.append(i)
            else : 
                pass
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __run__(self) : 
        """
        repeats update until all nodes are infected or until update has been run 30 times
        """
        for j in range(30) :
            self.update()
            print(self.num_infected)
            
    def __str__(self) : 
        """
        the number of infected nodes
        """
        return str(self.num_infected)

print(SIModel)
102/3:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object): 
    """
    Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self):       
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes.append(self.random_nodes)
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __update__(self) : 
        """
        iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.infected_nodes:
            if i in self.susceptible_nodes: 
                self.infected_nodes.append(i)
            else : 
                pass
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __run__(self) : 
        """
        repeats update until all nodes are infected or until update has been run 30 times
        """
        for j in range(30) :
            self.update()
            print(self.num_infected)
            
    def __str__(self) : 
        """
        the number of infected nodes
        """
        return str(self.num_infected)

print(SIModel())
102/4:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object): 
    """
    Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self):       
        self.network = Nodes
        self.susceptible_nodes = [keys for keys in str(Nodes)]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def __initialize__(self, n) : 
        """
        randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.random_nodes = random.sample(str(Nodes), n)
        self.infected_nodes.append(self.random_nodes)
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __update__(self) : 
        """
        iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.infected_nodes:
            if i in self.susceptible_nodes: 
                self.infected_nodes.append(i)
            else : 
                pass
        self.num_infected = len(self.infected_nodes)
        print(self.num_infected)
        
    def __run__(self) : 
        """
        repeats update until all nodes are infected or until update has been run 30 times
        """
        for j in range(30) :
            self.update()
            print(self.num_infected)
            
    def __str__(self) : 
        """
        the number of infected nodes
        """
        return str(self.num_infected)

print(SIModel)
100/82:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        yield generator_nodes
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        yield generator_edges
        
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/83:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in generator_nodes : 
            print(k)
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        for v in generator_edges : 
            print(v)
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/84:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator_nodes = (keys for keys in self.nodes.keys())
        for k in self.generator_nodes() : 
            yield k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator_edges = (values for values in self.nodes[self.id]) 
        for v in self.generator_edges : 
            yield v
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/85:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() :
            yield k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] :
            yield v
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/86:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() :
            yield k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] :
            yield v
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

print(Nodes.get_node_neighbors(123))
100/87:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() :
            yield k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] :
            yield v
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/88:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator = (keys for keys in self.nodes.keys())
        for k in generator : 
            return k
    
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator1 = (values for values in self.nodes[self.id]) 
        for v in generator1 : 
            return v
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/89:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        generator = (keys for keys in self.nodes.keys())
        for k in generator : 
            print(k)
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        generator1 = (values for values in self.nodes[self.id]) 
        for v in generator1 : 
            print(v)
    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.get_node_neighbors(123)
100/90:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/91:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in enumerate(self.network.get_node_ids())]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/92:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield key
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

for i in Nodes.get_node_neighbors(123) : 
    print(i)
100/93:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield key
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

for i in Nodes.get_node_neighbors(123) : 
    print(i)
100/94:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/95:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

for i in Nodes.get_node_neighbors(123) : 
    print(i)
100/96:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.susceptible_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/97:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/98:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(set(random.sample(self.susceptible_nodes, self.n)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/99:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(int(random.sample(self.susceptible_nodes, self.n)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/100:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(str(random.sample(self.susceptible_nodes, self.n)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/101:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(i for i in (random.sample(self.susceptible_nodes, self.n)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/102:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/103:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        random = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(random[j] for j in range(len(random)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/104:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(ran[j] for j in range(len(ran)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/105:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(ran[j] for j in range(len(ran)))
                
    def __str__(self) : 
        """
        """
        return str(ran)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/106:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(ran[j] for j in range(len(ran)))
                
    def __str__(self) : 
        """
        """
        return str(self.ran)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/107:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(ran[j] for j in range(len(ran)))
                
    def __str__(self) : 
        """
        """
        return str(self.ran)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/108:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(self.ran[j] for j in range(len(self.ran)))
                
    def __str__(self) : 
        """
        """
        return str(self.ran)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/109:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(self.ran[j] for j in range(len(self.ran)))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/110:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n)[i] for i in range(self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/111:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n)[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/112:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = [i for i in random.sample(self.susceptible_nodes, self.n)]
        self.infected_nodes.append(random.sample(self.susceptible_nodes, self.n))
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/113:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/114:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/115:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/116:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/117:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(1)
print(Model)
100/118:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(2)
print(Model)
100/119:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/120:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(4)
print(Model)
100/121:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(5)
print(Model)
100/122:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
            self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(6)
print(Model)
100/123:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        try : 
            for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
        except : 
            raise ValuError('n higher than the number of nodes')
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(6)
print(Model)
100/124:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        try : 
            for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
        except : 
            raise ValuError('n higher than the number of nodes')
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(6)
print(Model)
100/125:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        try : 
            for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
        except : 
            raise ValueError('n higher than the number of nodes')
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(6)
print(Model)
100/126:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(6)
print(Model)
100/127:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/128:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
                    self.n += 1
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/129:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/130:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/131:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/132:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/133:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/134:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/135:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/136:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/137:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/138:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/139:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
print(Model)
100/140:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/141:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/142:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
print(Model)
100/143:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/144:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/145:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/146:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/147:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.infected_nodes
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/148:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/149:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/150:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/151:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/152:
lst = [1,2,3]

for i in lst : 
    lst.append(i)
100/153:
lst = [1,2,3]

for i in lst : 
    lst.append(i)
    
print(lst)
100/154:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.__str__()
100/155:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) != int(self.network__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
100/156:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) != int(self.network__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
100/157:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) != int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
100/158:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
100/159:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/160:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/161:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/162:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/163:
# Enter your answer to Problem 4 below. 
import random
import ast

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.n = len(self.infected_nodes)
                
        return self.n
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.infected_nodes)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/164:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(len(self.num_infected))

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/165:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/166:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/167:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/168:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/169:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/170:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.num_infected = len(self.infected_nodes)
        
        self.susceptible_nodes = 
        list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/171:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.num_infected = len(self.infected_nodes)
        
        self.susceptible_nodes = list
        (set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/172:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.num_infected = len(self.infected_nodes)
        
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/173:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        
        self.num_infected = len(self.infected_nodes)
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/174:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return str(len(self.nodes))
    
Nodes = UndirectedNetwork() #instantiation

Nodes.add_node(123)
Nodes.add_node(344)
Nodes.add_node(456)
Nodes.add_node(368)
Nodes.add_node(380)
Nodes.add_neighbors(123, 344)
Nodes.add_neighbors(123, 368)
Nodes.add_neighbors(344, 360)
Nodes.add_neighbors(123, 380)
print(Nodes) 

Nodes.__str__()
100/175:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        
        self.num_infected = len(self.infected_nodes)
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/176:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/177:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/178:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/179:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/180:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/181:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/182:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/183:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/184:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/185:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/186:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/187:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/188:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/189:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/190:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
100/191:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)

        
Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
101/41:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)
101/42:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
101/43:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
101/44:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)
authors_dct = {key : [] for key in authors}
authors_dct = {keys : [element[1] for element in edge
                       if element[0] == keys and element[1] != keys] 
               for keys in authors_dct}

coauthors = [authors_dct[keys] for keys in authors]


#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/45:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)



#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
101/46:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < int(self.network.__str__()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)
101/47:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
101/48:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < len(self.network.nodes()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)
101/49:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
101/50:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < len(self.network.nodes) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)
101/51:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
101/52:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
101/53:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
103/1:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
103/2:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
103/3:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)



#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
103/4:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
    """
    
    def __init__(self, Network) : 
        """
        """
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        """
        n = 0
        while len(self.infected_nodes) < 5242 or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        """
        return str(self.num_infected)
103/5:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
103/6:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making network nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        Takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        Takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        Returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        Takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        Prints the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
103/7:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)



#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
103/8:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while len(self.infected_nodes) < 5242 or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
103/9:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)
104/1:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making network nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        Takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        Takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        Returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        Takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        Prints the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
104/2:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)



#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
104/3:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while len(self.infected_nodes) < 5242 or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
104/4:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while len(self.infected_nodes) < len(self.network.nodes()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
104/5:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in 
                                  self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while len(self.infected_nodes) < len(self.network.nodes()) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
104/6:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in 
                                  self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while self.num_infected < len(self.network.nodes) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
104/7:
# Enter your answer to Problem 5 below. 

Model = SIModel(Nodes)
Model.initialize(3)
Model.update()
Model.run()
print(Model)

#The execution of model is taking way too long and not happening
105/1:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making network nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        Takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        Takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        Returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        Takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        Prints the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
105/2:
# Enter your answer to Problem 2 below.

class UndirectedNetwork(object): 
    """
    Create a class making network nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        Takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        Takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        Returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        Takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        Prints the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
105/3:
#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)



#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
105/4:
# Enter your answer to Problem 4 below. 

import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in 
                                  self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while self.num_infected < len(self.network.nodes) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
100/192:
# Enter your answer to Problem 2 below.


class UndirectedNetwork(object): 
    """
    Create a class making network nodes which is a dictionary where the node id is a key and the value is a list with the ids of the node's neighbors
    """
    
    def __init__(self): 
        self.nodes = {}
    
    def add_node(self, node_id) : 
        """
        Takes node_id as a key to nodes
        """
        self.node_id = node_id
        if self.node_id not in self.nodes.keys() :
            self.nodes[node_id] = []
        else : 
            return 'ID already added'
        
    def add_neighbors(self, ego_id, alter_id) : 
        """
        Takes ego_id and alter_id as elements of list of neighbors of each other, respectively
        """
        self.ego_id = ego_id
        self.alter_id = alter_id

        if self.ego_id in self.nodes.keys() : 
            if self.alter_id not in self.nodes[self.ego_id] :
                self.nodes[self.ego_id].append(self.alter_id)
        
        if self.alter_id in self.nodes.keys() : 
            if self.ego_id not in self.nodes[self.alter_id] :
                self.nodes[self.alter_id].append(self.ego_id)
    
    def get_node_ids(self): 
        """
        Returns the ids of the nodes in the network one at a time
        """
        for keys in self.nodes.keys() : 
            yield keys
            
    def get_node_neighbors(self, node_id): 
        """
        Takes node_id and returns its neighbors one at a time
        """
        self.id = node_id
        for values in self.nodes[self.id] : 
            yield values 

    
    def __str__(self) : 
        """
        Prints the number of nodes in the network
        """
        return "Undirected network with " + str(len(self.nodes)) + " Nodes"
100/193:
# Enter your answer to Problem 3 below. 

#Part1 - Reading the file 

text = open('ca-GrQc.txt', 'r')
lines = text.readlines()[4:]


#Part2 - Forming the authors-coauthors dict
edge = []
for line in lines:
    line = line.split()
    line_list = [int(i) for i in line]
    edge.append(line_list)

authors = []

for i in edge :
    j = i[0]
    authors.append(j)



#Part3 - Network Instantiation 

Nodes = UndirectedNetwork()
    
for i in authors : 
    Nodes.add_node(i)

for i in range(len(edge)) : 
    Nodes.add_neighbors(edge[i][0], edge[i][1])

    
print(Nodes)
100/194:
# Enter your answer to Problem 4 below. 
import random

class SIModel(object) : 
    """
     Create a class which simulates the contagion of disease or information on an empirical network
    """
    
    def __init__(self, Network) : 
        self.network = Network
        self.susceptible_nodes = [i for i in 
                                  self.network.get_node_ids()]
        self.infected_nodes = []
        self.num_infected = 0 
        
    def initialize(self, n) : 
        """
        Randomly selects n number of nodes and infects them; then prints the number of infected nodes
        """
        self.n = n
        self.ran = random.sample(self.susceptible_nodes, self.n)
        for i in range(self.n) : 
                self.infected_nodes.append(self.ran[i])
                
        self.susceptible_nodes = list(set(self.susceptible_nodes) - set(self.infected_nodes))
                
    def update(self) : 
        """
        Iterates over the susceptible nodes in random order and infects those who have at least one infected neighbor; 
        then prints the number of infected nodes
        """
        for i in self.susceptible_nodes : 
            for j in self.network.get_node_neighbors(i) :
                if j in self.infected_nodes : 
                    if i not in self.infected_nodes :
                        self.infected_nodes.append(i)
        
        self.num_infected = len(self.infected_nodes)
      
    
    def run(self) : 
        """
        Repeats update until all nodes are infected or until update has been run 30 times
        """
        n = 0
        while self.num_infected < len(self.network.nodes) or n < 30 :  
            self.update()
            n += 1
                
    def __str__(self) : 
        """
        The number of infected nodes
        """
        return str(self.num_infected)
108/1:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    temp = random.shuffle(data_list)
    test_set_size = int(len(data_list) * test_ratio)
    
    training_data = temp[:test_set_size]
    testing_data = temp[test_set_size:]
    
    return training_data, testing_data
108/2:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    temp = random.shuffle(data_list)
    test_set_size = int(len(data_list) * test_ratio)
    
    training_data = temp[:test_set_size]
    testing_data = temp[test_set_size:]
    
    return training_data, testing_data 

split_training_testing([1,2,3], 0.5)
108/3:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    temp = random.shuffle(data_list)
    test_set_size = int(len(data_list) * test_ratio)
    
    training_data = temp[:test_set_size]
    testing_data = temp[test_set_size:]
    
    return training_data, testing_data 

split_training_testing([1,2,3,4], 0.5)
108/4:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    temp = random.shuffle(data_list)
    test_set_size = int(len(data_list) * test_ratio)
    
    training_data = temp[:test_set_size]
    testing_data = temp[test_set_size:]
    
    return temp

split_training_testing([1,2,3,4], 0.5)
108/5:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    temp = random.shuffle(data_list)
    test_set_size = int(len(data_list) * test_ratio)
    
    
    
    return temp

split_training_testing([1,2,3,4], 0.5)
108/6:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    temp = random.shuffle(data_list)
    test_set_size = int(len(data_list) * test_ratio)
    
    
    
    return [temp for temp in temp]

split_training_testing([1,2,3,4], 0.5)
108/7:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set_size)
    
    
    
    return train_test, test_set

split_training_testing([1,2,3,4], 0.5)
108/8:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set_size)
                     
    return train_test, test_set

split_training_testing([1,2,3,4], 0.5)
108/9:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set_size)
                     return train_test, test_set

split_training_testing([1,2,3,4], 0.5)
108/10:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set_size)
    return train_test, test_set

split_training_testing([1,2,3,4], 0.5)
108/11:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set_size))
    return train_test, test_set

split_training_testing([1,2,3,4], 0.5)
108/12:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_test, test_set

split_training_testing([1,2,3,4], 0.5)
108/13:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.5)
108/14:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.1)
108/15:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.2)
108/16:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/17:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/18:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/19:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/20:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/21:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/22:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.3)
108/23:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set

split_training_testing([1,2,3,4], 0.6)
108/24:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    train_set = list(set(data_list) - set(test_set))
    return train_set, test_set
108/25:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    
    for data_list, test_set in zip(data_list, test_set) : 
        train_set.append(data_list - test_set)
        
    return train_set, test_set
108/26:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_set = random.sample(data_list, test_set_size)
    
    for data_list, test_set in zip(data_list, test_set) : 
        train_set.append(data_list - test_set)
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/27:
data = [1,2,3,4,5]
random_indices = random.sample(range(len(data)))
random_indices
108/28:
data = [1,2,3,4,5]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/29:
data = [1,2,3,4,5]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/30:
data = [1,2,3,4,5]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/31:
data = [1,2,3,4,5]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/32:
data = [1,2,3,4,5]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/33:
data = [0,0,0,0]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/34:
data = [0,0,0,0]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/35:
data = [0,0,0,0]
random_indices = random.sample(range(len(data)), 3)
random_indices
108/36:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    
    test_set_size = int(len(data_list) * test_ratio)
    
    random_indices = random.sample(range(len(data_list)))
    test_indices = random_indices[test_set_size:]
    
    test_set = data_list[test_indices]
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/37:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    
    test_set_size = int(len(data_list) * test_ratio)
    
    random_indices = random.sample(range(len(data_list)), test_set_size)
    test_indices = random_indices[test_set_size:]
    
    test_set = data_list[test_indices]
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/38:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    
    test_set_size = int(len(data_list) * test_ratio)
    
    random_indices = random.sample(range(len(data_list)), test_set_size)
    test_indices = random_indices[test_set_size:]
    
    for i in test_indices : 
        test_set.append(data_list[i])
        
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/39:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    random_indices = random.sample(range(len(data_list)), test_set_size)
    test_indices = random_indices[test_set_size:]
    
    for i in test_indices : 
        test_set.append(data_list[i])
        
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/40:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    
    for i in test_indices : 
        test_set.append(data_list[i])
        
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/41:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    
    for i in test_indices : 
        test_set.append(data_list[i])
        
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,1,2], 0.5)
108/42:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    
    for i in test_indices : 
        test_set.append(data_list[i])
        
    train_set = [x for x in data_list if x not in test_set]
    
        
    return train_set, test_set

split_training_testing([0,0,0], 0.5)
108/43:
data = [0,0,0,0]
data.append(0)
data
108/44:
data = [0,0,0,0]
range(len(data))
108/45:
data = [0,0,0,0]
list(range(len(data)))
108/46:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list)) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0], 0.5)
108/47:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0], 0.5)
108/48:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,0], 0.5)
108/49:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,0], 0.5)
108/50:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/51:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/52:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/53:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/54:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/55:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/56:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/57:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/58:
import random 

def split_training_testing(data_list, test_ratio) : 
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/59:
import random 

def split_training_testing(data_list, test_ratio) : 
    """"""
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/60:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
108/61:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) = len(actual_list) : 
        
        for i in len(range(predicted_list)) : 
            
            if predicted_list[i] = pos_class and actual_list[i] = neg_class : 
                True_Positive += 1
            elif predicted_list[i] = pos_class and actual_list[i] = neg_class : 
                False_Positive += 1 
            elif predicted_list[i] = neg_class and actual_list[i] = pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] = neg_class and actual_list[i] = neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/62:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in len(range(predicted_list)) : 
            
            if predicted_list[i] = pos_class and actual_list[i] = neg_class : 
                True_Positive += 1
            elif predicted_list[i] = pos_class and actual_list[i] = neg_class : 
                False_Positive += 1 
            elif predicted_list[i] = neg_class and actual_list[i] = pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] = neg_class and actual_list[i] = neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/63:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in len(range(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/64:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(predicted_list) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/65:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(len(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/66:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(len(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
    return  True_Positive, False_Positive, False_Nagetive, True_Negative
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/67:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(len(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
    return  True_Positive, False_Positive, False_Nagetive, True_Negative
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/68:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(len(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
    return  True_Positive, False_Positive, False_Nagetive, True_Negative
        
confusion_matrix([0,0,0,1], [1,0,0,1], 0)
108/69:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(len(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
    return  True_Positive, False_Positive, False_Nagetive, True_Negative
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/70:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    neg_class = 1 - pos_class 
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    if len(predicted_list) == len(actual_list) : 
        
        for i in range(len(predicted_list)) : 
            
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1 
    else : 
        print('Enter valid list')
        
    return  True_Positive, False_Positive, False_Nagetive, True_Negative
        
confusion_matrix([0,0,0,1], [1,0,0,1], 0)
108/71:
lst = [0,0,0]
set(lst)
108/72:
lst = [0,0,0]
set(lst) in (0)
108/73:
lst = [0,0,0]
set(lst) in {0}
108/74:
lst = [0,0,0]

set(lst) issubset {0}
108/75:
lst = [0,0,0]

set(lst).issubset{0}
108/76:
lst = [0,0,0]

set(lst).issubset({0})
108/77:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        if pos_class in (0,1) : 
        neg_class = 1 - pos_class 
        True_Positive = 0
        False_Positive = 0 
        False_Nagetive = 0 
        True_Negative = 0
         
            if len(predicted_list) == len(actual_list) : 
                for i in range(len(predicted_list)) : 
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                            False_Positive += 1 
                            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                                False_Nagetive += 1 
                                elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                                    True_Negative += 1
                                    
                                     return  True_Positive, False_Positive, False_Nagetive, True_Negative
                
            else : 
                print('Enter valid list')
    
        else : print('Enter positive class to be 1 or 0')
    
    else : print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 0)
108/78: 1 in (1,2)
108/79: 2 in (1,2)
108/80:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                            False_Positive += 1 
                            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                                False_Nagetive += 1 
                                elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                                    True_Negative += 1
                                    
                                     return  True_Positive, False_Positive, False_Nagetive, True_Negative
                else : 
                print('Enter valid list')
            else : print('Enter positive class to be 1 or 0')
        else : print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 0)
108/81:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                    return  True_Positive, False_Positive, False_Nagetive, True_Negative
                else : 
                print('Enter valid list')
            else : print('Enter positive class to be 1 or 0')
        else : print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 0)
108/82:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                    return  True_Positive, False_Positive, False_Nagetive, True_Negative
                else : 
                    print('Enter valid list')
            else : 
                print('Enter positive class to be 1 or 0')
        else : 
            print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 0)
108/83:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                    return  True_Positive, False_Positive, False_Nagetive, True_Negative
                else : 
                    print('Enter valid list')
            else : 
                print('Enter positive class to be 1 or 0')
        else : 
            print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/84:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                    return  True_Positive, False_Positive, False_Nagetive, True_Negative
                
                else : 
                    print('Enter valid list')
            else : 
                print('Enter positive class to be 1 or 0')
        else : 
            print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/85:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                return  True_Positive, False_Positive, False_Nagetive, True_Negative
                
                else : 
                    print('Enter valid list')
            else : 
                print('Enter positive class to be 1 or 0')
        else : 
            print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/86:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                return  True_Positive, False_Positive, False_Nagetive, True_Negative
            else : 
                print('Enter valid list')
        else : 
            print('Enter positive class to be 1 or 0')
    else : 
        print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
108/87:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                return  True_Positive, False_Positive, False_Nagetive, True_Negative
            else : 
                print('Enter valid list')
        else : 
            print('Enter positive class to be 1 or 0')
    else : 
        print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 2)
108/88:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                return  True_Positive, False_Positive, False_Nagetive, True_Negative
            else : 
                print('Enter valid list')
        else : 
            print('Enter positive class to be 1 or 0')
    else : 
        print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 2)
108/89:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                return  True_Positive, False_Positive, False_Nagetive, True_Negative
            else : 
                print('Enter valid list')
        else : 
            print('Enter positive class to be 1 or 0')
    else : 
        print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 1)
108/90:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    if set(predicted_list).issubset({0,1}) == True : 
        
        if pos_class in (0,1) : 
            neg_class = 1 - pos_class
            True_Positive = 0
            False_Positive = 0 
            False_Nagetive = 0 
            True_Negative = 0
            
            if len(predicted_list) == len(actual_list) : 
                
                for i in range(len(predicted_list)) : 
                    
                    if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                        True_Positive += 1
                    elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                        False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                        True_Negative += 1
                                    
                return  True_Positive, False_Positive, False_Nagetive, True_Negative
            else : 
                print('Enter valid list')
        else : 
            print('Enter positive class to be 1 or 0')
    else : 
        print('Enter valid list')
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 2)
109/1:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 50)
109/2:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing((0,0,0,1), 0.5)
109/3:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

split_training_testing([0,0,0,1], 0.5)
109/4:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

    except : 
        print(test_ratio, 'must be less than 1')

split_training_testing([0,0,0,1], 0.5)
109/5:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
        
    
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])


    
        
    return train_set, test_set

    except : 
        print(test_ratio, 'must be less than 1')

split_training_testing([0,0,0,1], 0.5)
109/6:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print(test_ratio, 'must be less than 1')

split_training_testing([0,0,0,1], 0.5)
109/7:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print(test_ratio, 'must be less than 1')

split_training_testing([0,0,0,1], 5)
109/8:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('test_ratio must be less than 1')

split_training_testing([0,0,0,1], 5)
109/9:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([0,0,0,1], 5)
109/10:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([0,0,0,1], 0)
109/11:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([0,0,0,1], 0.2)
109/12:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([0,0,0,1], 0.4)
109/13:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([], 0.4)
109/14:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([], 0.5)
109/15:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([], 1)
109/16:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([], )
109/17:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([], 0.1)
109/18:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1], 0.1)
109/19:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1], 0.5)
109/20:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1], 0.6)
109/21:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1], 0.8)
109/22:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1], 1)
109/23:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1)
109/24:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.2)
109/25:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.5)
109/26:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.2)
109/27:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.3)
109/28:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    try :
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    except : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.4)
109/29:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
        test_set = []
        train_set = []
        test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size < data_list :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.4)
109/30:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size < data_list :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.4)
109/31:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size < len(data_list) :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.4)
109/32:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size < len(data_list) :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1.01)
109/33:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size < len(data_list) :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1)
109/34:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size <= len(data_list) :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 1)
109/35:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
        
    if test_set_size <= len(data_list) :
        

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    else : 
        print('Test Ratio must be less than 1')

split_training_testing([1,0,0], 0.9)
109/36: int(2.7)
109/37:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1' #The function should only run if test_ratio is less than 1
        
   

        test_indices = random.sample(range(len(data_list)), test_set_size)
        for i in test_indices : 
            test_set.append(data_list[i])
            
        train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
        for i in train_indices :
            train_set.append(data_list[i])
            
        return train_set, test_set

    

split_training_testing([1,0,0], 0.9)
109/38:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1' #The function should only run if test_ratio is less than 1
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 0.9)
109/39:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1' #The function should only run if test_ratio is less than 1
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 1.2)
109/40:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1' #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 1.2)
109/41:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 1.2)
109/42:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing((1,0,0), 1.2)
109/43:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_set_size <= len(data_list), 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 1.2)
109/44:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 1.2)
109/45:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,0,0], 0.9)
109/46:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
            
    try : 
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
                elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                    False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                            True_Negative += 1
                            
                            return  True_Positive, False_Positive, False_Nagetive, True_Negative
    except : print('aaaa')
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 2)
109/47:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
            
    try : 
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
                elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                    False_Positive += 1 
                    elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                        False_Nagetive += 1 
                        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                            True_Negative += 1
                            
                            return  True_Positive, False_Positive, False_Nagetive, True_Negative
    except : print('aaaa')
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 2)
109/48:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
            
    try : 
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
                
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
                    
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
                        
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
        
        return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    except : print('aaaa')
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 2)
109/49:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
            
    try : 
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
                
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
                    
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
                        
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
        
        return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    except : print('aaaa')
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 1)
109/50:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
            
   
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
                
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
                    
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Nagetive += 1 
                        
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
        
        return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 1)
109/51:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
        True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
        False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
        False_Nagetive += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
        True_Negative += 1
                            
        

return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 1)
109/52:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
        

return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 1)
109/53:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
        

    return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,0], 1)
109/54:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], 0.5)
109/55:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], 0.9)
109/56:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], 0.5)
110/1:
import unittest
import class_eval

class TestSplitTrainTest(unittest.TestCase) : 
    """
    Test for splitting function 
    """
    
    def test_split_empty(self) :
    """
    Test empty list
    """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    
    def test_split_one_element(self) : 
    """
    Test a single element list
    """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    def test_split_two_elements(self) : 
    """
    Test a two elements list
    """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([1], [-1])
    self.assertEqual(expected_output, inputted, 'The list is empty')

    
    def test_split_input_value(self) : 
    
    def test_split_
    
    def test_split_
    
    def test_split_
    
    if __name__ == '__main__':
    unittest.main()
    
class TestConfusionMatrix(unittest.TestCase) :
    """
    Test for Confusion Matrix function
    """
    
    def test_confusion_matrix_
    
    
    def test_confusion_matrix_
    
    
    def test_confusion_matrix_
    
    def test_confusion_matrix_
    
    
    def test_confusion_matrix_
    
    def test_confusion_matrix_
    
    def test_confusion_matrix_
110/2:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1 and test_ratio >= 0, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], 0.5)[1]
110/3:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1 and test_ratio >= 0, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], 0.5)[0]
110/4:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1 and test_ratio >= 0, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], -1)
110/5:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1 and test_ratio >= 0, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1], -1)
110/6:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1 and test_ratio >= 0, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], -1)
110/7:
import unittest
import class_eval

class TestSplitTrainTest(unittest.TestCase) : 
    """
    Test for splitting function 
    """
    
    def test_split_empty(self) :
    """
    Test empty list
    """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    
    def test_split_one_element(self) : 
    """
    Test a single element list
    """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    def test_split_two_elements(self) : 
    """
    Test a two elements list
    """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')

    
    def test_split_multiple_elements(self) : 
    """
    Tests multi-element list
    """
    inputted = [1,2,3,4,5]
    test_ratio = 0.2
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')
    
    def test_split_zero_test_size(self) : 
    """
    Test a zero value split ratio
    """
    self.assertEqual(len(split_training_testing([1,2,3], 0)[1]), 0, 'The length of test list is not 0')
    
    def test_split_negative_test_size(self) : 
    """
    Test a negative value split ratio
    """
    self.assertRaises(AssertException, class_eval.split_training_testing([1,2,3], -1))
    
    
    def test_split_
    
    if __name__ == '__main__':
    unittest.main()
110/8:
import unittest
import class_eval

class TestSplitTrainTest(unittest.TestCase) : 
    """
    Test for splitting function 
    """
    
    def test_split_empty(self) :
    """
    Test empty list
    """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    
    def test_split_one_element(self) : 
        """
        Test a single element list
        """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    def test_split_two_elements(self) : 
        """
        Test a two elements list
        """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')

    
    def test_split_multiple_elements(self) : 
        """
        Tests multi-element list
        """
    inputted = [1,2,3,4,5]
    test_ratio = 0.2
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')
    
    def test_split_zero_test_size(self) : 
        """
        Test a zero value split ratio
        """
    self.assertEqual(len(split_training_testing([1,2,3], 0)[1]), 0, 'The length of test list is not 0')
    
    def test_split_negative_test_size(self) : 
        """
        Test a negative value split ratio
        """
    self.assertRaises(AssertException, class_eval.split_training_testing([1,2,3], -1))
    
    
    if __name__ == '__main__':
    unittest.main()
110/9:
import unittest
import class_eval

class TestSplitTrainTest(unittest.TestCase) : 
    """
    Test for splitting function 
    """
    
    def test_split_empty(self) :
        """
        Test empty list
        """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    
    def test_split_one_element(self) : 
        """
        Test a single element list
        """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    def test_split_two_elements(self) : 
        """
        Test a two elements list
        """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')

    
    def test_split_multiple_elements(self) : 
        """
        Tests multi-element list
        """
    inputted = [1,2,3,4,5]
    test_ratio = 0.2
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')
    
    def test_split_zero_test_size(self) : 
        """
        Test a zero value split ratio
        """
    self.assertEqual(len(split_training_testing([1,2,3], 0)[1]), 0, 'The length of test list is not 0')
    
    def test_split_negative_test_size(self) : 
        """
        Test a negative value split ratio
        """
    self.assertRaises(AssertException, class_eval.split_training_testing([1,2,3], -1))
    
    
    if __name__ == '__main__':
    unittest.main()
110/10:
import unittest
import class_eval

class TestSplitTrainTest(unittest.TestCase) : 
    """
    Test for splitting function 
    """
    
    def test_split_empty(self) :
        """
        Test empty list
        """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    
    def test_split_one_element(self) : 
        """
        Test a single element list
        """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'The list is empty')
    
    
    def test_split_two_elements(self) : 
        """
        Test a two elements list
        """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')

    
    def test_split_multiple_elements(self) : 
        """
        Tests multi-element list
        """
    inputted = [1,2,3,4,5]
    test_ratio = 0.2
    class_eval.split_training_testing(inputted, test_ratio) 
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'The test list contains one element')
    
    def test_split_zero_test_size(self) : 
        """
        Test a zero value split ratio
        """
    self.assertEqual(len(split_training_testing([1,2,3], 0)[1]), 0, 'The length of test list is not 0')
    
    def test_split_negative_test_size(self) : 
        """
        Test a negative value split ratio
        """
    self.assertRaises(AssertException, class_eval.split_training_testing([1,2,3], -1))
    
    
    if __name__ == '__main__':
        unittest.main()
110/11:
import unittest
import class_eval

class TestSplitTrainTest(unittest.TestCase) :
    """
    Test for splitting function
    """

    def test_split_empty(self) :
        """
        Test empty list
        """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio)
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'Case : Empty List')



    def test_split_one_element(self) :
        """
        Test a single element list
        """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio)
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'Case : Single element list')


    def test_split_two_elements(self) :
        """
        Test a two elements list
        """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio)
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'Case : Two element list')


    def test_split_multiple_elements(self) :
        """
        Tests multi-element list
        """
    inputted = [1,2,3,4,5]
    test_ratio = 0.2
    class_eval.split_training_testing(inputted, test_ratio)
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'Case : Multi element list')

    def test_split_zero_test_size(self) :
        """
        Test a zero value split ratio
        """
    self.assertEqual(len(split_training_testing([1,2,3], 0)[1]), 0, 'Case : Split_Ratio = 0')

    def test_split_negative_test_size(self) :
        """
        Test a negative value split ratio
        """
    self.assertRaises(AssertException, class_eval.split_training_testing([1,2,3], -1), 'Case : Negative split ratio')


    if __name__ == '__main__':
        unittest.main()
110/12:
import unittest


class TestSplitTrainTest(unittest.TestCase) :
    """
    Test for splitting function
    """

    def test_split_empty(self) :
        """
        Test empty list
        """
    inputted = []
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio)
    expected_output = ([])
    self.assertEqual(expected_output, inputted, 'Case : Empty List')



    def test_split_one_element(self) :
        """
        Test a single element list
        """
    inputted = [1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio)
    expected_output = ([1], [])
    self.assertEqual(expected_output, inputted, 'Case : Single element list')


    def test_split_two_elements(self) :
        """
        Test a two elements list
        """
    inputted = [1, -1]
    test_ratio = 0.5
    class_eval.split_training_testing(inputted, test_ratio)
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'Case : Two element list')


    def test_split_multiple_elements(self) :
        """
        Tests multi-element list
        """
    inputted = [1,2,3,4,5]
    test_ratio = 0.2
    class_eval.split_training_testing(inputted, test_ratio)
    expected_test_set_length = 1
    self.assertEqual(expected_test_set_length, len(inputted[1]), 'Case : Multi element list')

    def test_split_zero_test_size(self) :
        """
        Test a zero value split ratio
        """
    self.assertEqual(len(split_training_testing([1,2,3], 0)[1]), 0, 'Case : Split_Ratio = 0')

    def test_split_negative_test_size(self) :
        """
        Test a negative value split ratio
        """
    self.assertRaises(AssertException, class_eval.split_training_testing([1,2,3], -1), 'Case : Negative split ratio')


    if __name__ == '__main__':
        unittest.main()
110/13:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], -1)
110/14:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio <= 1, 'Test Ratio must be less than 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], -0.1)
110/15:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0 1, 'Test Ratio must be greater than or equal to zero'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], -0.1)
110/16:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0, 'Test Ratio must be greater than or equal to zero'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], -0.1)
110/17:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0, 'Test Ratio must be greater than or equal to zero'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], -5)
110/18:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0, 'Test Ratio must be greater than or equal to zero'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], 5)
110/19:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0, 'Test Ratio must be greater than or equal to zero'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], 1.2)
110/20:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0 and test_ratio <= 1, 'Test Ratio must be greater than or equal to zero and less than or equal to 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,2], 1.2)
110/21:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
        

    return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1,], 1)
110/22:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
        

    return  True_Positive, False_Positive, False_Nagetive, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/23:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Nagetive = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
        

    return  True_Positive, False_Positive, False_Negative, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/24:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
    
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
                
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
                    
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
                        
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
        

    return  True_Positive, False_Positive, False_Negative, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/25:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                            
    except raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  True_Positive, False_Positive, False_Negative, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/26:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  True_Positive, False_Positive, False_Negative, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/27:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  True_Positive, False_Positive, False_Negative, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/28:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  True_Positive, False_Positive, False_Negative, True_Negative
    
    
    
    
            
            
                
           
        
confusion_matrix((0,0,0,1), [1,0,0,1], 1)
110/29:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  'True Positives :', True_Positive + '\n' + 
                'False Positive :', False_Positive + '\n' +  
                'False Negative :', False_Negative + '\n' +
                'True_Negative  :', True_Negative 
                
    
    
    
    
            
            
                
           
        
confusion_matrix((0,0,0,1), [1,0,0,1], 1)
110/30:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  'True Positives :' + True_Positive + '\n' + 
                'False Positive :' + False_Positive + '\n' +  
                'False Negative :' + False_Negative + '\n' +
                'True_Negative  :' + True_Negative 
                
    
    
    
    
            
            
                
           
        
confusion_matrix((0,0,0,1), [1,0,0,1], 1)
110/31:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  'True Positives :' + True_Positive + '\n' + 'False Positive :' + False_Positive + '\n' +  'False Negative :' + False_Negative + '\n' +'True_Negative  :' + True_Negative 
                
    
    
    
    
            
            
                
           
        
confusion_matrix((0,0,0,1), [1,0,0,1], 1)
110/32:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
            
            
                
           
        
confusion_matrix((0,0,0,1), [1,0,0,1], 1)
110/33:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    try : 
        
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                            
    except : 
        raise(TypeError, 'One or more argumemts are not lists')
        

    else : 
        return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix({0,0,0,1}, {1,0,0,1}, 1)
110/34:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
        neg_class = 1 - pos_class
        True_Positive = 0
        False_Positive = 0 
        False_Negative = 0 
        True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix({0,0,0,1}, {1,0,0,1}, 1)
110/35:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
        
        for i in range(len(predicted_list)) : 
            if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
                True_Positive += 1
            elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
                False_Positive += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
                False_Negative += 1 
            elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
                True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix({0,0,0,1}, {1,0,0,1}, 1)
110/36:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
        
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix({0,0,0,1}, {1,0,0,1}, 1)
110/37:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
        
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix([0,0,0,1], {1,0,0,1}, 1)
110/38:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
        
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix([0,0,0,1], {1,0,0,1}, 1)
110/39:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 0 or 1'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
        
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix([0,0,0,1], [1,0,0,1], 1)
110/40:
def confusion_matrix(predicted_list, actual_list, pos_class) : 
    """
    Takes in predicted list consisting of 1s and 0s
    and actual list consisting of 1s and 0s 
    Returns a tuple of True Positives, False Positive, False Negative and True Negative of confusion matrix
    """
    assert type(predicted_list) == list, 'Predicted list is not of type list' 
    
    assert type(actual_list) == list, 'Actual list is not of type list'
    
    assert set(predicted_list).issubset({0,1}) == True, 'List must contain only 0 or 1'
        
    assert pos_class in (0,1), 'Positive class must be either 1 or 0'
    
    assert len(predicted_list) == len(actual_list), 'Predicted list and actual list must be of same length'
    
    neg_class = 1 - pos_class
    True_Positive = 0
    False_Positive = 0 
    False_Negative = 0 
    True_Negative = 0
        
    for i in range(len(predicted_list)) : 
        if predicted_list[i] == pos_class and actual_list[i] == pos_class : 
            True_Positive += 1
        elif predicted_list[i] == pos_class and actual_list[i] == neg_class : 
            False_Positive += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == pos_class : 
            False_Negative += 1 
        elif predicted_list[i] == neg_class and actual_list[i] == neg_class : 
            True_Negative += 1
                
    return  True_Positive, False_Positive, False_Negative, True_Negative 
                
    
    
    
    
confusion_matrix([], [], 1)
110/41:
import class_eval
from sklearn.neighbors import KNeighborsClassifier

def get_data():
    """Opens file house-votes-84.data and returns a list with 
    labels (political affiliations) and a list with 
    feature vectors (voting decisions). Voting decisions 
    are represented with 1 for yes, 0 for no, and 0.5 for neither.
    """
    relabel = {'y': 1, 'n': 0, '?': 0.5}
    data = []
    for line in open('house-votes-84.data', 'r'):
        strlst = line.strip().split(',')
        toappend = [strlst[0]] + [relabel[i] for i in strlst[1:]]
        data.append(toappend)
    return data 

# Get the data
data = get_data()

# Split it into training and testing sets and separate labels from feature vectors
train, test = class_eval.split_training_testing(data, p_test=20)
train_labels = [i[0] for i in train]
train_features = [i[1:] for i in train]
test_actual_labels = [i[0] for i in test]
test_features = [i[1:] for i in test]

# Make an instance of the KNN classifier and fit a model to the training data
neigh = KNeighborsClassifier(n_neighbors=11)
neigh.fit(train_features, train_labels) 

# Predict the labels for the test data and evaluate the performance
test_pred_labels = neigh.predict(test_features)
# The predict() method returns an object of type numpy.ndarray, so
# we will transform it to list to fit the function specification
class_eval.print_eval_metrics(list(test_pred_labels), test_actual_labels, 'democrat')


# This routine is meant for testing purposes only.
# In an actual analysis, we will look more systematically for a k 
# that maximizes the model's accuracy. We will then use multiple rounds 
# of random partitioning and average the model's performance over all rounds.
110/42:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0 and test_ratio <= 1, 'Test Ratio must be greater than or equal to zero and less than or equal to 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,[1,2],2], 1.2)
110/43:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0 and test_ratio <= 1, 'Test Ratio must be greater than or equal to zero and less than or equal to 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([1,[1,2],2], 1)
110/44:
import random 

def split_training_testing(data_list, test_ratio) : 
    """
    Takes a list of data points, 
    and percentage of list to be split into test_set
    and splits it into training and test list 
    """
    
    assert type(data_list) == list, 'Argument is not a list'  #Verify if the type of input is list
    
    test_set = []
    train_set = []
    test_set_size = int(len(data_list) * test_ratio)
    
    assert test_ratio >0 and test_ratio <= 1, 'Test Ratio must be greater than or equal to zero and less than or equal to 1'    #The function should only run if test_ratio is less than 1
    
    test_indices = random.sample(range(len(data_list)), test_set_size)
    for i in test_indices : 
        test_set.append(data_list[i])
            
    train_indices = [x for x in list(range(len(data_list))) if x not in test_indices]
    for i in train_indices :
        train_set.append(data_list[i])
            
    return train_set, test_set

    

split_training_testing([i*i for i in range(4)], 0.2)
111/1:
import time

seconds = time.time()
print("Seconds since unix epoch =", seconds)
111/2:
import time

# Create a list
ls = list(range(100000))

start = time.time()
print("Start time:", start)

# Count the number of times appears in list.
ls.count(99999)

end = time.time()
print("End time:", end)

print("Total running time:", end - start)
111/3:
import time

# Create a list
ls = list(range(100000))

start = time.time()
print("Start time:", start)

# Count the number of times appears in list.
ls.count(99999)

end = time.time()
print("End time:", end)

print("Total running time:", end - start)
111/4:
# Do it yourself: Using a loop to time
ls = list(range(100000))

res = 0
for i in range(100):
    start = time.time()
    ls.count(99999)
    end = time.time()
    res += end - start
print(res / 100)

# Use a module
# This is what you are more likely to see on Stack Overflow
from timeit import timeit 

timeit(stmt='ls.count(99999)', setup='ls = list(range(100000))', number=100) / 100
111/5:
# Do it yourself: Using a loop to time
ls = list(range(100000))

res = 0
for i in range(100):
    start = time.time()
    ls.count(99999)
    end = time.time()
    res += end - start
print(res / 100)

# Use a module
# This is what you are more likely to see on Stack Overflow
from timeit import timeit 

timeit(stmt='ls.count(99999)', setup='ls = list(range(100000))', number=100) / 100
111/6:
# Code snippet to be executed only once.
# Note that this is a string.
mysetup = "from math import sqrt"
 
# Code snippet whose execution time is to be measured
# We can have multi line code more easily by formatting 
# simular to a docstring.
mycode = '''
def example():
    mylist = []
    for x in range(100):
        mylist.append(sqrt(x))
'''
 
# timeit statement
print (timeit(setup = mysetup,
              stmt = mycode,
              number = 10000))
111/7:
# Code snippet to be executed only once.
# Note that this is a string.
mysetup = "from math import sqrt"
 
# Code snippet whose execution time is to be measured
# We can have multi line code more easily by formatting 
# simular to a docstring.
mycode = '''
def example():
    mylist = []
    for x in range(100):
        mylist.append(sqrt(x))
'''
 
# timeit statement
print (timeit(setup = mysetup,
              stmt = mycode,
              number = 10000))
111/8:
# Code snippet to be executed only once.
# Note that this is a string.
mysetup = "from math import sqrt"
 
# Code snippet whose execution time is to be measured
# We can have multi line code more easily by formatting 
# simular to a docstring.
mycode = '''
def example():
    mylist = []
    for x in range(100):
        mylist.append(sqrt(x))
'''
 
# timeit statement
print (timeit(setup = mysetup,
              stmt = mycode,
              number = 10000))
111/9:
# Exercise 7: Create a function to multiply each element of a 
# vector `v` by a scalar (i.e. a number) `m` in R with and without 
# a for-loop and compare their execution time.

### R code ###
multiply <- function (v, m) {
  for (i in length(v)) : 
    v[i] <- m*v[i]
}

multiply2 <- function(v, m) {
  v <- mv
}
111/10:
# Exercise 7: Create a function to multiply each element of a 
# vector `v` by a scalar (i.e. a number) `m` in R with and without 
# a for-loop and compare their execution time.

### R code ###
multiply <- function (v, m) {
  for (i in length(v)) : 
    v[i] <- m*v[i]
}

multiply2 <- function(v, m) {
  v <- mv
}
113/1:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2
113/2:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2 

f_6([1,2,3,4])
113/3:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2
return lst

f_6([1,2,3,4])
113/4:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2
    return lst

f_6([1,2,3,4])
113/5:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2
    return lst

f_6([1,2,3,4, 5, 6, 7])
113/6:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2
    return lst

f_6([1,2, [3,4], 5, 6, 7])
113/7:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2*lst[i]
    return lst

f_6([1,2, [3,4], 5, 6, 7])
113/8:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)) : 
        if (i+1) % 3 == 0 : 
            lst[i] = 2*lst[i]
    return lst

f_6([1,2, 3,4, 5, 6, 7])
113/9:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    lst = [lst[i].sort() for i in range(len(lst))]
    
    return lst.sort()

f_7(['abc', 'ugh'])
113/10:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    lst = ["".join(sorted(lst[i])) for i in range(len(lst))]
    
    return sorted(lst)

f_7(['abc', 'ugh'])
113/11:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    lst = ["".join(sorted(lst[i])) for i in range(len(lst))]
    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaa'])
113/12:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    lst = ["".join(sorted(lst[i])) for i in range(len(lst))]
    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa'])
113/13:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    lst = ["".join(sorted(lst[i])) for i in range(len(lst))]
    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
113/14:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = sorted(lst[i]) #
    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
113/15:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #
    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
113/16:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a*log(a)
    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
113/17:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a + a*log(a)
    
    return sorted(lst) #nlog(n)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/1:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = sorted(lst[i])
    
    return sorted(lst) #nlog(n)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/2:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = sorted(lst[i]) #a*log(a) where a = len(lst(i))

    
    return "".join(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/3:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = sorted(lst[i]) #a*log(a) where a = len(lst(i))

    
    return "".join(lst[i] for i in range(len(lst)))

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/4:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a*log(a) where a = len(lst(i))\
        

    
    return lst

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/5:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        

    
    return lst.sort()

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/6:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        

    
    return lst.sort()

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/7:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        

    
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/8:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        

    lst = lst.sort()
    return lst

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/9:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        

    lst = lst.sort()
    return lst

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/10:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        

    lst_new = lst.sort()
    return lst_new

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/11:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))\
        
    return sorted(lst)

f_7(['abc', 'ugh', 'aaaaaa', 'zxy'])
114/12:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = "".join(sorted(lst[i])) #a2*log(a) where a = len(lst(i))
        
    return sorted(lst) #nlog(n)

f_7(['abc', 'ugh', 'aaa', 'zxy'])
114/13:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = sorted(lst[i]) #a*log(a) where a = len(lst(i))
        lst[i] = "".join(lst[i]) #a
        
    sorted(lst) #nlog(n)
        
    return lst 

#Order of growth : n(a*log(a) + a) + n*log(n) = nalog(a) + na + nlog(n) = nalog(a) + nlog(n)

f_7(['abc', 'ugh', 'aaa', 'zxy'])
114/14:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : #n
        lst[i] = sorted(lst[i]) #a*log(a) where a = len(lst(i))
        lst[i] = "".join(lst[i]) #a
        
    lst.sort() #nlog(n)
        
    return lst 

#Order of growth : n(a*log(a) + a) + n*log(n) = nalog(a) + na + nlog(n) = nalog(a) + nlog(n)

f_7(['abc', 'ugh', 'aaa', 'zxy'])
114/15:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : 
        lst[i] = "".join(sorted(lst[i]))
        
    lst.sort() 
        
    return lst 

#Order of growth : n(a*log(a) + a) + n*log(n) = nalog(a) + na + nlog(n) = nalog(a) + nlog(n)

f_7(['abc', 'ugh', 'aaa', 'zxy'])
114/16:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in lst[::3] : 
        if i % 3 == 0 : 
            lst[i] = 2*lst[i]
    return lst

f_6([1,2, 3,4, 5, 6, 7])

#O(len(lst))
114/17:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[::3] : 
    print lst[i]
114/18:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[::3] : 
    print (lst[i])
114/19:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[::3] : 
    print (lst_1[i])
114/20:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[::3] : 
    print(i)
114/21:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[1::3] : 
    print(i)
114/22:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[0::3] : 
    print(i)
114/23:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[-1::3] : 
    print(i)
114/24:
lst_1 = [1, 2, 3, 4, 5, 6, 7]
for i in lst_1[0::3] : 
    print(i)
114/25:
lst_1 = [1, 2, 3, 4, 5, 6, 9]
for i in lst_1[0::3] : 
    print(i)
114/26:
lst_1 = [2, 2, 3, 4, 5, 6, 9]
for i in lst_1[0::3] : 
    print(i)
114/27:
lst_1 = [2, 2, 3, 4, 5, 6, 9]
for i in lst_1[3::3] : 
    print(i)
114/28:
lst_1 = [2, 2, 3, 4, 5, 6, 9]
for i in lst_1[2::3] : 
    print(i)
114/29:
lst_1 = [2, 2, 2, 4, 5, 6, 9]
for i in lst_1[2::3] : 
    print(i)
114/30:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in lst[2::3] : 
        if i % 3 == 0 : 
            lst[i] = 2*lst[i]
    return lst

f_6([1,2, 3,4, 5, 6, 7])

#O(len(lst))
114/31:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in lst[2::3] :  
            lst[i] = 2*lst[i]
    return lst

f_6([1,2, 3,4, 5, 6, 7])

#O(len(lst))
114/32:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in lst[2::3] :  
        lst[i] = 2*lst[i]
    return lst

f_6([1,2, 3,4, 5, 6, 7])

#O(len(lst))
114/33:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in lst[1::3] :  
        lst[i] = 2*lst[i]
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst))
114/34:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 

sample = lst[1::3] #O(len(lst)/3)
    
for i in sample :  #O(len(lst)/3)
    lst[i] = 2*lst[i]
    
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst)/3)
114/35:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    sample = lst[1::3] #O(len(lst)/3)
    
    for i in sample :  #O(len(lst)/3)
    lst[i] = 2*lst[i]
    
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst)/3)
114/36:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    sample = lst[1::3] #O(len(lst)/3)
    
    for i in sample :  #O(len(lst)/3)
        lst[i] = 2*lst[i]
    
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst)/3)
114/37:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)):  #O(len(lst))
        if i % 3 == 0 : 
            lst[i] = 2*lst[i]
    
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst)/3)
114/38:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)):  #O(len(lst))
        if i + 1 % 3 == 0 : 
            lst[i] = 2*lst[i]
    
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst)/3)
114/39:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)):  #O(len(lst))
        if (i + 1) % 3 == 0 : 
            lst[i] = 2*lst[i]
    
    return lst

f_6([1, 2, 3, 4, 5, 6, 7])

#O(len(lst)/3)
114/40:
import time 

a = 2

for b in [2,3,4] : 
    start = time.time()
    modulo(a,b)
    end = time.time()
    
    print(start, '-', end)
114/41:
def modulo(a, b):
    """Take numbers a and b and compute a % b."""
    if b <= 0:
        return None
    div = int(a / b)
    return a - div*b

# Enter your answer to Problem 4 below. 
#O(1)
114/42:
import time 

a = 2

for b in [2,3,4] : 
    start = time.time()
    modulo(a,b)
    end = time.time()
    
    print(start, '-', end)
114/43:
import time 

a = 2

for b in [2,3,4] : 
    start = time.time()
    modulo(a,b)
    end = time.time()
    
    print(start - end)
114/44:
import time 

a = 2

for b in [2,200, 2000000] : 
    start = time.time()
    modulo(a,b)
    end = time.time()
    
    print(start - end)
114/45:
import time 

a = 2

for b in [2,200, 2000000] : 
    
    start = time.time()
    res = modulo(a,b)
    end = time.time()
    
    print(res, start - end)
114/46:
import time 

a = 2000

for b in [2,200, 1000000] : 
    
    start = time.time()
    res = modulo(a,b)
    end = time.time()
    
    print(res, start - end)
114/47:
import time 
import decimal

a = 2000

for b in [2,200, 1000000] : 
    
    start = time.time()
    res = decimal.Decimal(modulo(a,b))
    end = time.time()
    
    print(res, start - end)
114/48:
import time 
import decimal

a = 2000

for b in [2,200, 1000000] : 
    
    start = time.time()
    res = decimal.Decimal(modulo(a,b))
    end = time.time()
    
    print(res, start - end)
114/49:
def sum_of_n(n):
    """Assume n is a positive integer. 
    Calculate the sum of all integers from 1 to n, inclusive.
    """
    res = 0
    for i in range(1, n + 1):
        res += i
    return res

start = time.time()
res = sum_of_n(1000000)
end = time.time()
print(res, end - start)
114/50:
import time 
import decimal

a = 2000

for b in [2,200, 1000000, 100000000000000000000] : 
    
    start = time.time()
    res = decimal.Decimal(modulo(a,b))
    end = time.time()
    
    print(res, start - end)
114/51:
import time 
import decimal

a = 2000

for b in [2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = decimal.Decimal(modulo(a,b))
    end = time.time()
    
    print(res, start - end)
114/52:
import time 
import decimal

a = 2000

for b in [2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = modulo(a,b)
    end = time.time()
    
    print(res, start - end)
114/53:
import time 
import decimal

a = 2000

for b in [2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = modulo(a,b)
    end = time.time()
    
print(res, start - end)
114/54:
import time 
import decimal

a = 2000

for b in [2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = modulo(a,b)
    end = time.time()
    print(res, start - end)
114/55:
import time 
import decimal

a = 2000

for b in [1, 2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = modulo(a,b)
    end = time.time()
    print(res, start - end)
114/56:
def is_prime(x):
    """Take an integer greater than 1 and check if it is a prime number.
    Return True if prime, False otherwise.
    """
    for i in range(2, int(x**0.5) + 1):
        if x % i == 0:
            return False
    return True

# Enter your answer to Problem 1 below. 
#O()

print(range(1,2))
114/57:
def is_prime(x):
    """Take an integer greater than 1 and check if it is a prime number.
    Return True if prime, False otherwise.
    """
    for i in range(2, int(x**0.5) + 1):
        if x % i == 0:
            return False
    return True

# Enter your answer to Problem 1 below. 
#O()

print(range(1,3))
114/58:
def is_prime(x):
    """Take an integer greater than 1 and check if it is a prime number.
    Return True if prime, False otherwise.
    """
    for i in range(2, int(x**0.5) + 1):
        if x % i == 0:
            return False
    return True

# Enter your answer to Problem 1 below. 
#O()

1 in range(1,3)
114/59:
def is_prime(x):
    """Take an integer greater than 1 and check if it is a prime number.
    Return True if prime, False otherwise.
    """
    for i in range(2, int(x**0.5) + 1):
        if x % i == 0:
            return False
    return True

# Enter your answer to Problem 1 below. 
#O()

3 in range(1,3)
114/60:
import time 
import decimal

a = 2000

for b in [1, 2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = modulo(b)
    end = time.time()
    print(res, start - end)
114/61:
import time 
import decimal

a = 2000

for b in [1, 2,200, 1000000, 100000000000000000000, -1, 0] : 
    
    start = time.time()
    res = is_prime(b)
    end = time.time()
    print(res, start - end)
114/62:
import time 
import decimal

a = 2000

for b in [1, 2,200, 1000000, 100000000000000000000, 0] : 
    
    start = time.time()
    res = is_prime(b)
    end = time.time()
    print(res, start - end)
114/63:
"""Take a list of numbers and modify it in place by
multiplying every 3rd number by 2.
"""

# Enter your answer to Problem 6 below. 

def f_6(lst) : 
    for i in range(len(lst)):  
        if (i + 1) % 3 == 0 : 
            lst[i] = 2*lst[i]
    
    return lst



#Order : The function loops through the list n times. Then it checks for each index whether its a multiple of 3. 
#The final part involves modifying list in place by mulitplying the element by 2, which is overall of constant order as it doesnt touch the other elements in list. 
#Hence, the order of this function would be O(n) where n = len(list)

f_6([1, 2, 3, 4, 5, 6, 7])
114/64:
"""Take a list of strings, sort the letters in each string,
and then sort the full list. The list is modified in place.
"""

# Enter your answer to Problem 7 below. l

def f_7(lst) : 
    for i in range(len(lst)) : 
        lst[i] = "".join(sorted(lst[i]))
        
    lst.sort() 
        
    return lst 

#Order of growth : This function first sorts each string of the list, and then sorts the list in place. Sorting each string in the worst case, using for loop, will take a runtime of n*a*log(a) where a is the maximum length of all strings. 
#The function then sorts the entire list in place, hence its total runtime will be O(n*a(log(a)) + nlog(n)), where n = length of the list. 

f_7(['abc', 'ugh', 'aaa', 'zxy'])
115/1:
def is_prime(x):
    """Take an integer greater than 1 and check if it is a prime number.
    Return True if prime, False otherwise.
    """
    for i in range(2, int(x**0.5) + 1):
        if x % i == 0:
            return False
    return True

# Enter your answer to Problem 1 below. 
#O(x)
#The functions calls the for loop (x/2) + 1 -2 = (x/2) - 1 times. This is equivalent of the order O(x/2) which is further 
#of the order O(x) as we ignore constants.
118/1:
my_var = filter(lambda a: a%2 == 1,
                reversed(range(20)))

# What is the first result of calling next() my_var?
118/2:
# It returns odd numbers, counting back from 19
next(my_var)
118/3:
# It returns odd numbers, counting back from 19
next(my_var)
118/4:
# It returns odd numbers, counting back from 19
next(my_var)
118/5:
# It returns odd numbers, counting back from 19
next(my_var)
118/6:
# It returns odd numbers, counting back from 19
next(my_var)
118/7:
# It returns odd numbers, counting back from 19
next(my_var)
118/8:
# It returns odd numbers, counting back from 19
next(my_var)

#To get all values at once : 
list(my_val)
118/9:
my_var = filter(lambda a: a%2 == 1,
                reversed(range(20)))

# What is the first result of calling next() my_var?
118/10:
my_var = filter(lambda a: a%2 == 1,
                reversed(range(20)))

# What is the first result of calling next() my_var?
118/11:
# It returns odd numbers, counting back from 19
next(my_var)

#To get all values at once : 
list(my_var)
118/12:
# Return list of authors whose last name starts with 'R'
list(filter(lambda name: name.split()[-1][0]=='R', authors))
118/13:
authors = ['George Orwell', 'Zadie Smith', 'J.K. Rowling', 
           'Roald Dahl', 'Salman Rushdie']
# Return list ordered by length of author name
sorted(authors, key=len)
118/14:
# Return list ordered alphabetically by last name
sorted(authors, key=lambda name: name.split()[-1])
118/15:
# Return list of authors whose last name starts with 'R'
list(filter(lambda name: name.split()[-1][0]=='R', authors))
118/16:
# Takes x and y and adds them together; returns an iterable
my_var = map(lambda x, y: x + y, range(10), range(10, 20))
118/17: list(my_var)
118/18:
import math

def area(r):
    """
    Reurns area of a circle with radius 'r'.
    Accepts numeric types
    """
    return math.pi * (r**2)

# What if we need to compute the area for lots of different circles?
radii = [2, 5, 7.8, 4.2, 37]

# List comprehension
areas1 = [area(r) for r in radii]
    
# With map ... (can pass the map object to the list constructor)
areas2 = list(map(area, radii))
118/19:
from timeit import timeit

print('List comprehension:', timeit('[area(r) for r in radii]', 
                                    setup='from __main__ import area, radii', 
                                    number=10**5) )
print('Map function:',  timeit('list(map(area, radii))', 
                               setup='from __main__ import area, radii', 
                               number=10**5) )
118/20:
from timeit import timeit

print('List comprehension:', timeit('[area(r) for r in radii]', 
                                    setup='from __main__ import area, radii', 
                                    number=10**5) )
print('Map function:',  timeit('list(map(area, radii))', 
                               setup='from __main__ import area, radii', 
                               number=10**5) )
118/21:
# No longer a built-in funtion in Python 3

# Guido van Rossum: "Use functools.reduce() if you really need it; 
# however 99% of the time an explict for-loop is more readable."

from functools import reduce

reduce(lambda x, y: x + ', ' + y, authors)  # equivalent to: ', '.join(authors)
118/22:
# Exercise 1: Use map() and lambda to add each elements of two lists below. 
# The answer should be [101, 210, 400, 1400, 10500].

ls1 = [100, 200, 300, 400, 500]
ls2 = [1, 10, 100, 1000, 10000]

map(lambda x, y : x + y, ls1, lst2)
118/23:
# Exercise 1: Use map() and lambda to add each elements of two lists below. 
# The answer should be [101, 210, 400, 1400, 10500].

ls1 = [100, 200, 300, 400, 500]
ls2 = [1, 10, 100, 1000, 10000]

map(lambda x, y : x + y, ls1, ls2)
118/24:
# Exercise 1: Use map() and lambda to add each elements of two lists below. 
# The answer should be [101, 210, 400, 1400, 10500].

ls1 = [100, 200, 300, 400, 500]
ls2 = [1, 10, 100, 1000, 10000]

map(lambda x, y : x + y, ls1, ls2)
118/25:
# Exercise 1: Use map() and lambda to add each elements of two lists below. 
# The answer should be [101, 210, 400, 1400, 10500].

ls1 = [100, 200, 300, 400, 500]
ls2 = [1, 10, 100, 1000, 10000]

list(map(lambda x, y : x + y, ls1, ls2))
118/26:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [i + j for i, j in ls1, ls2]
118/27:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [i + j for i in ls1, j in ls2]
118/28:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [i + j for i in ls1 and j in ls2]
118/29:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [ls1[i] + ls2[j] for i in range(len(ls1)) and j in range(len(ls2))]
118/30:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [ls1[i] + ls2[j] for i, j in range(len(ls1)),range(len(ls2))]
118/31:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [ls1[i] + ls2[j] for i, j in range(len(ls1)), range(len(ls2))]
118/32:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [ls1[i] + ls2[j] for i, j in enumerate(range(len(ls1)), range(len(ls2)))]
118/33:
# Exercise 2: Now use a list comprehension to solve Exercise 1.

ans = [i + j for i, j in enumerate(ls1, ls2)]
118/34:
# Exercise 3: Use map() and lambda to create a list consisting of 
# the frequency of the letter "a" (regardless of case) in each string
# in the list below. The answer should be [3, 4, 2, 3].

states = ["Alaska", "Alabama", "Arizona", "Arkansas"]


map(lambda lst : states.lower.count('a', states)
118/35:
# Exercise 3: Use map() and lambda to create a list consisting of 
# the frequency of the letter "a" (regardless of case) in each string
# in the list below. The answer should be [3, 4, 2, 3].

states = ["Alaska", "Alabama", "Arizona", "Arkansas"]


map(lambda lst : states.lower.count('a'), states)
118/36:
# Exercise 3: Use map() and lambda to create a list consisting of 
# the frequency of the letter "a" (regardless of case) in each string
# in the list below. The answer should be [3, 4, 2, 3].

states = ["Alaska", "Alabama", "Arizona", "Arkansas"]


list(map(lambda lst : states.lower.count('a'), states))
118/37:
# Exercise 3: Use map() and lambda to create a list consisting of 
# the frequency of the letter "a" (regardless of case) in each string
# in the list below. The answer should be [3, 4, 2, 3].

states = ["Alaska", "Alabama", "Arizona", "Arkansas"]


list(map(lambda lst : lst.lower.count('a'), states))
118/38:
# Exercise 3: Use map() and lambda to create a list consisting of 
# the frequency of the letter "a" (regardless of case) in each string
# in the list below. The answer should be [3, 4, 2, 3].

states = ["Alaska", "Alabama", "Arizona", "Arkansas"]


list(map(lambda lst : lst.lower().count('a'), states))
118/39:
# Exercise 4: Use filter() and lambda to get a list 
# of all the vowels in the string.

sentence = 'They did nothing as the raccoon attacked the lady’s bag of food.'

filter(lambda string : string in ['a', 'e', 'i', 'o', 'u'], sentence)
118/40:
# Exercise 4: Use filter() and lambda to get a list 
# of all the vowels in the string.

sentence = 'They did nothing as the raccoon attacked the lady’s bag of food.'

list(filter(lambda string : string in ['a', 'e', 'i', 'o', 'u'], sentence))
118/41:
# Exercise 4: Use filter() and lambda to get a list 
# of all the vowels in the string.

sentence = 'They did nothing as the raccoon attacked the lady’s bag of food.'

list(filter(lambda string : string.lower() in ['a', 'e', 'i', 'o', 'u'], sentence))
118/42:
# Exercise 4: Use filter() and lambda to get a list 
# of all the vowels in the string.

sentence = 'They did nothing as the raccoon attacked the lady’s bag of food.'

list(filter(lambda string : string.lower() in 'aeiou' sentence))
118/43:
# Exercise 4: Use filter() and lambda to get a list 
# of all the vowels in the string.

sentence = 'They did nothing as the raccoon attacked the lady’s bag of food.'

list(filter(lambda string : string.lower() in 'aeiou', sentence))
118/44: # Exercise 2: Now use a list comprehension to solve Exercise 1.
119/1:
# To answer Problem 1, modify the code below. 

def linear_search(ls, e):
    '''Assumes ls is a list.
    Returns True if e is in ls, False otherwise.'''
    
    for i in range(len(ls) - 1, 0, -1):
        if ls[i] == e:
            return True
    return False
119/2:
# To answer Problem 1, modify the code below. 

def linear_search(ls, e):
    '''Assumes ls is a list.
    Returns True if e is in ls, False otherwise.'''
    
    for i in range(len(ls) - 1, 0, -1):
        if ls[i] == e:
            return True
    return False

linear_search([1,2,3], 2)
119/3:
# To answer Problem 1, modify the code below. 

def linear_search(ls, e):
    '''Assumes ls is a list.
    Returns True if e is in ls, False otherwise.'''
    
    for i in range(len(ls) - 1, 0, -1):
        if ls[i] == e:
            return True
    return False

linear_search([1,2,3], 4)
119/4:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
119/5:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
selection_sort([1,3,5,2,3])
119/6:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
    return ls
        
selection_sort([1,3,5,2,3])
119/7:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
    
    return ls
        
selection_sort([1,3,5,2,3])
119/8:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
    
    return ls
        
selection_sort([1,3,5,2,3])
119/9:
# To answer Problem 1, modify the code below. 

def linear_search(ls, e):
    '''Assumes ls is a list.
    Returns True if e is in ls, False otherwise.'''
    
    for i in range(len(ls) - 1, 0, -1):
        if ls[i] == e:
            return True
    return False

linear_search([1,2,3], 0)
119/10:
# To answer Problem 1, modify the code below. 

def linear_search(ls, e):
    '''Assumes ls is a list.
    Returns True if e is in ls, False otherwise.'''
    
    for i in range(len(ls) - 1, 0, -1):
        if ls[i] == e:
            return True
    return False

linear_search([1,2,3], [])
120/1:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
    
 
selection_sort([1,3,5,2,3])
120/2:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
    
 
print(selection_sort([1,3,5,2,3]))
120/3:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
    
 
next(selection_sort([1,3,5,2,3]))
120/4:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        print(ls)
        
selection_sort([1,2,3,6,2])
120/5:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return(ls)
        
selection_sort([1,2,3,6,2])
120/6:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
    return(ls)
        
selection_sort([1,2,3,6,2])
120/7:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the back
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos - 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
    return(ls)
        
selection_sort([1,2,3,6,2])
120/8:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
    return(ls)
        
selection_sort([1,2,3,6,2])
120/9:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
    return(ls)
        
selection_sort([1,2,3,6,2])
120/10:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos - 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
    return(ls)
        
selection_sort([1,2,3,6,2])
120/11:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
    return(ls)
        
selection_sort([1,2,3,6,2])
120/12:
# To answer Problem 2, modify the code below.  

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
   
        
print(selection_sort([1,2,3,6,2]), [1,2,3,6,2])
120/13:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
   
        
print(selection_sort(ls), ls)
120/14:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return ls
120/15:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return ls
        
selection_sort(ls)
120/16:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) + 1):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return ls
        
selection_sort(ls)
120/17:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) + 1):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return ls
        
selection_sort(ls)
120/18:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) + 1):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(0, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return ls
        
selection_sort(ls)
120/19:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] < ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        return ls
        
selection_sort(ls)
120/20:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] < ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/21:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/22:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/23:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] >= ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/24:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] < ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/25:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls)):
        max_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, pos + 1):
            if ls[i] > ls[max_pos]:
                max_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/26:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, len(ls)):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/27:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(i + 1, len(ls) - 1):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/28:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(1, len(ls) - 1):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/29:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(pos + 1, len(ls) - 1):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/30:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = 0
        # Find the largest item in the sublist until this position
        for i in range(pos, len(ls) - 1):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/31:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = pos
        # Find the largest item in the sublist until this position
        for i in range(pos, len(ls) - 1):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/32:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = pos
        # Find the largest item in the sublist until this position
        for i in range(pos, len(ls)):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/33:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2, 1, 3, 0]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = pos
        # Find the smalles item in the sublist until this position
        for i in range(pos, len(ls)):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/34:
# To answer Problem 2, modify the code below.  

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def selection_sort(ls):
    '''Assumes ls is a list of elements that can be compared using >.
    Sorts ls in ascending order'''
    
    # Consider each position, starting from the front
    for pos in range(0, len(ls) - 1):
        min_pos = pos
        # Find the smalles item in the sublist until this position
        for i in range(pos, len(ls)):
            if ls[i] < ls[min_pos]:
                min_pos = i
        
        # Swap the item at this position with the largest item
        ls[pos], ls[min_pos] = ls[min_pos], ls[pos]
        
        
        
selection_sort(ls)
print(ls)
120/35:
ls = [1,2,4]
ls[:]
120/36:
ls = [1,2,4]

ls
120/37:
ls = [1,2,4]

head(ls, 1)
120/38:
ls = [1,2,4]

ls.head()
120/39:
ls = [1,2,4]

next(ls)
120/40:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
    left_half = []
    right_half = []
        for i < (ls[0] + ls[-1])/2 : 
            left_half.append(i)
            
        for j > (ls[0] + ls[-1])/2 : 
            right_half.append(j)
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/41:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
    left_half = []
    right_half = []
        for i < (ls[0] + ls[-1])/2 : 
            left_half.append(i)
            
        for j > (ls[0] + ls[-1])/2 : 
            right_half.append(j)
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/42:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        for i < (ls[0] + ls[-1])/2 : 
            left_half.append(i)
            
        for j > (ls[0] + ls[-1])/2 : 
            right_half.append(j)
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/43:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        i, j = 0,0
        for i < (ls[0] + ls[-1])/2 : 
            left_half.append(i)
            
        for j > (ls[0] + ls[-1])/2 : 
            right_half.append(j)
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/44:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        i, j = 0,0
        while i < (ls[0] + ls[-1])/2 : 
            left_half.append(ls[i])
            i += 1
            
        for j > (ls[0] + ls[-1])/2 and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/45:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        i, j = 0,0
        while i < (ls[0] + ls[-1])/2 : 
            left_half.append(ls[i])
            i += 1
            
        while j > (ls[0] + ls[-1])/2 and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/46:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = (ls[0] + ls[-1])/2
        i = 0
        j = middle + 1
        
        while i < middle : 
            left_half.append(ls[i])
            i += 1
            
        while j > middle and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/47:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = (ls[0] + ls[-1])//2
        i = 0
        j = middle + 1
        
        while i < middle : 
            left_half.append(ls[i])
            i += 1
            
        while j > middle and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/48:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        i = 0
        j = middle + 1
        
        while i < middle : 
            left_half.append(ls[i])
            i += 1
            
        while j > middle and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/49:
# To answer Problem 3, modify the code below. 

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        i = 0
        j = middle + 1
        
        while i <= middle : 
            left_half.append(ls[i])
            i += 1
            
        while j > middle and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/50:
# To answer Problem 3, modify the code below. 

import sys
sys.setrecursionlimit(10000)

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        i = 0
        j = middle + 1
        
        while i <= middle : 
            left_half.append(ls[i])
            i += 1
            
        while j > middle and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/51:
# To answer Problem 3, modify the code below. 

import sys
sys.setrecursionlimit(10000)

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        i = 0
        j = middle + 1
        
        while i <= middle : 
            left_half.append(ls[i])
            i += 1
            
        while j > middle and j < len(ls) : 
            right_half.append(ls[j])
            j += 1
            
    left = merge_sort(left_half)
    right = merge_sort(right_half)
            
    return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/52:
# To answer Problem 3, modify the code below. 

import sys
sys.setrecursionlimit(10000)

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        
        for i in range(middle) : 
            left_half.append(ls[i])
            
        for j in range(middle + 1, len(ls)) : 
            right_half.append(ls[j])
            
    left = merge_sort(left_half)
    right = merge_sort(right_half)
            
    return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/53:
# To answer Problem 3, modify the code below. 

import sys
sys.setrecursionlimit(10000)

ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        
        for i in range(middle) : 
            left_half.append(ls[i])
            
        for j in range(middle + 1, len(ls)) : 
            right_half.append(ls[j])
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
    return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/54:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6,4,2, 1, 3, 0, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        
        for i in range(middle) : 
            left_half.append(ls[i])
            
        for j in range(middle + 1, len(ls)) : 
            right_half.append(ls[j])
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
    return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/55:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        
        for i in range(middle) : 
            left_half.append(ls[i])
            
        for j in range(middle + 1, len(ls)) : 
            right_half.append(ls[j])
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
            
    return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/56:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left_half = []
        right_half = []
        
        middle = len(ls)//2
        
        for i in range(middle) : 
            left_half.append(ls[i])
            
        for j in range(middle + 1, len(ls)) : 
            right_half.append(ls[j])
            
        left = merge_sort(left_half)
        right = merge_sort(right_half)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/57:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left = merge_sort(list(lambda lst : lst[0, len(lst)//2]))
        right = merge_sort(list(lambda lst : lst[len(lst)//2, len(lst)]))
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
120/58:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        left = merge_sort(list(lambda ls : lst[0, len(ls)//2]))
        right = merge_sort(list(lambda ls : lst[len(ls)//2, len(ls)]))
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
121/1:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        
        middle = len(ls)/2
        left = merge_sort(ls[0 : middle])
        right = merge_sort(ls[middle : -1])
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
121/2:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        
        middle = len(ls)//2
        left = merge_sort(ls[0 : middle])
        right = merge_sort(ls[middle : -1])
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
121/3:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        
        middle = len(ls)//2
        left = merge_sort(ls[:middle])
        right = merge_sort(ls[middle:])
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
121/4:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6, -1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        
        middle = len(ls)//2
        left = merge_sort(ls[:middle])
        right = merge_sort(ls[middle:])
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
121/5:
ls = [1,2,4]
middle = (0 + 3)//2
print(ls[0:middle]) 
print(ls[middle:end])
121/6:
ls = [1,2,4]
middle = (0 + 3)//2
a = ls[0:middle] 
b = ls[middle:end]

print(a, b)
121/7:
ls = [1,2,4]
middle = (0 + 3)//2
a = ls[0:middle] 
b = ls[middle:3]

print(a, b)
121/8:
ls = [1,2,4, 5, 6]
middle = (0 + len(lst))//2
a = ls[0:middle] 
b = ls[middle:3]

print(a, b)
121/9:
ls = [1,2,4, 5, 6]
middle = (0 + len(ls))//2
a = ls[0:middle] 
b = ls[middle:3]

print(a, b)
121/10:
ls = [1,2,4, 5, 6]
middle = (0 + len(ls))//2
a = ls[0:middle] 
b = ls[middle:len(ls)]

print(a, b)
121/11:
ls = [1,2,4, 5, 6, 7]
middle = (0 + len(ls))//2
a = ls[0:middle] 
b = ls[middle:len(ls)]

print(a, b)
121/12:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], 0, middle)
        right = merge_sort(ls[middle : end], middle, end)
        
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
121/13:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], 0, middle)
        right = merge_sort(ls[middle : end], middle, end)
        
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 5)
121/14:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], 0, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 5)
121/15:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], 0, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/16:
# To answer Problem 3, modify the code below. 


ls = [1,2,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], 0, middle)
        right = merge_sort(ls[middle : end], middle, end)
        
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/17:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], 0, middle)
        right = merge_sort(ls[middle : end], middle, end)
        
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/18:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/19:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/20:
ls = [1,2,4, 5, 6, 7]
middle = (0 + len(ls))//2
a = ls[0:middle] 
b = ls[middle:len(ls)]

print(a, b)

ls[1:3]
121/21:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/22:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 1, 5)
121/23:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = (start + end)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/24:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/25:
# To answer Problem 3, modify the code below. 


ls = [1,4,3,6,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/26:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/27:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/28:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/29:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 1, 5)
121/30:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - 1)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/31:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    if len(ls) <= 1:
        return ls
    else:
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/32:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if end - start < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/33:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if end - start < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/34:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if end - start < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/35:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if end - start < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/36:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/37:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle : end + 1], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/38:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle + 1 : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/39:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle + 1 : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
121/40:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle + 1 : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 1, 5)
121/41:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls, start, end):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle + 1 : end], middle + 1, end)
        return merge(left, right)
    
def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls, 0, 4)
122/1:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end)
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle + 1 : end], middle + 1, end)
        return merge(left, right)
    
    def merge(left, right)
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
122/2:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
    if (end - start) < 1 : 
        return ls
    else :
        middle = start + (end - start)//2
        left = merge_sort(ls[start : middle], start, middle)
        right = merge_sort(ls[middle + 1 : end], middle + 1, end)
        return merge(left, right)
    
    def merge(left, right)
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
122/3:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
        return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right)
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
122/4:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right)
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
122/5:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right) :
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result

merge_sort(ls)
122/6:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
    return result

merge_sort(ls)
122/7:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
            return result

merge_sort(ls)
122/8:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
            return result

merge_sort(ls)
122/9:
# To answer Problem 3, modify the code below. 


ls = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result

merge_sort(ls)
122/10:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle], start, middle)
            right = merge_sort(ls[middle + 1 : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result

merge_sort(lst)
122/11:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle + 1 : end])
            return merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result

merge_sort(lst)
122/12:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle + 1 : end])
            new_ls = merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result
    
    return new_ls

merge_sort(lst)
122/13:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle + 1 : end])
            new_ls = merge(left, right)
    
    def merge(left, right) :
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result
    
return new_ls

merge_sort(lst)
123/1:
# To answer Problem 1, modify the code below. 

def linear_search(ls, e):
    '''Assumes ls is a list.
    Returns True if e is in ls, False otherwise.'''
    
    for i in range(len(ls) - 1, 0, -1):
        if ls[i] == e:
            return True
    return False

linear_search([1,2,3], [5])
123/2:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle + 1 : end])
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
            
            while j < len(right):
                result.append(right[j])
                j += 1
            
    return result
    


merge_sort(lst)
123/3:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle + 1 : end])
            
            
        result = []
        i, j = 0, 0
            
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                    
        # Append any remaining items
        while i < len(left):
            result.append(left[i])
            i += 1
            
        while j < len(right):
            result.append(right[j])
            j += 1
            
    return result
    


merge_sort(lst)
123/4:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle + 1 : end])
            
            
        result = []
        i, j = 0, 0
            
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
                    
        # Append any remaining items
        while i < len(left):
            result.append(left[i])
            i += 1
            
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result


merge_sort(lst)
123/5:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle + 1 : end], middle, end)
            
            result = []
            i, j = 0, 0
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result


merge_sort(lst)
123/6:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle + 1 : end], middle, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2


merge_sort(lst)
123/7:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle + 1 : end], middle, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2


print(merge_sort(lst))
123/8:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle + 1 : end], middle, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


print(merge_sort(lst))
123/9:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle + 1 : end], middle + 1, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


print(merge_sort(lst))
123/10:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


print(merge_sort(lst))
123/11:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


merge_sort(lst)
123/12:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = 0, mid + 1
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


merge_sort(lst)
123/13:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = 0, middle + 1
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


merge_sort(lst)
123/14:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = middle + 1
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
        return result
    
    return merge_sort2(ls, start, end)


merge_sort(lst)
123/15:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
            return result
    
    return merge_sort2(ls, start, end)


merge_sort(lst)
123/16:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            result = []
            i, j = 0, 0
            
            # Inspect the first items of the two lists and append the smaller one to results
            while i < len(left) and j < len(right):
                if left[i] < right[j]:
                    result.append(left[i])
                    i += 1
                else:
                    result.append(right[j])
                    j += 1
                    
            # Append any remaining items
            while i < len(left):
                result.append(left[i])
                i += 1
                
            while j < len(right):
                result.append(right[j])
                j += 1
            
            return result
    
    return merge_sort2(ls, start, end)


merge_sort(lst)
123/17:
# To answer Problem 3, modify the code below. 


lst = [1,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right):
        '''Assumes left and right are sorted lists.
        Returns a new sorted list containing the same elements as (left + right).'''
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
            
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result
    
    return merge_sort2(ls, start, end)

            
           


merge_sort(lst)
123/18:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) - 1
    
    def merge_sort2(ls, start, end) :
        if (end - start) < 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
    
    def merge(left, right):
        '''Assumes left and right are sorted lists.
        Returns a new sorted list containing the same elements as (left + right).'''
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to results
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
            
        while j < len(right):
            result.append(right[j])
            j += 1
            
        return result
    
    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/19:
ls = [1,2,4, 5, 6, 7]

def mergeSort2(alist, l, r):
    if r - l >= 1:
        mid = l + (r - l)//2

        mergeSort2(alist, l, mid)
        mergeSort2(alist, mid+1, r)

        i = l
        j = mid+1
        k = 0
        temp_list = [None]*(r-l+1)
        while i < mid+1 and j < r+1:
            if alist[i] <= alist[j]:
                temp_list[k] = alist[i]
                i=i+1
            else:
                temp_list[k] = alist[j]
                j=j+1
            k=k+1

        while i < mid+1:
            temp_list[k] = alist[i]
            i=i+1
            k=k+1

        while j < r+1:
            temp_list[k] = alist[j]
            j=j+1
            k=k+1

        n = 0
        for index in range(l,r+1):
            alist[index] = temp_list[n]
            n += 1
            
mergeSort2(ls, 0, 5)
123/20:
ls = [1,2,4, 5, 6, 7]

def mergeSort2(alist, l, r):
    if r - l >= 1:
        mid = l + (r - l)//2

        mergeSort2(alist, l, mid)
        mergeSort2(alist, mid+1, r)

        i = l
        j = mid+1
        k = 0
        temp_list = [None]*(r-l+1)
        while i < mid+1 and j < r+1:
            if alist[i] <= alist[j]:
                temp_list[k] = alist[i]
                i=i+1
            else:
                temp_list[k] = alist[j]
                j=j+1
            k=k+1

        while i < mid+1:
            temp_list[k] = alist[i]
            i=i+1
            k=k+1

        while j < r+1:
            temp_list[k] = alist[j]
            j=j+1
            k=k+1

        n = 0
        for index in range(l,r+1):
            alist[index] = temp_list[n]
            n += 1
            
            
print(mergeSort2(ls, 0, 5))
123/21:
ls = [1,2,4, 5, 6, 7]

def mergeSort2(alist, l, r):
    if r - l >= 1:
        mid = l + (r - l)//2

        mergeSort2(alist, l, mid)
        mergeSort2(alist, mid+1, r)

        i = l
        j = mid+1
        k = 0
        temp_list = [None]*(r-l+1)
        while i < mid+1 and j < r+1:
            if alist[i] <= alist[j]:
                temp_list[k] = alist[i]
                i=i+1
            else:
                temp_list[k] = alist[j]
                j=j+1
            k=k+1

        while i < mid+1:
            temp_list[k] = alist[i]
            i=i+1
            k=k+1

        while j < r+1:
            temp_list[k] = alist[j]
            j=j+1
            k=k+1

        n = 0
        for index in range(l,r+1):
            alist[index] = temp_list[n]
            n += 1
            
    return alist
            
            
mergeSort2(ls, 0, 5)
123/22:
ls = [1,2,4, 5,8,  6, 7]

def mergeSort2(alist, l, r):
    if r - l >= 1:
        mid = l + (r - l)//2

        mergeSort2(alist, l, mid)
        mergeSort2(alist, mid+1, r)

        i = l
        j = mid+1
        k = 0
        temp_list = [None]*(r-l+1)
        while i < mid+1 and j < r+1:
            if alist[i] <= alist[j]:
                temp_list[k] = alist[i]
                i=i+1
            else:
                temp_list[k] = alist[j]
                j=j+1
            k=k+1

        while i < mid+1:
            temp_list[k] = alist[i]
            i=i+1
            k=k+1

        while j < r+1:
            temp_list[k] = alist[j]
            j=j+1
            k=k+1

        n = 0
        for index in range(l,r+1):
            alist[index] = temp_list[n]
            n += 1
            
    return alist
            
            
mergeSort2(ls, 0, 5)
123/23:
ls = [1,2,4, 5,8,  6, 7]

def mergeSort2(alist, l, r):
    if r - l >= 1:
        mid = l + (r - l)//2

        mergeSort2(alist, l, mid)
        mergeSort2(alist, mid+1, r)

        i = l
        j = mid+1
        k = 0
        temp_list = [None]*(r-l+1)
        while i < mid+1 and j < r+1:
            if alist[i] <= alist[j]:
                temp_list[k] = alist[i]
                i=i+1
            else:
                temp_list[k] = alist[j]
                j=j+1
            k=k+1

        while i < mid+1:
            temp_list[k] = alist[i]
            i=i+1
            k=k+1

        while j < r+1:
            temp_list[k] = alist[j]
            j=j+1
            k=k+1

        n = 0
        for index in range(l,r+1):
            alist[index] = temp_list[n]
            n += 1
            
    return alist
            
            
mergeSort2(ls, 1, 6)
123/24:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            i, j = 0, 0
            
            result = []
            
            while i < mid+1 and j < r+1:
                if alist[i] <= alist[j]:
                    result[k] = alist[i]
                    i=i+1
                else:
                    result[k] = alist[j]
                    j=j+1
                k=k+1
                
            while i < mid+1:
                temp_list[k] = alist[i]
                i=i+1
                k=k+1
                
            while j < r+1:
                temp_list[k] = alist[j]
                j=j+1
                k=k+1
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/25:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            i, j = 0, 0
            
            result = []
            
            while i < middle+1 and j < end+1:
                if ls[i] <= lst[j]:
                    resul.appeend(ls[i])
                    i=i+1
                else:
                    result.append(ls[j])
                    j=j+1
    
                
            while i < middle + 1 :
                result.append(ls[i])
                i=i+1
        
                
            while j < r+1 :
                result.append(ls[j])
                j=j+1
                
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/26:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            i, j = 0, 0
            
            result = []
            
            while i < middle+1 and j < end+1:
                if ls[i] <= lst[j]:
                    result.append(ls[i])
                    i=i+1
                else:
                    result.append(ls[j])
                    j=j+1
    
                
            while i < middle + 1 :
                result.append(ls[i])
                i=i+1
        
                
            while j < r+1 :
                result.append(ls[j])
                j=j+1
                
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/27:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            i, j = 0, 0
            
            result = []
            
            while i < len(left) and j < len(right) :
                if ls[i] <= lst[j]:
                    result.append(ls[i])
                    i=i+1
                else:
                    result.append(ls[j])
                    j=j+1
    
                
            while i < len(left) :
                result.append(ls[i])
                i=i+1
        
                
            while j < len(right) :
                result.append(ls[j])
                j=j+1
                
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/28:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            i, j = 0, 0
            
            result = []
            
            while i < len(left) and j < len(right) :
                if ls[i] <= lst[j]:
                    result.append(ls[i])
                    i=i+1
                else:
                    result.append(ls[j])
                    j=j+1
    
                
            while i < len(left) :
                result.append(ls[i])
                i=i+1
        
                
            while j < len(right) :
                result.append(ls[j])
                j=j+1
                
            return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/29:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls[:]
        else :
            middle = start + (end - start)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            
            i, j = 0, 0
            
            result = []
            
            while i < len(left) and j < len(right) :
                if ls[i] <= lst[j]:
                    result.append(ls[i])
                    i=i+1
                else:
                    result.append(ls[j])
                    j=j+1
    
                
            while i < len(left) :
                result.append(ls[i])
                i=i+1
        
                
            while j < len(right) :
                result.append(ls[j])
                j=j+1
                
            return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/30:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
    
                
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
                
        while j < len(right) :
            result.append(ls[j])
            j=j+1
                
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/31:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/32:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/33:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) + 1 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/34:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 0
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort2(ls[start : middle], start, middle)
            right = merge_sort2(ls[middle : end], middle + 1, end)
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/35:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/36:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start - 1 : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/37:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start - 1 : middle])
            right = merge_sort(ls[middle + 1 : end])
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/38:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start - 1 : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/39:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[0 : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/40:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[ : middle])
            right = merge_sort(ls[middle : )
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/41:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[ : middle])
            right = merge_sort(ls[middle : ])
            return merge(left, right)
        
    def merge(left, right) :
        i, j = 0, 0
        result = []
        while i < len(left) and j < len(right) :
            if ls[i] <= lst[j]:
                result.append(ls[i])
                i=i+1
            else:
                result.append(ls[j])
                j=j+1
        
        while i < len(left) :
            result.append(ls[i])
            i=i+1
        
        while j < len(right) :
            result.append(ls[j])
            j=j+1
        
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/42:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[ : middle])
            right = merge_sort(ls[middle : ])
            return merge(left, right)
        
    def merge(left, right):
    '''Assumes left and right are sorted lists.
    Returns a new sorted list containing the same elements as (left + right).'''
    
    result = []
    i, j = 0, 0
    # Inspect the first items of the two lists and append the smaller one to results
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    # Append any remaining items
    while i < len(left):
        result.append(left[i])
        i += 1
    while j < len(right):
        result.append(right[j])
        j += 1
    return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/43:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[ : middle])
            right = merge_sort(ls[middle : ])
            return merge(left, right)
        
    def merge(left, right):
        '''Assumes left and right are sorted lists.
        Returns a new sorted list containing the same elements as (left + right).'''
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to result
        
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        while j < len(right):
            result.append(right[j])
            j += 1
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/44:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right):
        '''Assumes left and right are sorted lists.
        Returns a new sorted list containing the same elements as (left + right).'''
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to result
        
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        while j < len(right):
            result.append(right[j])
            j += 1
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/45:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start - 1 : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right):
        '''Assumes left and right are sorted lists.
        Returns a new sorted list containing the same elements as (left + right).'''
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to result
        
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        while j < len(right):
            result.append(right[j])
            j += 1
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
123/46:
# To answer Problem 3, modify the code below. 


lst = [5,4,6,3,-1, 0, 2, 4]

def merge_sort(ls):
    '''Assumes ls is a list. 
    Returns a new sorted list with same elements as ls.'''
    
    start = 1
    end = len(ls) 
    
    def merge_sort2(ls, start, end) :
        if len(ls) <= 1 : 
            return ls
        else :
            middle = (start + end)//2
            left = merge_sort(ls[start - 1 : middle])
            right = merge_sort(ls[middle : end])
            return merge(left, right)
        
    def merge(left, right):
        '''Assumes left and right are sorted lists.
        Returns a new sorted list containing the same elements as (left + right).'''
        result = []
        i, j = 0, 0
        # Inspect the first items of the two lists and append the smaller one to result
        
        while i < len(left) and j < len(right):
            if left[i] < right[j]:
                result.append(left[i])
                i += 1
            else:
                result.append(right[j])
                j += 1
        # Append any remaining items
        
        while i < len(left):
            result.append(left[i])
            i += 1
        while j < len(right):
            result.append(right[j])
            j += 1
        return result
    

    return merge_sort2(ls, start, end)

            
merge_sort(lst)
126/1:
# Import modules to estimate and show results

toy_data = read.csv('../assignment-final-data/2020.csv')
126/2:
# Import modules to estimate and show results

import csv

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader] #To remove the first two columns
        return df_list
126/3:
# Import modules to estimate and show results

import csv

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df, quoting = csv.QUOTE_NONNUMERIC) 
        
        df_list = [row[2:] for row in df_reader] #To remove the first two columns
        return df_list
    
get_data('../assignment-final-data/2020.csv')
126/4:
# Import modules to estimate and show results

import csv

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        
        next(df) #Skips the first entry 
        
        df_reader = csv.reader(df) 
        
        df_list = [row[2:] for row in df_reader] #To remove the first two columns
        return df_list
    
get_data('../assignment-final-data/2020.csv')
126/5:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        df_reader = csv.reader(df) 
        df_list = [row[2:] for row in df_reader] #To remove the first two columns
        return df_list
    
get_data('../assignment-final-data/2020.csv')
126/6:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        df_reader = csv.reader(df) 
        return df_list
    
get_data('../assignment-final-data/2020.csv')
126/7:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        df_reader = csv.reader(df) 
        return df_reader
    
get_data('../assignment-final-data/2020.csv')
126/8:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        df_reader = csv.reader(df) 
        for row in df_reader : 
            print row
    
get_data('../assignment-final-data/2020.csv')
126/9:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        df_reader = csv.reader(df) 
        for row in df_reader : 
            print(row)
    
get_data('../assignment-final-data/2020.csv')
126/10:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
    
get_data('../assignment-final-data/2020.csv')
126/11:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
    
get_data('../assignment-final-data/2020.csv')
126/12:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
get_data('../assignment-final-data/2020.csv')
126/13:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')
126/14:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data
126/15:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/16:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/17:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[:5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/18:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[:5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/19:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[:5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/20:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[:5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/21:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[:5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/22:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data[:5]

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/23:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/24:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/25:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

toy_data

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/26:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

print(toy_data)

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner for each match
    '''
126/27:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

print(toy_data)

for row in toy_data : 
    if row[4] != 3 : 
        print(row)

def get_winner(df_lst) : 
    '''
    Takes a list of all matches and returns the winner 
    '''
    for row in df_lst :
126/28:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

print(toy_data)

for row in toy_data : 
    if row[4] != 3 : 
        print(row)
126/29:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

print(toy_data)

for row in toy_data : 
    if row[3] != 3 : 
        print(row)
126/30:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

print(toy_data)

for row in toy_data : 
    if row[3] != '3' : 
        print(row)
126/31:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[3] != '3' : 
        print(row)
126/32:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[3] = '3' : 
        print(row)
126/33:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[3] == '3' : 
        print(row)
126/34:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[3] != '3' : 
        print(row)
126/35:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[3] == '3' : 
        print(row)
126/36:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[11] != 'completed' : 
        print(row)
126/37:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')


for row in toy_data : 
    if row[11] != 'Completed' : 
        print(row)
126/38:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 


toy_data
126/39:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split()


def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/40:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split()


def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/41:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split()


def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/42:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split()
126/43:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split()
126/44:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split()
trial_split
126/45:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split('-')
trial_split
126/46:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split('-')
trial_split
126/47:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split('-')
trial_split
126/48:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

trial = '4-5'
trial_split = trial.split('-')
trial_split
126/49:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data)

def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/50:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data)

def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/51:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data)

def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/52:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data)

def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            
            
            
        else :
126/53:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data)
126/54:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/55:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    return row

def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    for row in df : 
        if row[11] == 'Completed' : 
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            
            
            
        else :
126/56:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    return row
126/57:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    print(row)
126/58:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    print(row)
126/59:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[10] = row[10].split('-')
    row[10] = [int(i) for i in row[10]]
    
    print(row)
126/60:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[10] = row[10].split('-')
    
    print(row)
126/61:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[10] = row[10].split('-')
    
    if row[10] != [''] : 
        row[10].split('-')
    
    print(row)
126/62:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[10] = row[10].split('-')
    
    if row[10] != [''] : 
        row[10].split('-')
    
    print(row)
126/63:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[10] = row[10].split('-')
    
    if row[10] != [''] : 
        row[10].split('-')
    
    print(row)
126/64:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[10] = row[10].split('-')
    
    if row[10] != [''] : 
        row[10].split('-')
    
    print(row)
126/65:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != [''] : 
        row[10].split('-')
    
    print(row)
126/66:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != [''] : 
        row[10].split('-')
        row[10] = [int(i) for i in row[10]]
    
    print(row)
126/67:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != [''] : 
        row[10].split('-')
        row[10] = [int(i) for i in row[10]]
    
    print(row)
126/68:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/69:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != [''] : 
        row[10].split('-')
        row[10] = [int(i) for i in row[10]]
    
    print(row)
126/70:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != [''] : 
        row[10].split('-')
    
    print(row)
126/71:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != '' : 
        row[10].split('-')
    
    print(row)
126/72:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != ' ' : 
        row[10].split('-')
    
    print(row)
126/73:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != ' ' : 
        row[10] = ow[10].split('-')
    
    print(row)
126/74:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != ' ' : 
        row[10] = row[10].split('-')
    
    print(row)
126/75:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != '' : 
        row[10] = row[10].split('-')
    
    print(row)
126/76:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    if row[10] != '' : 
        row[10] = row[10].split('-')
        row[10] = [int(i) for i in row[10]]
        
    
    print(row)
126/77:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    
    i = 0 #Player 1 wins if i >= 2
    
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    #Match going to third set
    if row[10] != '' : 
        row[10] = row[10].split('-')
        row[10] = [int(i) for i in row[10]]
        if row[8][0] > row[8][1] : 
            i += 1 
        if row[9][0] > row[9][1] : 
            i += 1
        row.append(i)
        
    
    print(row)
126/78:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    
    i = 0 #Player 1 wins if i >= 2
    
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    #Match going to third set
    if row[10] != '' : 
        row[10] = row[10].split('-')
        row[10] = [int(i) for i in row[10]]
        if row[8][0] > row[8][1] : 
            i += 1 
        if row[9][0] > row[9][1] : 
            i += 1
        
    row.append(i)
        
    
    print(row)
126/79:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    
    i = 0 #Player 1 wins if i >= 2
    
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    #Match going to third set
    if row[10] != '' : 
        row[10] = row[10].split('-')
        row[10] = [int(i) for i in row[10]]
        if row[8][0] > row[8][1] : 
            i += 1 
            
        if row[9][0] > row[9][1] : 
            i += 1
            
        if row[10][0] > row[10][1] : 
            i += 1 
        
    row.append(i)
        
    
    print(row)
126/80:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    
    i = 0 #Player 1 wins if i >= 2
    
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    #Match going to third set
    if row[10] != '' : 
        row[10] = row[10].split('-')
        row[10] = [int(i) for i in row[10]]
        if row[8][0] > row[8][1] : 
            i += 1 
            
        if row[9][0] > row[9][1] : 
            i += 1
            
        if row[10][0] > row[10][1] : 
            i += 1 
    else : 
        if row[8][0] > row[8][1] : 
            i += 1 
            
        if row[9][0] > row[9][1] : 
            i += 1 
        
    row.append(i)
        
    
    print(row)
126/81:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
    
    i = 0 #Player 1 wins if i >= 2
    
    row[8] = row[8].split('-')
    row[8] = [int(i) for i in row[8]]
    
    row[9] = row[9].split('-')
    row[9] = [int(i) for i in row[9]]
    
    #Match going to third set
    if row[10] != '' : 
        row[10] = row[10].split('-')
        row[10] = [int(i) for i in row[10]]
        if row[8][0] > row[8][1] : 
            i += 1 
            
        if row[9][0] > row[9][1] : 
            i += 1
            
        if row[10][0] > row[10][1] : 
            i += 1 
    else : 
        if row[8][0] > row[8][1] : 
            i += 1 
            
        if row[9][0] > row[9][1] : 
            i += 1 
            
    if i >= 2 : 
        row.append(row[4]) 
    else : 
        row.append(row[5])
        
    
    print(row)
126/82:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split()
126/83:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split()
            print(row)
126/84:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split('.')
            print(row)
126/85:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split('.')
            if row[4] != row[11][0] : 
                row.append(row[4])
            else : 
                row.append(row[5])
                
            print(row)
126/86:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split('. ')
            if row[4] != row[11][0] : 
                row.append(row[4])
            else : 
                row.append(row[5])
                
            print(row)
126/87:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split('Retired')
            if row[4] != row[11][0] : 
                row.append(row[4])
            else : 
                row.append(row[5])
                
            print(row)
126/88:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            row[11] = row[11].split(' Retired')
            
            if row[4] != row[11][0] : 
                row.append(row[4])
            else : 
                row.append(row[5])
                
            print(row)
126/89:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])

for row in toy_data : 
        
        if row[11] != 'Completed' : #For completed matche
            store = row[11].split(' Retired')
            
            if row[4] != store[0] : 
                row.append(row[4])
            else : 
                row.append(row[5])
                
            print(row)
126/90:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
            i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
            
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
126/91:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
                i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
            
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
126/92:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
                i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
            
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    return row
                
get_winner
126/93:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
                i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
            
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    print(row)
                
get_winner
126/94:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
                i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
            
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    print(row)
                
get_winner(toy_data)
126/95:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
                i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    print(row)
                
get_winner(toy_data)
126/96:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/97:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
            
            if row[8][0] > row[8][1] : 
                i += 1 
            
            if row[9][0] > row[9][1] : 
                i += 1
            
            if row[10][0] > row[10][1] : 
                i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    print(row)
                
get_winner(toy_data)
126/98:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    print(row)
                
get_winner(toy_data)
126/99:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/100:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    print(row)
                
get_winner(toy_data)
126/101:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    return row
             
get_winner(toy_data)
126/102:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/103:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                
    return row
             
get_winner(toy_data)
126/104:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return row
             
get_winner(toy_data)
126/105:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/106:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return row
             
get_winner(toy_data)
126/107:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
             
get_winner(toy_data)
126/108:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/109:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        if row[11] == 'Completed' : #For completed matches
            player_1 = row[4]
            player_2 = row[5]
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
             
get_winner(toy_data)
126/110:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
126/111:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        
        if row[11] == 'Completed' : #For completed matches
            
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] : 
                    i += 1
                if row[10][0] > row[10][1] : 
                    i += 1 
            
            #Match not going to third set
            else : 
                if row[8][0] > row[8][1] : 
                    i += 1 
                if row[9][0] > row[9][1] :
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
             
get_winner(toy_data)
127/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
127/2:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        
        if row[11] == 'Completed' : #For completed matches
            
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
          
            if row[8][0] > row[8][1] : 
                i += 1 
            if row[9][0] > row[9][1] :
                i += 1
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                
                if row[10][0] > row[10][1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
             
get_winner(toy_data)

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/3: winner_data = [get_winner(toy_data)]
127/4:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
127/5:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        
        if row[11] == 'Completed' : #For completed matches
            
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
          
            if row[8][0] > row[8][1] : 
                i += 1 
            if row[9][0] > row[9][1] :
                i += 1
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                
                if row[10][0] > row[10][1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/6:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

print(toy_data[:5])
127/7:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place
127/8:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place
127/9:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        
        if row[11] == 'Completed' : #For completed matches
            
            
            i = 0 
            
            row[8] = row[8].split('-')
            row[8] = [int(i) for i in row[8]]
            
            row[9] = row[9].split('-')
            row[9] = [int(i) for i in row[9]]
            
          
            if row[8][0] > row[8][1] : 
                i += 1 
            if row[9][0] > row[9][1] :
                i += 1
            
            #Match going to third set
            if row[10] != '' : 
                row[10] = row[10].split('-')
                row[10] = [int(i) for i in row[10]]
                
                if row[10][0] > row[10][1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/10: winner_data = [get_winner(toy_data)]
127/11:
winner_data = [get_winner(toy_data)]
winner_data
127/12:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place
127/13:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/14:
winner_data = [get_winner(toy_data)]
winner_data
127/15:
winner_data = [get_winner(toy_data)]
winner_data
127/16: winner_data = [get_winner(toy_data)]
127/17:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return row
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/18: winner_data = [get_winner(toy_data)]
127/19:
winner_data = [get_winner(toy_data)]

winner_data
127/20:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/21:
winner_data = [get_winner(toy_data)]

winner_data
127/22:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place
127/23:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        print(row)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/24:
winner_data = [get_winner(toy_data)]

winner_data
127/25:
winner_data = [get_winner(toy_data)]

winner_data
127/26:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return df
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/27:
winner_data = [get_winner(toy_data)]

winner_data
127/28: get_winner(toy_data)
127/29: get_winner(toy_data)
127/30:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for i in range(len(df)) : 
        row = df[i]
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return df
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/31: get_winner(toy_data)
127/32:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place
127/33:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for i in range(len(df)) : 
        row = df[i]
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return df
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/34: get_winner(toy_data)
127/35: get_winner(toy_data)
127/36:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for i in range(len(df)) : 
        row = df[i]
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return df
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/37: get_winner(toy_data)
127/38:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

len(toy_data)
127/39:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

len(toy_data[0])
127/40:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

len(toy_data[1])
127/41:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

len(toy_data[2])
127/42:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

len(toy_data[3])
127/43:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

len(toy_data[10])
127/44:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
127/45:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for i in range(len(df)) : 
        df_copy = df[:]
        row = df_copy[i]
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return df_copy
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/46: get_winner(toy_data)
127/47: get_winner(toy_data)
127/48:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for i in range(len(df)) : 
        df_copy = df[:]
        row = df_copy[i]
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row.append(player_1) 
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
            else : 
                row.append(player_2)
                 
        return (df_copy)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/49: get_winner(toy_data)
127/50:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        row_copy = row[:]
        player_1 = row_copy[4]
        player_2 = row_copy[5]
        set_1 = row_copy[8]
        set_2 = row_copy[9]
        set_3 = row_copy[10]
        
        if row_copy[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row_copy.append(player_1) 
            else : 
                row_copy.append(player_2)
            
        else : #Matches that were not completed 
            store = row_copy[11].split(' Retired')
            
            if player_1 != store[0] : 
                row_copy.append(player_1)
            else : 
                row_copy.append(player_2)
                 
        return (df)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/51: get_winner(toy_data)
127/52:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        row_copy = row[:]
        player_1 = row_copy[4]
        player_2 = row_copy[5]
        set_1 = row_copy[8]
        set_2 = row_copy[9]
        set_3 = row_copy[10]
        
        if row_copy[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                row_copy.append(player_1) 
            else : 
                row_copy.append(player_2)
            
        else : #Matches that were not completed 
            store = row_copy[11].split(' Retired')
            
            if player_1 != store[0] : 
                row_copy.append(player_1)
            else : 
                row_copy.append(player_2)
                 
        return (row_copy)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/53: get_winner(toy_data)
127/54:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
127/55:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
        return (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/56: get_winner(toy_data)
127/57:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    return (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/58: get_winner(toy_data)
127/59: get_winner(toy_data)
127/60: get_winner(toy_data)
127/61:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
return (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/62:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    return (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/63: get_winner(toy_data)
127/64:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    print (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/65: get_winner(toy_data)
127/66:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result = result.append(player_1) 
            else : 
                result = result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result = result.append(player_1)
            else : 
                result = result.append(player_2)
                 
    print (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/67: get_winner(toy_data)
127/68:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result = result.append(player_1) 
            else : 
                result = result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result = result.append(player_1)
            else : 
                result = result.append(player_2)
                 
    return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/69: get_winner(toy_data)
127/70:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result = result.append(player_1) 
            else : 
                result = result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result = result.append(player_1)
            else : 
                result = result.append(player_2)
                 
    return (result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/71: get_winner(toy_data)
127/72:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    return(result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/73: get_winner(toy_data)
127/74:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
        return(result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/75: get_winner(toy_data)
127/76:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
            return(result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/77: get_winner(toy_data)
127/78:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
                return(result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/79: get_winner(toy_data)
127/80:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    return(result)
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/81: get_winner(toy_data)
127/82:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/83: get_winner(toy_data)
127/84:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/85:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    
    return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/86: get_winner(toy_data)
127/87:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
127/88:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    
    return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/89: get_winner(toy_data)
127/90:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                 
    return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/91: get_winner(toy_data)
127/92:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
    return result
            

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/93: get_winner(toy_data)
127/94:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
                return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/95: get_winner(toy_data)
127/96:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
        return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/97: get_winner(toy_data)
127/98:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
    return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/99: get_winner(toy_data)
127/100:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/101:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
    return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/102: get_winner(toy_data)
127/103:
gen = get_winner()

for i in gen : 
    print(i)
127/104:
gen = get_winner(toy_data)

for i in gen : 
    print(i)
127/105:
gen = get_winner(toy_data)

for i in gen : 
    print i
127/106:
gen = get_winner(toy_data)

next(gen)
127/107:
gen = get_winner(toy_data)

gen
127/108:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
    
    yield result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/109:
gen = get_winner(toy_data)

gen
127/110:
gen = get_winner(toy_data)

next(gen)
127/111:
gen = get_winner(toy_data)

next(gen)
next(gen)
127/112:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            
            i = 0 
            
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
          
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
            
            #Match going to third set
            if set_3 != '' : 
                
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                if set_3[0] > set_3[1] : 
                    i += 1 
                    
            if i >= 2 : 
                result.append(player_1) 
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
            else : 
                result.append(player_2)
    
    return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/113: get_winner(toy_data)
127/114:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        
    result = []
    player_1 = row[4]
    player_2 = row[5]
    set_1 = row[8]
    set_2 = row[9]
    set_3 = row[10]
        
    if row[11] == 'Completed' : #For completed matches
            
        i = 0 
            
        set_1 = set_1.split('-')
        set_1 = [int(i) for i in set_1]
            
        set_2 = set_2.split('-')
        set_2 = [int(i) for i in set_2]
            
          
        if set_1[0] > set_1[1] : 
            i += 1 
        if set_2[0] > set_2[1] :
            i += 1
            
        #Match going to third set
        if set_3 != '' : 
                
            set_3 = set_3.split('-')
            set_3 = [int(i) for i in set_3]
            if set_3[0] > set_3[1] : 
                i += 1 
                    
        if i >= 2 : 
            result.append(player_1) 
        else : 
            result.append(player_2)
            
    else : #Matches that were not completed 
        store = row[11].split(' Retired')
            
        if player_1 != store[0] : 
            result.append(player_1)
        else : 
            result.append(player_2)
    
    return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/115:
def get_winner(df) : 
    '''
    Returns the winner for each match played
    '''
    
    for row in df : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
    
    return result
             

def get_round(df) : 
    '''
    Returns the dataset with each round number indicated
    '''
127/116: get_winner(toy_data)
128/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/2:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
    print(result)
128/4:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        print(result)
128/5:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        row = row.append(result)
        
        print(row)
128/6:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/7:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        row.append(result)
        
        print(row)
128/8:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/9:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        row.append(result)
128/10:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        row.append(result)
        
        
toy_data
128/11:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/12:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        row.append(result)
128/13:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/14:
for row in toy_data : 
        result = []
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                result.append(player_1) 
                
            else : 
                result.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                result.append(player_1)
                
            else : 
                result.append(player_2)
                
        row.append(result)

toy_data
128/15:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/16:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/17:
lst = [1,2,34]
lst.append(1,2)
128/18:
lst = [1,2,34]
lst.append(1)
lst.append(2)
lst
128/19:
lst = (1,2,34)
lst.add(1,3)
128/20:
lst = set(1,2,34)
lst.add(1,3)
128/21:
lst = set(1,2,34)
lst.add(1)
128/22:
lst = {1,2,34}
lst.add(1)
128/23:
lst = {1,2,34}
lst.add(1)
lst
128/24:
lst = {1,2,34}
lst.add(1, 5)
lst
128/25:
lst = {1,2,34}
lst.add(1)
lst.add(5)
lst
128/26:
lst = {1,2,34}
lst.add(1)
lst.add(5)
lst

lst2 = {}
lst2.add(2)
128/27:
lst = {1,2,34}
lst.add(1)
lst.add(5)
lst

lst2 = set()
lst2.add(2)
128/28:
lst = {1,2,34}
lst.add(1)
lst.add(5)
lst

lst2 = set()
lst2.add(2)
lstr
128/29:
lst = {1,2,34}
lst.add(1)
lst.add(5)
lst

lst2 = set()
lst2.add(2)
lst
128/30:
lst = {1,2,34}
lst.add(1)
lst.add(5)
lst

lst2 = set()
lst2.add(2)
lst2
128/31:
lst = [1,2,34]
lst.add(1)
lst.add(5)
lst
128/32:
lst = [1,2,34]
lst.append(1)
lst.append(5)
lst
128/33:
lst = [1,2,34]
lst.append(1)
lst.append(5)
lst.count(1)
128/34:
lst = [1,2,34, 'aaa']
lst.append(1)
lst.append(5)
lst.count(1)
lst.count('aaa')
128/35:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
toy_data
128/36:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/37:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
                if set_3 != '' : 
                    set_3 = set_3.split('-')
                    set_3 = [int(i) for i in set_3]
                    
                    if set_3[0] > set_3[1] : 
                        i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/38:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/39:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/40:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
    print(winners)
128/41:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/42:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/43:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
    print(winners)
128/44:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/45:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/46:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
    return winners
128/47:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
        return winners
128/48:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
    return winners
128/49:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
    
return winners
128/50:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
128/51:
last_tournament = None 
winners = []

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] != last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/52:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/53:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/54:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] == last_tournament :
        i = 0
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        match.append(i)
        winners.append(match[12])
        
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 0
        
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        else : 
            i += 1
            
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/55:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/56:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/57:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/58:
#Determining the total number of participants in the tournament

output = []
last_tournament = None 


for match in toy_data : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    
    
    if name != last_tournament : 
        output.ammend([name, 0])
        last_tournament = name
        participants = set()
    
    if player_1 not in participants : 
        output[0][1] += 1
        participants.add(player_1)
        
    if player_2 not in participants : 
        output[0][1] += 1
        participants.add(player_2)
        
output
        
 
    
    
#Determining who all get a 'bye' in a round
128/59:
#Determining the total number of participants in the tournament

output = []
last_tournament = None 


for match in toy_data : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    
    
    if name != last_tournament : 
        output.append([name, 0])
        last_tournament = name
        participants = set()
    
    if player_1 not in participants : 
        output[0][1] += 1
        participants.add(player_1)
        
    if player_2 not in participants : 
        output[0][1] += 1
        participants.add(player_2)
        
output
        
 
    
    
#Determining who all get a 'bye' in a round
128/60:
#Determining the total number of participants in the tournament

output = []
last_tournament = None 


for match in toy_data : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    
    
    if name != last_tournament : 
        output.append([name, 0])
        last_tournament = name
        participants = set()
    
    if player_1 not in participants : 
        output[-1][1] += 1
        participants.add(player_1)
        
    if player_2 not in participants : 
        output[-1][1] += 1
        participants.add(player_2)
        
output
        
 
    
    
#Determining who all get a 'bye' in a round
128/61:
#Determining the total number of participants in the tournament

def get_total_participants(lst) : 
    output = []
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            output[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            output[-1][1] += 1
            participants.add(player_2)
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/62:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = []
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.append([name, 0, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            output[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            output[-1][1] += 1
            participants.add(player_2)
            
        output[-1][2] = int(math.log(output[-1][1],2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/63:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = []
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.append([name, 0, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            output[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            output[-1][1] += 1
            participants.add(player_2)
            
        output[-1][2] = floor(math.log(output[-1][1],2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/64:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = []
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.append([name, 0, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            output[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            output[-1][1] += 1
            participants.add(player_2)
            
        output[-1][2] = math.floor(math.log(output[-1][1],2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/65:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = []
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.append([name, 0, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            output[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            output[-1][1] += 1
            participants.add(player_2)
            
        output[-1][2] = math.ceiling(math.log(output[-1][1],2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/66:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = []
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.append([name, 0, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            output[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            output[-1][1] += 1
            participants.add(player_2)
            
        output[-1][2] = math.ceil(math.log(output[-1][1],2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/67:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data['Australian Open']
128/68:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    player_1 = match[4]
    player_2 = match[5]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
        
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/69:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/70:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

dct = get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
128/71:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

dct = get_total_participants(toy_data)

dct['Australian Open']
        
 
    
    
#Determining who all get a 'bye' in a round
128/72:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)

        
 
    
    
#Determining who all get a 'bye' in a round
128/73:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/74:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/75:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)

        
 
    
    
#Determining who all get a 'bye' in a round
128/76:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            if i < rounds - 2 :
                i += winners.count(player_1)
                match.append(i)
                
            elif i = rounds - 1 : 
                match.append('Quarter Finals')
            
            elif i = rounds : 
                match.append('Semi Finals')
                
            elif i = rounds + 1 : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            match.append(i)
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/77:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            if i < rounds - 2 :
                i += winners.count(player_1)
                match.append(i)
                
            elif i == rounds - 1 : 
                match.append('Quarter Finals')
            
            elif i == rounds : 
                match.append('Semi Finals')
                
            elif i == rounds + 1 : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            match.append(i)
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/78:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
128/79:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
128/80:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)

        
 
    
    
#Determining who all get a 'bye' in a round
128/81:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/82:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)['ASB Classic']

        
 
    
    
#Determining who all get a 'bye' in a round
128/83:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    name = match[0][0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
        match.append(i)
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
128/84:
winners = []
last_tournament = toy_data[0][0]

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if match[0] == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0] #Tournament name
    
    else : 
        winners = []
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        
toy_data
129/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
129/2:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
129/3:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
129/4:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
129/5:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
129/6:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
129/7:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
            
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
                
        
    
    else : 
        winners = []
        participants = set()
        
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
        
        
toy_data
129/8:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
129/9:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
            
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
                
        
    
    else : 
        winners = []
        participants = set()
        
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
        
        
toy_data
129/10:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
        
 
    
    
#Determining who all get a 'bye' in a round
131/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
131/2:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
131/3:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

toy_data
131/4:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
131/5:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
131/6:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
            
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
                
        
    
    else : 
        winners = []
        participants = set()
        
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
        
        
toy_data
131/7:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
131/8:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name == last_tournament :
        i = 1
        
        if player_1 in winners : 
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
            
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
                
        
    
    else : 
        winners = []
        participants = set()
        
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
        
        
toy_data
132/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2021.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/2:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/3:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/4:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2019.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/5:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/6:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/7:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'WTA Finals' : 
        print(matches)
132/8:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'WTA Elite Trophy' : 
        print(matches)
132/9:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/10:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2018.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/11:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/12:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/13:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for match in toy_data : 
    if match[0] == 'WTA Elite Trophy' : 
        print(match)
132/14:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2017.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/15:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/16:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/17:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2017.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/18:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/19:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/20:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/21:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/22:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/23:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/24:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output 

get_total_participants(toy_data)
132/25:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/26:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/27:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/28:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
    output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/29:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
            output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/30:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/31:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2020.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/32:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/33:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/34:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/35:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/36:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2017.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/37:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/38:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/39:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

toy_data
132/40:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/41:
#Determining the total number of participants in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/42:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2015.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/43:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/44:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/45:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2014.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/46:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/47:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/48:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' : 
        print(matches)
132/49:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/50:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/51:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[4] == 'Pironkova T.' : 
        print(matches)
132/52:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[4] == 'Cibulkova D.' : 
        print(matches)
132/53:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[4] == 'Suarez Navarro C.' : 
        print(matches)
132/54:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[5] == 'Suarez Navarro C.' : 
        print(matches)
132/55:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[5] == 'Petkovic A.' : 
        print(matches)
132/56:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[4] == 'Petkovic A.' : 
        print(matches)
132/57:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[5] == 'Petkovic A.' : 
        print(matches)
132/58:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' : 
        print(matches)
132/59:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 
    matches[4] == 'Pironkova T.' or matches[5] == 'Pironkova T.' : 
        print(matches)
132/60:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and matches[4] == 'Pironkova T.' or matches[5] == 'Pironkova T.' : 
        print(matches)
132/61:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Pironkova T.' in [matches[4], matches[5]] : 
        print(matches)
132/62:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Cibulkova D.' in [matches[4], matches[5]] : 
        print(matches)
132/63:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Suarez Navarro C.' in [matches[4], matches[5]] : 
        print(matches)
132/64:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Pennetta F.' in [matches[4], matches[5]] : 
        print(matches)
132/65:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Cornet A.' in [matches[4], matches[5]] : 
        print(matches)
132/66:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Muguruza G.' in [matches[4], matches[5]] : 
        print(matches)
132/67:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Petkovic A.' in [matches[4], matches[5]] : 
        print(matches)
132/68:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' : 
        print(matches)
132/69:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' and 'Suarez Navarro C.' in [matches[4], matches[5]] : 
        print(matches)
132/70:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' :  
        print(matches[4], matches[5])
132/71:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2013.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/72:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' :  
        print(matches[4], matches[5])
132/73:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/74:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return tournament

get_total_participants(toy_data)
132/75:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/76:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name in round_robin :
        
        
        
    else : 
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
            
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
                
        
    
    else : 
        winners = []
        participants = set()
        
        i = 1
        
        if player_1 in winners :  
            i += winners.count(player_1)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
            
            
        elif player_2 in winners : 
            i += winners.count(player_2)
            
            if i < rounds - 2 :
                match.append(i)
                
            elif i == rounds - 2 : 
                match.append('Quarter Finals')
            
            elif i == rounds - 1 : 
                match.append('Semi Finals')
                
            elif i == rounds  : 
                match.append('Finals')
        
        else : 
            match.append(i)
            
        winners.append(match[12])
        last_tournament = match[0]
        
        if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            
        if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
            if player_1 not in participants : 
                winners.append(player_1)
            
            if player_2 not in participants : 
                winners.append(player_2)
        
        
toy_data
132/77:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' :  
        print(matches[4], matches[5])
132/78:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2012.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/79:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Garanti Koza WTA Tournament of Champions' :  
        print(matches[4], matches[5])
132/80:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/81:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2012.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/82:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/83:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/84:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Sony Ericsson Championships' :  
        print(matches[4], matches[5])
132/85:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Qatar Airways Tournament of Champions Sofia' :  
        print(matches[4], matches[5])
132/86:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2011.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/87:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/88:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/89:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

for matches in toy_data : 
    if matches[0] == 'Sony Ericsson Championships' :  
        print(matches[4], matches[5])
132/90:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/91:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2011.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/92:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/93:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/94:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2010.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/95:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/96:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/97:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2009.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/98:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/99:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/100:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/101:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/102:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/103:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2007.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
132/104:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
132/105:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
132/106:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name in round_robin :
        
        
        
    else : 
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
        
toy_data
132/107:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name in round_robin :
        match.append('a')
        
        
        
    else : 
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
        
toy_data
133/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2015.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/2:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/3:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
133/4:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name not in round_robin_usual :
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
        match.append('a')
        
    else if name in round_robin : 
        participants_count = []
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
            
                
toy_data
133/5:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name not in round_robin_usual :
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
        match.append('a')
        
    elif name in round_robin : 
        participants_count = []
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
            
                
toy_data
133/6:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name not in round_robin :
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
        match.append('a')
        
    elif name in round_robin : 
        participants_count = []
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
            
                
toy_data
133/7:
winners = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name not in round_robin :
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
    elif name in round_robin : 
        participants_count = []
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
            
                
toy_data
133/8:
for matches in toy_data : 
    if matches[0] in round_robin : 
        print(matches)
133/9:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2015.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/10:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/11:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
133/12:
winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name not in round_robin :
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
    elif name in round_robin : 
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
133/13:
for matches in toy_data : 
    if matches[0] in round_robin : 
        print(matches)
133/14:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/15:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/16:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    last_tournament = None 
    tournament = []
    
    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = math.ceil(math.log(tournament[-1][1], 2))
        
    return output

get_total_participants(toy_data)
133/17:
winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_participants(toy_data)[name]
    
    if name not in round_robin :
        if name == last_tournament :
            i = 1
            
            if player_1 in winners : 
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners :# To account for byes
                i += winners.count(player_2)
            
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
                    
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    winners.append(player_1)
                    
                if player_2 not in participants : 
                    winners.append(player_2)
                
        else : 
            winners = []
            participants = set()
            i = 1
            
            if player_1 in winners :  
                i += winners.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in winners : 
                i += winners.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            winners.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    winners.append(player_1)
            
                if player_2 not in participants : 
                    winners.append(player_2)
        
    elif name in round_robin : 
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
133/18:
for matches in toy_data : 
    if matches[0] in round_robin : 
        print(matches)
133/19:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = {}
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
        return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(name), 2))
        
        return output 
    
get_total_participants(toy_data)
133/20:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
        return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(name), 2))
        
        return output 
    
get_total_participants(toy_data)
133/21:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(name), 2))
        
        return output 
    
get_total_participants(toy_data)
133/22:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(name), 2))
        
    return output 
    
get_total_participants(toy_data)

get_total_rounds(toy_data)
133/23:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 
    
get_total_participants(toy_data)

get_total_rounds(toy_data)
133/24:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0] 
        i = 0
        
        if name != last_tournament : 
            output.update({name : 0})
            i += 1 
            last_tournament = name
                
        output[name] = i 
        
        return ouput 
            
    

get_total_matches(toy_data)
133/25:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0] 
        i = 0
        
        if name != last_tournament : 
            output.update({name : 0})
            i += 1 
            last_tournament = name
                
        output[name] = i 
        
        return output 
            
    

get_total_matches(toy_data)
133/26:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None 
    
    for match in toy_data : 
        name = match[0] 
        i = 0
        
        if name != last_tournament : 
            output.update({name : 0})
            i += 1 
            last_tournament = name
                
        output[name] = i 
        
    return output 
            
    

get_total_matches(toy_data)
133/27:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = toy_data[0][0]
    
    for match in toy_data : 
        name = match[0] 
        i = 0
        
        if name != last_tournament : 
            output.update({name : 0})
            i += 1 
            last_tournament = name
            output[name] = i 
        
    return output 
            
    

get_total_matches(toy_data)
133/28:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        i = 0
        
        if name != last_tournament : 
            output.update({name : 0})
            i += 1 
            last_tournament = name
            output[name] = i 
        
    return output 
            
    

get_total_matches(toy_data)
133/29:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        i = 1
        
        if name != last_tournament : 
            output.update({name : 0}) 
            last_tournament = name
            
        elif name == last_tournament : 
            i += 1
            output[name] = i 
        
    return output 
            
    

get_total_matches(toy_data)
133/30:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        i = 1
        
        if name != last_tournament : 
            output.update({name : 0}) 
            last_tournament = name
            
        elif name == last_tournament : 
            i += 1
            
        output[name] = i 
        
    return output 
            
    

get_total_matches(toy_data)
133/31:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    i = 1
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 0}) 
            last_tournament = name
            
        elif name == last_tournament : 
            i += 1
            
        output[name] = i 
        
    return output 
            
    

get_total_matches(toy_data)
133/32:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    i = 1
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 0}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output 
            
    

get_total_matches(toy_data)
133/33:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output 
            
    

get_total_matches(toy_data)
133/34:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output 
            
    

for matches in toy_data : 
    if get_total_participants(toy_data)[matches[0]] == get_total_matches(toy_data)[matches[0]] + 1 : 
        print(matches)
133/35:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output 
            
    

for matches in toy_data : 
    if get_total_participants(toy_data)[matches[0]] == get_total_matches(toy_data)[matches[0]] + 1 : 
        print(matches[0])
133/36:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output 
            
    

for matches in toy_data : 
    if get_total_participants(toy_data)[matches[0]] != get_total_matches(toy_data)[matches[0]] + 1 : 
        print(matches[0])
133/37:
from itertools import groupby

list(g) for k,g in groupby(toy_data, lambda x : x[0])
133/38:
from itertools import groupby

[list(g) for k,g in groupby(toy_data, lambda x : x[0])]
133/39:
from itertools import groupby

[g[1] for k,g in groupby(toy_data, lambda x : x[0])]
133/40:
from itertools import groupby

for k,g in groupby(toy_data, lambda x : x[0]): 
    print(group[0] for group in g)
133/41:
from itertools import groupby

for k,g in groupby(toy_data, lambda x : x[0]): 
    print([group[0] for group in g])
133/42:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/43:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/44:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
133/45:
winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for match in toy_data :
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_rounds(toy_data)[name]
    
    if name not in round_robin :
        if name == last_tournament :
            i = 1
            
            no_of_players = get_total_participants(toy_data)[name]
            no_of_matches = get_total_matches(toy_data)[name]
            
            if no_of_players == no_of_matches - 1 : #No third place tournaments
            
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)

                    if i < rounds - 2 :
                        match.append(i)

                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')

                    elif i == rounds - 1 : 
                        match.append('Semi Finals')

                    elif i == rounds  : 
                        match.append('Finals')


                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)

                    if i < rounds - 2 :
                        match.append(i)

                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')

                    elif i == rounds - 1 : 
                        match.append('Semi Finals')

                    elif i == rounds  : 
                        match.append('Finals')
                        
                else : 
                    match.append(i)
                        
            elif no_of_players == no_of_matches : #Third place tournaments 
                 
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)

                    if i < rounds - 2 :
                        match.append(i)

                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')

                    elif i == rounds - 1 : 
                        match.append('Semi Finals')

                    elif i == rounds  : 
                        match.append('Finals')


                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)

                    if i < rounds - 2 :
                        match.append(i)

                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')

                    elif i == rounds - 1 : 
                        match.append('Semi Finals')

                    elif i == rounds  : 
                        match.append('Finals')
                        
                else : 
                    match.append(i)
                
                
            
            participants_count.append(match[12])
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)
                    
                if player_2 not in participants : 
                    participants_count.append(player_2)
                
        else : 
            participants_count = []
            participants = set()
            i = 1
            
            if player_1 in participants_count :  
                i += participants_count.count(player_1)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
            
            
            elif player_2 in participants_count : 
                i += participants_count.count(player_2)
                
                if i < rounds - 2 :
                    match.append(i)
                
                elif i == rounds - 2 : 
                    match.append('Quarter Finals')
            
                elif i == rounds - 1 : 
                    match.append('Semi Finals')
                
                elif i == rounds  : 
                    match.append('Finals')
        
            else : 
                match.append(i)
            
            participants_count.append(match[12])
            last_tournament = match[0]
        
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice
                if player_1 not in participants : 
                    participants_count.append(player_1)
            
                if player_2 not in participants : 
                    participants_count.append(player_2)
        
    elif name in round_robin : 
        participants_count.append(player_1)
        participants_count.append(player_2)
        
        i = max(participants_count.count(player_1), participants_count.count(player_2)) 
        
        if name != 'WTA Elite Trophy': 
            
            if i <= 3 : 
                match.append('Group Stage')
            
            if i == 4 : 
                match.append('Semi Finals')
                
            if i == 5 : 
                match.append('Finals')
                
        else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
            
            if i <= 2 : 
                match.append('Group Stage')
            
            if i == 3 : 
                match.append('Semi Finals')
                
            if i == 4 : 
                match.append('Finals')
133/46:
#Not in RR 
from itertools import groupby 

winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for key, match in groupby(toy_data, lambda x : x[0]) : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_rounds(toy_data)[name]
    
    if name == last_tournament :
        i = 1

        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
            
            participants_count.append(player_1)
            participants_count.append(player_2)
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
            participants.add(player_1)
            participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

                
                

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
133/47:
#Not in RR 
from itertools import groupby 

winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for key, match in groupby(toy_data, lambda x : x[0]) : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]
    rounds = get_total_rounds(toy_data)[name]
    
    if name == last_tournament :
        i = 1

        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
            
            participants_count.append(player_1)
            participants_count.append(player_2)
            last_tournament = match[0]
            
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)
            
            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

                
                

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
133/48:
check = grouppby(toy_data, lambda x : x[0])

for key, match in check : 
    print(key)
133/49:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    print(key)
133/50:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    print(match)
133/51:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    print(match[0])
133/52:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    print(match for match in match)
133/53:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    print[match for match in match]
133/54:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    print([match for match in match])
133/55:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    for m in match : 
        print(m)
133/56:
#Not in RR 
from itertools import groupby 

winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for key, group in groupby(toy_data, lambda x : x[0]) : 
    for match in group :
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
            last_tournament = match[0]

            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)




            elif no_of_players == no_of_matches : #Third place tournaments 

                if player_1 in participants_count : 
                    i += participants_count.count(player_1)

                    if i < rounds - 2 :
                        match.append(i)

                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')

                    elif i == rounds - 1 : 
                        match.append('Semi Finals')

                    elif i == rounds  : 
                        match.append('Finals')


                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)

                    if i < rounds - 2 :
                        match.append(i)

                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')

                    elif i == rounds - 1 : 
                        match.append('Semi Finals')

                    elif i == rounds  : 
                        match.append('Finals')

                else : 
                    match.append(i)
133/57:
#Not in RR 
from itertools import groupby 

winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for key, group in groupby(toy_data, lambda x : x[0]) : 
    
    for match in group :
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
            last_tournament = match[0]

            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)




        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
133/58:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    for m in match : 
        m.append(m[0])
133/59:
check = groupby(toy_data, lambda x : x[0])

for key, match in check : 
    for m in match : 
        m.append(m[0])
        print(m)
133/60:
#Not in RR 
from itertools import groupby 

winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for key, group in groupby(toy_data, lambda x : x[0]) : 
    
    for match in group :
        
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
    
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
                
        print(match)
133/61:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/62:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/63:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
133/64:
#Not in RR 
from itertools import groupby 

winners = []
participants_count = []
last_tournament = toy_data[0][0]
participants = set()

for key, group in groupby(toy_data, lambda x : x[0]) : 
    
    for match in group :
        
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
    
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
                
        print(match)
133/65:
#Not in RR 
from itertools import groupby 

winners = []
last_tournament = toy_data[0][0]
participants = set()

for key, group in groupby(toy_data, lambda x : x[0]) : 
    
    for match in group :
        
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        participants_count = []
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]
        i = 1

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
    
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
                
        print(match)
133/66:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/67:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/68:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
133/69:
#Not in RR 
from itertools import groupby 

winners = []
last_tournament = toy_data[0][0]
participants = set()

for key, group in groupby(toy_data, lambda x : x[0]) : 
    
    for match in group :
        
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        participants_count = []
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]
        i = 1

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
    
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

toy_data
133/70:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/71:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/72:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
133/73:
#Not in RR 
from itertools import groupby 

winners = []
last_tournament = toy_data[0][0]
participants = set()

grouping = groupby(toy_data, lambda x : x[0]) 

for key, group in grouping : 
    
    for match in group :
        
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        participants_count = []
        rounds = get_total_rounds(toy_data)[name]
        no_of_players = get_total_participants(toy_data)[name]
        no_of_matches = get_total_matches(toy_data)[name]
        i = 1

        if no_of_players == no_of_matches + 1 : #No third place tournaments

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 2 :
                    match.append(i)

                elif i == rounds - 2 : 
                    match.append('Quarter Finals')

                elif i == rounds - 1 : 
                    match.append('Semi Finals')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)

            participants_count.append(player_1)
            participants_count.append(player_2)
    
            if i == 1 : #Store the participants of R1
                participants.add(player_1)
                participants.add(player_2)

            if i == 2 : #Add the players that got a 'bye' in R1 to the appearence list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                if player_1 not in participants : 
                    participants_count.append(player_1)

                if player_2 not in participants : 
                    participants_count.append(player_2)

        elif no_of_players == no_of_matches : #Third place tournaments 

            if player_1 in participants_count : 
                i += participants_count.count(player_1)

                if i < rounds - 3 :
                    match.append(i)
                
                elif i == rounds - 3 : 
                    match.append('Quarter Finals')

                elif i == rounds - 2 : 
                    match.append('Semi Finals')

                elif i == rounds - 1 : 
                    match.append('Third Place')

                elif i == rounds  : 
                    match.append('Finals')


            elif player_2 in participants_count : # To account for byes in R2
                i += participants_count.count(player_2)

                if i < rounds - 3 :
                    match.append(i)
                    
                elif i == rounds - 3 : 
                    match.append('Quarter Finals')

                elif i == rounds - 2 : 
                    match.append('Semi Finals')

                elif i == rounds - 1 : 
                    match.append('Third Place')

                elif i == rounds  : 
                    match.append('Finals')

            else : 
                match.append(i)
                
        print(match)
133/74:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/75:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/76:
#Determining the total number of rounds in the tournament

import math

def get_total_participants(lst) : 
    output = {}
    tournament = []
    last_tournament = None 

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if name != last_tournament : 
            output.update({name : 0})
            tournament.append([name, 0])
            last_tournament = name
            participants = set()
            
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)
        
        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)
            
        output[name] = tournament[-1][1]
        
    return output 
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in toy_data : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
133/77:
import numpy as np 

np.split(toy_data[:,1], np.unique(toy_data[:, 0]))
133/78:
import numpy as np 

np.split(toy_data[:,1], np.unique(toy_data[:, 0])[1][1:])
133/79:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
133/80:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
133/81:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if name not in prev_winner : 
            output.update({name : 1})
        
        elif name in prev_winner : 
            output[name] += 1
133/82:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if name not in prev_winner : 
            output.update({name : 1})
        
        elif name in prev_winner : 
            output[name] += 1

get_wins(toy_data)
133/83:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if name not in prev_winner : 
            output.update({name : 1})
        
        elif name in prev_winner : 
            output[name] += 1
        
        return output

get_wins(toy_data)
133/84:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if name not in prev_winner : 
            output.update({winner : 1})
        
        elif name in prev_winner : 
            output[winner] += 1
        
        return output

get_wins(toy_data)
133/85:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if name not in prev_winner : 
            output.update({winner : 1})
        
        elif name in prev_winner : 
            output[winner] += 1
        
    return output

get_wins(toy_data)
133/86:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if name not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif name in prev_winner : 
            output[winner] += 1
        
    return output

get_wins(toy_data)
133/87:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output

get_wins(toy_data)
133/88:
for matches in toy_data : 
    if matches[12] == 'Wang Q.' : 
        print(matches)
133/89:
for matches in toy_data : 
    if matches[12] == 'King V.' : 
        print(matches)
133/90:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


win_count = get_wins(toy_data)
sorted(win_count, key = win_count.get)
133/91:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


win_count = get_wins(toy_data)

for key in sorted(win_count, key = win_count.get) : 
    print(key, win_count[key])
133/92:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


win_count = get_wins(toy_data)

for key in sorted(win_count, key = win_count.get, reverse = True) : 
    print(key, win_count[key])
133/93:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


win_count = get_wins(toy_data)

for key in sorted(win_count.items, key = lambda x : x[1], reverse = True) : 
    print(key, win_count[key])
133/94:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


win_count = get_wins(toy_data)

for key, value in sorted(win_count.items, key = lambda x : x[1], reverse = True) : 
    print(key, value)
133/95:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


win_count = get_wins(toy_data)

for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
    print(key, value)
133/96:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update(key : value)
        
    return output
133/97:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update({key : value})
        
    return output
133/98:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update({key : value})
        
    return output

get_rank(toy_data)
133/99:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append({key : value})
        
    return output

get_rank(toy_data)
133/100:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append(key : value)
        
    return output

get_rank(toy_data)
133/101:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append(key, value)
        
    return output

get_rank(toy_data)
133/102:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output

get_rank(toy_data)
133/103:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append({key, value})
        
    return output

get_rank(toy_data)
133/104:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update({key, value})
        
    return output

get_rank(toy_data)
133/105:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update({key : value})
        
    return output

get_rank(toy_data)
133/106:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = {}
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update({key : value})
        
    return output[:3]

get_rank(toy_data)
133/107:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.update([key, value])
        
    return output[:3]

get_rank(toy_data)
133/108:
def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_rank(toy_data)
133/109:
#Ans4

def get_total_players(lst) : 
    output = {}
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            output.update({player_1 : 0})
            players.add(player_1)
        
        if player_2 not in participants : 
            output.update({player_1 : 0})
            players.add(player_2)
    
    return output
133/110:
#Ans4

def get_players(lst) : 
    output = {}
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            output.update({player_1 : 0})
            players.add(player_1)
        
        if player_2 not in participants : 
            output.update({player_1 : 0})
            players.add(player_2)
    
    return output

get_players(toy_data)
133/111:
#Ans4

def get_players(lst) : 
    output = {}
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            output.update({player_1 : 0})
            players.add(player_1)
        
        if player_2 not in participants : 
            output.update({player_1 : 0})
            players.add(player_2)
            
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

get_players(toy_data)
133/112:
#Ans4

def get_players(lst) : 
    output = {}
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            output.update({player_1 : 0})
            players.add(player_1)
        
        if player_2 not in participants : 
            output.update({player_1 : 0})
            players.add(player_2)
            
    return output


def initialize_score(lst) : 
    output = get_players(lst) 
    count_players = len(players)
    
    for key in players : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)
133/113:
#Ans4

def get_players(lst) : 
    output = {}
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            output.update({player_1 : 0})
            players.add(player_1)
        
        if player_2 not in participants : 
            output.update({player_1 : 0})
            players.add(player_2)
            
    return output


def initialize_score(lst) : 
    output = get_players(lst) 
    count_players = len(output)
    
    for key in players : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)
133/114:
#Ans4

def get_players(lst) : 
    output = {}
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            output.update({player_1 : 0})
            players.add(player_1)
        
        if player_2 not in participants : 
            output.update({player_1 : 0})
            players.add(player_2)
            
    return output


def initialize_score(lst) : 
    output = get_players(lst) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)
133/115:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
        
    count_players = len(output)
    output[key] = 1/count_players
    
    return output

initialize_score(toy_data)
133/116:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
        
    count_players = len(output)
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)
133/117:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in ouput : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key = winner : 
                    wins += 1 
                else : 
                    lost_to.append[winner]
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = ouput[winners] + temp
    
    return output
133/118:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in ouput : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append[winner]
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = ouput[winners] + temp
    
    return output
133/119:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in ouput : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append[winner]
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = ouput[winners] + temp
    
    return output

update_scores(toy_data)
133/120:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in output : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append[winner]
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = ouput[winners] + temp
    
    return output

update_scores(toy_data)
133/121:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in output : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = ouput[winners] + temp
    
    return output

update_scores(toy_data)
133/122:
#Ans4

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players


def initialize_score(lst) : 
    players = get_players(lst) 
    output = {}
    
    for player in players : 
        output.update({player : 0})
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in output : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

update_scores(toy_data)
134/1:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2016.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/2:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
134/3:
#Ans 2 

def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_rank(toy_data)
134/4:
#Ans 2 

def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output

get_rank(toy_data)
134/5:
#Ans 2 

def get_wins(lst) : 
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12] 
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_rank(toy_data)
134/6:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/7:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in participants : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
players

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/8:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
players

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/9:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
players

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/10:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
print(players)

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/11:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = fromkeys(players, 0)
print(dct)

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/12:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = dict.fromkeys(players, 0)
print(dct)

def get_wins(lst) :
    players = get_players(lst)
    output = {}
    prev_winner = set() 
    
    for match in lst : 
        winner = match[12]
        
        if winner not in prev_winner : 
            output.update({winner : 1})
            prev_winner.add(winner)
        
        elif winner in prev_winner : 
            output[winner] += 1
        
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/13:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = dict.fromkeys(players, 0)
length(dct)

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/14:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = dict.fromkeys(players, 0)
len(dct)

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/15:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = dict.fromkeys(players, 0)
len(dct)

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/16:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = dict.fromkeys(players, 0)
print()len(dct)

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/17:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

players = get_players(toy_data)
dct = dict.fromkeys(players, 0)
print(len(dct))

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/18:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_wins(toy_data)
134/19:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

len(get_wins(toy_data))
134/20:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output

get_rank(toy_data)
134/21:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
            
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(toy_data)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_rank(toy_data)
134/22:
#Ans4

def initialize_score(lst) : 
    players = get_players(lst) 
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

initialize_score(toy_data)

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in output : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output
134/23:
#Ans4

def initialize_score(lst) : 
    players = get_players(lst) 
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

def update_scores(lst) : 
    output = initialize_score(lst) 
    
    for key in output : 
        loss = 0
        wins = 0 
        lost_to = []
        
        for match in lst : 
            players = [match[4], match[5]]
            winner = match[12] 
            
            if key in players : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

initialize_score(toy_data)
134/24:
#Ans4
players = get_players(lst) 

def initialize_score(lst) : 
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

def update_scores(lst) : 
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

initialize_score(toy_data)
134/25:
#Ans4 

def initialize_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players
    
    return output

def update_scores(lst) : 
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

initialize_score(toy_data)
134/26:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            temp = output[key]/loss
            output[key] = output[key] - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

get_scores(toy_data)
134/27:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            temp = output[key]/loss
            output[key] = output[key] - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 
    temp = output[key]/loss                
    output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

get_score(toy_data)
134/28:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            if loss == 0 : 
                output[key] += output[key]
                
            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 
    if loss = 0 : 
        
    else :
        temp = output[key]/loss
        output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

get_score(toy_data)
134/29:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            if loss == 0 : 
                output[key] += output[key]
                
            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 
    if loss == 0 : 
        
    else :
        temp = output[key]/loss
        output[key] = output[key] - temp
    
    for winners in lost_to : 
        output[winners] = output[winners] + temp
    
    return output

get_score(toy_data)
134/30:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            if loss == 0 : 
                output[key] += output[key]
                
            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/31:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                current = output[key]
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            if loss == 0 : 
                output[key] += current
                
            else : 
                temp = current/loss
                output[key] = current - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/32:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        output[key] = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                current = output[key]
                
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
            if loss == 0 : 
                output[key] += current
                
            else : 
                temp = current/loss
                output[key] = current - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/33:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        current = 1/count_players #Step for initializing
        loss = 0
        wins = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                
                if key == winner : 
                    wins += 1 
                else : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += current + current
                
        else : 
            temp = current/loss
            output[key] = current + current - temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/34:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    output = dict.fromkeys(players, 0) 
    count_players = len(output)
    
    for key in output : 
        current = 1/count_players #Step for initializing
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += current + current
                
        else : 
            temp = current/loss
            output[key] = current + current - temp
            
            for players in lost_to :   
                output[players] += temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/35:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(output)
    output = dict.fromkeys(players, count_players) #initialize
    
    for key in output : 
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += output[key]
                
        else : 
            temp = current/loss
            output[key] = output[key] - temp
            
            for players in lost_to :   
                output[players] += temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/36:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    output = dict.fromkeys(players, count_players) #initialize
    
    for key in output : 
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += output[key]
                
        else : 
            temp = current/loss
            output[key] = output[key] - temp
            
            for players in lost_to :   
                output[players] += temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/37:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    output = dict.fromkeys(players, count_players) #initialize
    
    for key in output : 
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += output[key]
                
        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in lost_to :   
                output[players] += temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/38:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for key in output : 
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += output[key]
                
        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in lost_to :   
                output[players] += temp
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/39:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for key in output : 
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += output[key]
                
        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in lost_to :   
                output[players] += temp
                
        output[key] = 0.85*output[key] + (0.15/count_players)#rescale
                    
    return output

def update_scores(lst) : 
    
    output = initialize_score(lst) 
    loss = 0
    wins = 0 
    lost_to = []
        
    for match in lst : 
        players = [match[4], match[5]]
        winner = match[12] 

        if key in players : 
            if key == winner : 
                wins += 1 
            else : 
                lost_to.append(winner)
                loss += 1 

    
    return output

get_score(toy_data)
134/40:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for i in range(100): 
        for key in output : 
            loss = 0
            lost_to = []

            for match in lst : 
                player_match = [match[4], match[5]]
                winner = match[12]

                if key in player_match : 
                    if key != winner : 
                        lost_to.append(winner)
                        loss += 1

            if loss == 0 : 
                output[key] += output[key]

            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp

                for players in lost_to :   
                    output[players] += temp

            output[key] = 0.85*output[key] + (0.15/count_players)#rescale
                    
    return output

get_score(toy_data)
134/41:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for key in output : 
        loss = 0
        lost_to = []
        
        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]
            
            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1
            
        if loss == 0 : 
            output[key] += output[key]
                
        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in lost_to :   
                output[players] += temp
                
        output[key] = 0.85*output[key] + (0.15/count_players)#rescale
                    
    return output

get_score(toy_data)
134/42:
#Ans4 



def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for loop in itertools.count() : 
        for key in output : 
            loss = 0
            lost_to = []

            for match in lst : 
                player_match = [match[4], match[5]]
                winner = match[12]

                if key in player_match : 
                    if key != winner : 
                        lost_to.append(winner)
                        loss += 1

            if loss == 0 : 
                output[key] += output[key]

            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp

                for players in lost_to :   
                    output[players] += temp

            output[key] = 0.85*output[key] + (0.15/count_players)#rescale
                    
    return output

get_score(toy_data)
134/43:
#Ans4 

from itertools import itertools.count

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for loop in itertools.count() : 
        for key in output : 
            loss = 0
            lost_to = []

            for match in lst : 
                player_match = [match[4], match[5]]
                winner = match[12]

                if key in player_match : 
                    if key != winner : 
                        lost_to.append(winner)
                        loss += 1

            if loss == 0 : 
                output[key] += output[key]

            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp

                for players in lost_to :   
                    output[players] += temp

            output[key] = 0.85*output[key] + (0.15/count_players)#rescale
                    
    return output

get_score(toy_data)
134/44:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    
    for loop in itertools.count() : 
        for key in output : 
            loss = 0
            lost_to = []

            for match in lst : 
                player_match = [match[4], match[5]]
                winner = match[12]

                if key in player_match : 
                    if key != winner : 
                        lost_to.append(winner)
                        loss += 1

            if loss == 0 : 
                output[key] += output[key]

            else : 
                temp = output[key]/loss
                output[key] = output[key] - temp

                for players in lost_to :   
                    output[players] += temp

            output[key] = 0.85*output[key] + (0.15/count_players)#rescale
                    
    return output

get_score(toy_data)
134/45:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
     
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

get_score(toy_data)
134/46:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, '')
lost_to
134/47:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to
134/48:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to[Mateas M.].append['a']
134/49:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
134/50:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
lost_to
134/51:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].update('a')
lost_to
134/52:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
lost_to
134/53:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to = lost_to['Mateas M.'].append('a')
lost_to
134/54:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to = lost_to['Mateas M.'].append('a')
print(lost_to)
134/55:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
134/56:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
lost_to
134/57:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = [match[4], match[5]]
        winner = match[12]
        
    
    for key in output : 
        loss = 0
        lost_to = []

        for match in lst : 
            player_match = [match[4], match[5]]
            winner = match[12]

            if key in player_match : 
                if key != winner : 
                    lost_to.append(winner)
                    loss += 1

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

            for players in lost_to :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.']
134/58:
from collections import defaultdict 

dct = defaultdict(list)
dct
134/59:
from collections import defaultdict 

dct = defaultdict(list)
dct = dict.fromkeys(players, [])
134/60:
from collections import defaultdict 

dct = defaultdict(list)
dct = dict.fromkeys(players, [])
dct
134/61:
from collections import defaultdict 

dct = defaultdict(list)
dct = dict.fromkeys(players, [])
dct['Mateas M.'].append('a')
134/62:
from collections import defaultdict 

dct = defaultdict(list)
dct = dict.fromkeys(players, [])
dct['Mateas M.'].append('a')
dct
134/63:
from collections import defaultdict 

dct = defaultdict(list)
dct['Mateas M.'].append('a')
dct
134/64:
from collections import defaultdict 

dct = defaultdict(list)
players = get_players(toy_data)
dct['Mateas M.'].append('a')
dct
134/65:
from collections import defaultdict 

dct = defaultdict(list)
players = get_players(toy_data)
for players in players : 
    dct[players] : []
dct['Mateas M.'].append('a')
dct
134/66:
from collections import defaultdict 

dct = defaultdict(list)
players = get_players(toy_data)

for players in players : 
    dct[players] : []
134/67:
from collections import defaultdict 

dct = defaultdict(list)
players = get_players(toy_data)

for players in players : 
    dct[players] : []
        
dct
134/68:
a = ['abc', 'def']
loser = a[!'def']
134/69:
a = set('abc', 'def')
b = set('def')
loser = a - b
134/70:
a = {'abc', 'def'}
b = {'def'}
loser = a-b
134/71:
a = {'abc', 'def'}
b = {'def'}
loser = a-b
loser
134/72:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
print(lost_to['Mateas M.'])
134/73:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'].append('a')
print(lost_to)
134/74:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
print(lost_to)
134/75:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])

if 'Mateas M.'in lost_to : 
    lost_to["Mateas M."].append('a')
else : 
    lost_to["Mateas M."].append('a')
    
print(lost_to)
134/76:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'] += []
134/77:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'] += ['a']
lost_to
134/78:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy 
players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to = copy.deepcopy(lost_to)
lost_to['Mateas M.'] += ['a']
lost_to
134/79:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
lost_to = dict.fromkeys(players, [])
lost_to2 = copy.deepcopy(lost_to)
lost_to2['Mateas M.'] += ['a']
lost_to2
134/80:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
players = copy.deepcopy(players)
lost_to = dict.fromkeys(players, [])
lost_to['Mateas M.'] += ['a']
lost_to
134/81:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
players1 = copy.deepcopy(players)
lost_to = dict.fromkeys(players1, [])
lost_to['Mateas M.'] += ['a']
lost_to
134/82:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = dict.fromkeys(players, initial) #initialize
    lost_to = dict.fromkeys(players, '')
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
lost_to = {players : [] for players in players}
lost_to['Mateas M.'] += ['a']
lost_to
134/83:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : [] for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
lost_to = {players : [] for players in players}

for match in toy_data : 
    player_match = {match[4], match[5]}
    winner = {match[12]}
    loser = player_match - winner
    lost_to[loser].append(winner)
    
lost_to
134/84:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : [] for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
lost_to = {players : [] for players in players}

for match in toy_data : 
    player_match = {match[4], match[5]}
    winner = {match[12]}
    loser = player_match - winner
    lost_to[loser].append(list(winner))
    
lost_to
134/85:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : [] for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
lost_to = {players : [] for players in players}

for match in toy_data : 
    player_match = {match[4], match[5]}
    winner = {match[12]}
    loser = player_match - winner
    lost_to[loser].append(winner for winner in winner)
    
lost_to
134/86:
a = {'abc', 'def'}
b = {'def'}
loser = a-b
ast.literat_eval(loser)
134/87:
a = {'abc', 'def'}
b = {'def'}
loser = a-b
repr(loser)
134/88:
a = {'abc', 'def'}
b = {'def'}
loser = a-b
list(loser)
134/89:
a = {'abc', 'def'}
b = {'def'}
loser = a-b
str(list(loser))
134/90:
a = ['abc', 'def']
b = ['def']

a not in b
134/91:
a = ['abc', 'def']
b = ['def']

which(a not in b)
134/92:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : [] for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player_match = {match[4], match[5]}
        winner = {match[12]}
        loser = player_match - winner
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

import copy

players = get_players(toy_data)
lost_to = {players : [] for players in players}

for match in toy_data : 
    player1 = match[4]
    player2 = match[5]
    winner = match[12]
    if player1 == winner : 
        loser = player2 
    else : 
        loser = player1
    
    lost_to[loser].append(winner)
    
lost_to
134/93:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output
134/94:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp

        for players in beat :   
            output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

get_score(toy_data)
134/95:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

get_score(toy_data)
134/96:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

get_score(toy_data)['Kerber A.']
134/97:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

get_score(toy_data)['Cibulkova D.']
134/98:
#Ans4 

import itertools

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] = output[key] - temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players)#rescale

    return output

get_score(toy_data)
134/99:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_score(toy_data)
134/100:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst) : 
    win_count = get_wins(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_rank(toy_data)
134/101:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]

get_rank(toy_data, get_wins)
134/102:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/103:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/104:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output
134/105:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/106:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        
    return output[:3]
134/107:
#Ans4 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/108:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i += 1
        
    return output[:3]
134/109:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/110:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
    
    prev_score = 0 
    i = 0
    for player in output : 
        score = player[1] 
        if score > prev_score : 
            i += 1
            output.append(i)
            prev_score = score
        elif score == prev_score : 
            output.append(i)
            
    return output[:3]
134/111:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/112:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
    
    prev_score = 0 
    i = 0
    
    for player in output : 
        score = player[1] 
        if score > prev_score : 
            i += 1
            output.append(i)
            prev_score = score
        elif score == prev_score : 
            output.append(i)
            
    return output[:3]
134/113:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/114:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
            
    return output[:3]
134/115:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/116:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

a = get_rank(toy_data, get_score)

for player in a : 
    print(a)
134/117:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

a = get_rank(toy_data, get_score)

a[1]
134/118:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

a = get_rank(toy_data, get_score)

a[2]
134/119:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

a = get_rank(toy_data, get_score)

for i in a : 
    print(a[i])
134/120:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

a = get_rank(toy_data, get_score)

for i in a : 
    i
134/121:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

a = get_rank(toy_data, get_score)

for i in a : 
    print(i)
134/122:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
    
    prev_score = 0 
    i = 0
    for row in output : 
        score = player[1] 
        if score > prev_score : 
            i += 1
            output.append(i)
            prev_score = score
        elif score == prev_score : 
            output.append(i)
            
    return output[:3]
134/123:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
    
    prev_score = 0 
    i = 0
    for row in output : 
        score = row[1] 
        if score > prev_score : 
            i += 1
            output.append(i)
            prev_score = score
        elif score == prev_score : 
            output.append(i)
            
    return output[:3]
134/124:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output
134/125:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

get_rank(toy_data, get_score)
134/126:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


for a in get_rank(toy_data, get_score) : 
    print(a[1])
134/127:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
            
    return output[:3]
134/128:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


for a in get_rank(toy_data, get_score) : 
    print(a[1])
134/129:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
        

    return output[:3]
134/130:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


for a in get_rank(toy_data, get_score) : 
    score = a[1]
134/131:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


for a in get_rank(toy_data, get_score) : 
    score = a[1]
    print(score)
134/132:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
    
    for row in output : 
        score = row[1]
    
    return output[:3]
134/133:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/134:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
    
    i = 0
    prev_score = 0
    for row in output : 
        score = row[1]
        if score > prev_score : 
            i += 1 
            output.append(i)
            prev_score = score
        elif score == prev_score : 
            output.append(i)
        
    
    return output[:3]
134/135:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/136:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/137:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value])
    
    i = 0
    prev_score = 0
    for line in output : 
        score = line[1]
        
        if score > prev_score : 
            i += 1 
            output.append(i)
            prev_score = score
        elif score == prev_score : 
            output.append(i)
        
    
    return output[:3]
134/138:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/139:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 0
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output[:3]
134/140:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/141:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output[:3]
134/142:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/143:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2007.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/144:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
134/145:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output[:3]
134/146:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/147:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output
134/148:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)
134/149:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)[:3]
134/150:
#Ans 5

initial_rank = get_rank(toy_data, get_score)
134/151:
#Ans 5

initial_rank = get_rank(toy_data, get_score)
initial_rank
134/152:
#Ans 5
players = get_players(toy_data)
players
initial_rank = get_rank(toy_data, get_score)
134/153:
#Ans 5
players = get_players(toy_data)
players
134/154:
#Ans 5
players = get_players(toy_data)
players
initial_rank_dct = {(players : 0 for players in players)}
134/155:
#Ans 5
players = get_players(toy_data)
players
initial_rank_dct = {players : 0 for players in players}
134/156:
#Ans 5
players = get_players(toy_data)
players
initial_rank_dct = {players : 0 for players in players}
initial_rank_dct
134/157:
#Ans 5

get_rank_dct = {}

for player in get_rank(toy_data, get_score) : 
    key, value = player[0], player[2]
    get_rank_dct[key] = value
134/158:
#Ans 5

get_rank_dct = {}

for player in get_rank(toy_data, get_score) : 
    key, value = player[0], player[2]
    get_rank_dct[key] = value

get_rank_dct
134/159:
#Ans 5

get_rank_dct_2007 = {}

for player in get_rank(toy_data, get_score) : 
    key, value = player[0], player[2]
    get_rank_dct_2007[key] = value

get_rank_dct_2007 #Ranking at the end of 2007
134/160:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/161:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data('../assignment-final-data/2007.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/162:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
        df_list = [row for row in df_reader]
        return df_list
    
toy_data = get_data(['../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/163:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    final_list = []
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list.append([row for row in df_reader])
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/164:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    final_list = []
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list.append(row for row in df_reader)
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/165:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/166:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/167:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data : 
    if matches[0] == 'ASB Classic' : 
        print(matches)
134/168:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data : 
    if matches[1] == '2008-01-01' : 
        print(matches)
134/169:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data :  
        print(matches)
134/170:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data :  
    print(matches)
134/171:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data : 
    if matches[0] == 'Australian Open'
    print(matches)
134/172:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data : 
    if matches[0] == 'Australian Open' :
    print(matches)
134/173:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for matches in toy_data : 
    if matches[0] == 'Australian Open' :
        print(matches)
134/174:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(filenames) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    for file in filenames : 
        with open(file, 'r') as df :
            next(df)
            df_reader = csv.reader(df) 
            final_list = [row for row in df_reader]
        return final_list
    
toy_data = get_data(['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv'])

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/175:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2007.csv']
for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/176:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']
for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/177:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data
134/178:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if match[0] == 'ASB Classic' : 
        print(match)
134/179:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if match[1] == '2008-01-01' : 
        print(match)
134/180:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if match[1] == '2008-02-01' : 
        print(match)
134/181:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if match[1] == '2008-04-01' : 
        print(match)
134/182:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if '2007' == match[1] : 
        print(match)
134/183:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if '2007' in match[1] : 
        print(match)
134/184:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    toy_data = get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

for match in toy_data : 
    if '2008' in match[1] : 
        print(match)
134/185:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

for file in lst : 
    get_data(file)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
134/186:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2008.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
134/187:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2008.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
134/188:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2008.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two
134/189:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2008.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two
toy_data
134/190:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two
toy_data
134/191:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    if '2008' in matches[1] : 
        print(matches)
134/192:
# Import modules to estimate and show results

import csv

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

toy_data
134/193:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d")
    matches[2] = datetime.strptime(matches[1], "%Y-%m-%d")
134/194:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d")
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d")
134/195:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d")
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d")
    
toy_data
134/196:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    
toy_data
134/197:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    
toy_data
134/198:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    matches[6] = int(matches[6])
    matches[7] = int(matches[7])
    
toy_data
134/199:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    matches[6] = float(matches[6])
    matches[7] = int(matches[7])
    
toy_data
134/200:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    matches[6] = float(matches[6])
    matches[7] = float(matches[7])
    
toy_data
134/201:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    matches[6] = float(matches[6])
    if matches[7] != ''  :
        matches[7] = float(matches[7])
    
toy_data
134/202:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    if matches[6] != '' : 
        matches[6] = float(matches[6])
    if matches[7] != ''  :
        matches[7] = float(matches[7])
    
toy_data
134/203:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
134/204:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output
134/205:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


get_rank(toy_data, get_score)[:3]
134/206:
string = '2002-02-25' 

dt = datetime.datetime(string)
dt
134/207:
string = '2002-02-25' 

dt = datetime.strptime(string)
dt
134/208:
string = '2002-02-25' 

dt = datetime.strptime(string, "%Y-%m-%d")
dt
134/209:
string = '2002-02-25' 

dt = datetime.strptime(string, "%Y-%m-%d").date()
dt
134/210:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
134/211:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

dt1 - dt2
134/212:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

(dt1 - dt2).days
134/213:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

(dt1 - dt2).weeks
134/214:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

(dt1 - dt2).week
134/215:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

(dt1 - dt2).days
134/216:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

(dt1 - dt2).days/7
134/217:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()

(dt2 - dt1).days/7
134/218:
#Ans 5

def sublist(lst, date) : 
    week_diff = (rows[3] - date).days/7
    output = [rows for rows in lst if week_diff <=0 and week_diff >= -52]
    return output
134/219:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1
(dt2 - dt1).days/7
134/220:
string1 = '2002-02-25' 
string2 = '2002-02-04' 

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1
134/221:
#Ans 5

def sublist(lst, date) : 
    week_diff = (rows[3] - date).days/7
    output = [rows for rows in lst if week_diff <=0 and week_diff >= -52]
    return output

sublist(toy_data, datetime.date(2008, 2, 1))
134/222:
#Ans 5

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[3] - date).days/7 <=0) and ((rows[3] - date).days/7 >= -52)]
    return output

sublist(toy_data, datetime.date(2008, 2, 1))
134/223:
#Ans 5

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

sublist(toy_data, datetime.date(2008, 2, 1))
134/224:
string1 = '2002-02-25' 
string2 = '2002-02-04'
datetime.date(2002, 04, 12)

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1
134/225:
string1 = '2002-02-25' 
string2 = '2002-02-04'
dt3 = datetime.date(2002, 4, 12)

dt1 = datetime.strptime(string1, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt3-dt2
134/226:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt3-dt2
134/227:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1-dt2
134/228:
#Ans 5

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

sublist(toy_data, string3)
134/229:
#Ans 5

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

sublist(toy_data, dt1)
134/230:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    if matches[6] != '' : 
        matches[6] = float(matches[6])
    if matches[7] != ''  :
        matches[7] = float(matches[7])
    
toy_data
134/231:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(get_rank(toy_data, get_score)[:3]) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
134/232:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_rank_dct(get_rank(toy_data, get_score)[:3])
134/233:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_rank_dct(get_rank(toy_data, get_score)[:3])
134/234:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_rank(toy_data, get_score)[:3]
134/235:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_score(toy_data)
134/236:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    if matches[6] != '' : 
        matches[6] = float(matches[6])
    if matches[7] != ''  :
        matches[7] = float(matches[7])
    
toy_data
134/237:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
134/238:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output
134/239:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_score(toy_data)
134/240:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_rank(toy_data, get_score)
134/241:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output = {rows[0] : rows[2]}
    return output
    
get_rank_dct(get_rank(toy_data, get_score))
134/242:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    
    for rows in lst : 
        output = {rows[0] : rows[2]}
        
    return output
    
get_rank_dct(get_rank(toy_data, get_score))
134/243:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    for rows in lst : 
        output.update({rows[0] : rows[2]})
        
    return output
    
get_rank_dct(get_rank(toy_data, get_score))
134/244:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    output = {}
    for rows in lst : 
        output.update({rows[0] : rows[2]})
        
    return output
    
get_rank_dct(get_rank(toy_data, get_score))
134/245:
#Ans 5

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year == 2007 :
        matches.append(get_rank_dct[player_1])
        matches.append(get_rank_dct[player_2])
    else : 
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
134/246:
#Ans 5

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
134/247:
#Ans 5

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
    
toy_data
134/248:
#Ans 5

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
        print(matches)
134/249:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
        plt.plot(matches[6], matches[13])
134/250:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    WTA = []
    WbW = []
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
        WTA.append(matches[6])
        WbW.append(matches[12])
        
plt.plot(WTA, WbW)
134/251:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    WTA = []
    WbW = []
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
        WTA.append(matches[6])
        WbW.append(matches[13])
        
plt.plot(WTA, WbW)
134/252:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output
WTA = []
WbW = []
for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
        WTA.append(matches[6])
        WbW.append(matches[13])
        
plt.plot(WTA, WbW)
134/253:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output
WTA = []
WbW = []
for matches in toy_data : 
    player_1 = matches[4]
    player_2 = matches[5]
    start_date = matches[1]
    if start_date.year != 2007 :
        new_list = sublist(toy_data, start_date)
        score = get_rank_dct(get_rank(new_list, get_score))
        matches.append(score[player_1])
        matches.append(score[player_2])
        WTA.append(matches[6])
        WbW.append(matches[13])
        
plt.plot(WTA, WbW)
plt.scatter()
135/1:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    if matches[6] != '' : 
        matches[6] = float(matches[6])
    if matches[7] != ''  :
        matches[7] = float(matches[7])
    
toy_data
135/2:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
135/3:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output = []
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output.append([key, value, i])
        i+=1
    
    return output
135/4:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]
135/5:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)
135/6:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output


def get_rank_dct(lst) : 
    output = {}
    for rows in lst : 
        output.update({rows[0] : rows[2]})
        
    return output
135/7:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)
135/8:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)[1]
135/9:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)[0]
135/10:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)[1]
135/11:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    
    tournament = matches[0]
    start_date = matches[1]
    player_1 = matches[4]
    player_2 = matches[5]
    
    if start_date.year != 2007 :
        
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1]
        matches.append(rank[player_1])
        matches.append(rank[player_2])
        
        players = set()
        if tournament == last_tournament : 
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.append(player_1)
            if player_2 not in players :
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.append(player_2)
            last_tournament = tournament 
            
        
plt.scatter(WTA, WbW)
135/12:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {}

for matches in toy_data : 
    toy_data_dct.update({matches[0] : []})\
    toy_data_dct[matches[0]].append(matches[1 : ])
    
toy_data_dct

for matches in toy_data : 
    players = set()
    tournament = matches[0]
    start_date = matches[1]
    player_1 = matches[4]
    player_2 = matches[5]
    if start_date.year != 2007 :
        
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1]
        matches.append(rank[player_1])
        matches.append(rank[player_2])
        
        if player_1 not in players : 
            WTA.append(matches[6])
            WbW.append(matches[13])
            players.append(player_1)
            players.append(player_2)
135/13:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {matches[0] : [] for matches in toy_data}
    
toy_data_dct

for matches in toy_data : 
    players = set()
    tournament = matches[0]
    start_date = matches[1]
    player_1 = matches[4]
    player_2 = matches[5]
    if start_date.year != 2007 :
        
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1]
        matches.append(rank[player_1])
        matches.append(rank[player_2])
        
        if player_1 not in players : 
            WTA.append(matches[6])
            WbW.append(matches[13])
            players.append(player_1)
            players.append(player_2)
135/14:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {matches[0] : [] for matches in toy_data}
    
toy_data_dct

for matches in toy_data : 
    players = set()
    tournament = matches[0]
    start_date = matches[1]
    player_1 = matches[4]
    player_2 = matches[5]
    if start_date.year != 2007 :
        
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1]
        matches.append(rank[player_1])
        matches.append(rank[player_2])
        
        if player_1 not in players : 
            WTA.append(matches[6])
            WbW.append(matches[13])
135/15:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {matches[0] : [] for matches in toy_data}
    
toy_data_dct
135/16:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    toy_data_dct = {matches[0] : []}
    toy_data_dct[matches[0]].append(matches{1:})

toy_data_dct
135/17:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    toy_data_dct = {matches[0] : []}
    toy_data_dct[matches[0]].append(matches[1:])

toy_data_dct
135/18:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    toy_data_dct = {matches[0] : [matches[1:]]}

toy_data_dct
135/19:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    toy_data_dct.update({matches[0] : [matches[1:]]})

toy_data_dct
135/20:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {}

for matches in toy_data : 
    toy_data_dct.update({matches[0] : [matches[1:]]})

toy_data_dct
135/21:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {}

for matches in toy_data : 
    toy_data_dct.update({matches[0] : []})

toy_data_dct
135/22:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {matches[0] for matches in toy_data}

for matches in toy_data : 
    toy_data_dct[matches[0]].append(matches[1 : ])
    

toy_data_dct
135/23:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {matches[0] : [] for matches in toy_data}

for matches in toy_data : 
    toy_data_dct[matches[0]].append(matches[1 : ])
    

toy_data_dct
135/24:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []

toy_data_dct = {matches[0] : [] for matches in toy_data}

for matches in toy_data : 
    toy_data_dct[matches[0]].append(matches[1 : ])
135/25: toy_data_dct['ASB Classic'][1]
135/26: toy_data_dct['ASB Classic'][1][1]
135/27: toy_data_dct['ASB Classic'][1][1].year
135/28:
date = toy_data[1][1]

for match in toy_data :
    date_check = match[1]
    
    if (date_check - date).days < 0 : 
        print(match)
        
    date = date_check
135/29:
name = tournament[0][0]

for match in toy_data :
    name_check = match[0]
    
    if name_check != name : 
        print(match)
        
        name = name_check
135/30:
groups = []
uniquekeys = []
for k, g in groupby(data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)
135/31:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)
135/32:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)
135/33:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

group
135/34:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

groups
135/35:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

uniquekeys
135/36:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

from g in groups : 
    if g[0] == 'ASB Classic' : 
        print(g)
135/37:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    if g[0] == 'ASB Classic' : 
        print(g)
135/38:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    if g[0] == 'ASB Classic' : 
        print(g)
        
groups
135/39:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    for s in g :
        if g[0] == 'ASB Classic' : 
        print(g)
135/40:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    for s in g :
        if g[0] == 'ASB Classic' : 
            print(g)
135/41:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    for s in g :
        if s[0] == 'ASB Classic' : 
            print(g)
135/42:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    for s in g :
        if s[0] == 'ASB Classic' : 
            print(s)
135/43:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(g)    # Store group iterator as a list
   uniquekeys.append(k)

groups
135/44:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(dict(g))    # Store group iterator as a list
   uniquekeys.append(k)

groups
135/45:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

groups
135/46:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    for row in g : 
        row.append(row[0])
135/47:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)

for g in groups : 
    for row in g : 
        row.append(row[0])
  
groups
135/48:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)
135/49:
WTA = []
WbW = []
for g in groups :
    players = set()
    for match in g : 
        start_date = matches[1] 
        player_1 = matches[4]
        player_2 = matches[5]
        
        if start_date != 2007 : 
            new_list = sublist(toy_data, start_date)
            rank = get_rank(new_list, get_score)[1]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/50: WTA
135/51: WbW
135/52: WTA
135/53:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    new_list = sublist(toy_data, start_date)
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date != 2007 : 
        
        for match in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/54: WTA
135/55:
for g in groups : 
    start_date = g[0][1]
135/56:
for g in groups : 
    start_date = g[0][1]
    print(start_date)
135/57: groups
135/58: groups
135/59:
for g in groups : 
    new_list = sublist(toy_data, g[1][1])
135/60:
for g in groups : 
    new_list = sublist(toy_data, g[1][1])

new_list
135/61:
for g in groups : 
    print(g[0])
135/62: groups[0]
135/63: groups[1][1]
135/64: groups[1][0]
135/65:
for g in groups : 
    start_date = g[0][1]
    print(start_date)
135/66:
check = sublist(toy_data, datetime.date(2008, 1, 1))
check
135/67:
datetime.date(2008, 1, 1)
check = sublist(toy_data, datetime.date(2008, 1, 1))
check
135/68: datetime.date(2008, 1, 1)
135/69: new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d"))
135/70: new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
135/71:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
new_list
135/72:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -53)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    players = set()
    tournament = matches[0]
    start_date = matches[1]
    player_1 = matches[4]
    player_2 = matches[5]
    
    if start_date.year != 2007 :
        
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1]
        matches.append(rank[player_1])
        matches.append(rank[player_2])
        
        if tournament != last_tournament : 
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
135/73:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -53)]
    return output

WTA = []
WbW = []

for matches in toy_data : 
    players = set()
    tournament = matches[0]
    start_date = matches[1]
    player_1 = matches[4]
    player_2 = matches[5]
    
    if start_date.year != 2007 :
        
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1]
        matches.append(rank[player_1])
        matches.append(rank[player_2])
135/74:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -53)]
    return output

WTA = []
WbW = []
135/75:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[1] - date).days/7 <=0) and ((rows[1] - date).days/7 >= -53)]
    return output
135/76:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
new_list
135/77:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 <=0) and ((rows[2] - date).days/7 >= -52)]
    return output
135/78:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
new_list
135/79:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
rank = get_rank(new_list, get_score)
135/80:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
rank = get_rank(new_list, get_score)
rank
135/81:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
rank = get_rank(new_list, get_score)[1]
rank
135/82:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
rank = get_rank(new_list, get_score)[1]
rank
new_list
135/83:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
rank = get_rank(new_list, get_score)[1]
rank
new_list[-1]
135/84:
new_list = sublist(toy_data, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
rank = get_rank(new_list, get_score)[1]
rank
135/85:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    new_list = sublist(toy_data, start_date)
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date != 2007 : 
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/86: WTA
135/87:
WTA
WbW
135/88:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    if matches[6] != '' : 
        matches[6] = float(matches[6])
    if matches[7] != ''  :
        matches[7] = float(matches[7])
    
toy_data
135/89:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
135/90:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)[1]
135/91:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output
135/92:
#Ans 5

import matplotlib.pyplot as plt

    
def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output
135/93:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    new_list = sublist(toy_data, start_date)
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date != 2007 : 
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/94:
WTA
WbW
135/95:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)
135/96:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    new_list = sublist(toy_data, start_date)
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date != 2007 : 
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/97:
WTA
WbW
135/98: one
135/99: one[9]
135/100: one[10]
135/101: two[10]
135/102: two[9]
135/103: WTA
135/104: two[0]
135/105:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date != 2007 : 
         new_list = sublist(toy_data, start_date)
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/107:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date != 2007 : 
        new_list = sublist(toy_data, start_date)
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/108: WTA
135/109: groups
135/110:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/111: WTA
135/112: two
135/113: WbW
135/114: plt.scatterplot(WTA, WbW)
135/115: plt.scatter(WTA, WbW)
135/116:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

one = get_data('../assignment-final-data/2007.csv')
two = get_data('../assignment-final-data/2008.csv')

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

toy_data = one + two

for matches in toy_data : 
    matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
    matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
    matches[3] = int(matches[3])
    if matches[6] != '' : 
        matches[6] = int(float(matches[6]))
    if matches[7] != ''  :
        matches[7] = int(float(matches[7]))
    
toy_data
135/117:
from itertools import groupby 

groups = []
uniquekeys = []
for k, g in groupby(toy_data,  lambda x: x[0]) :
   groups.append(list(g))    # Store group iterator as a list
   uniquekeys.append(k)
135/118:
for row in toy_data : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
                

toy_data
135/119:
#Ans 2 

def get_players(lst) : 
    players = set()

    for match in toy_data : 
        name = match[0]
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in players : 
            players.add(player_1)
        
        if player_2 not in players : 
            players.add(player_2)
      
    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for match in lst : 
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(toy_data, get_score)[1]
135/120:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1
        
        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output
135/121:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                WTA.append(matches[6])
                WbW.append(matches[13])
                players.add(player_1)
                
            if player_2 not in players : 
                WTA.append(matches[7])
                WbW.append(matches[14])
                players.add(player_2)
135/122: plt.scatter(WTA, WbW)
135/123:
for a in WTA : 
    if a = '' : 
        print(a)
135/124:
for a in WTA : 
    if a == '' : 
        print(a)
135/125:
for a in WbW : 
    if a == '' : 
        print(a)
135/126:
WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                if matches[6] != '' :
                    WTA.append(matches[6])
                    WbW.append(matches[13])
                    players.add(player_1)
                
            if player_2 not in players :
                if matches[7] != '' :
                    WTA.append(matches[7])
                    WbW.append(matches[14])
                    players.add(player_2)
135/127:
for a in WTA : 
    if a == '' : 
        print(a)
135/128: plt.plot(WTA, WbW)
135/129: plt.scatter(WTA, WbW)
135/130:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                if matches[6] != '' :
                    WTA.append(matches[6])
                    WbW.append(matches[13])
                    players.add(player_1)
                
            if player_2 not in players :
                if matches[7] != '' :
                    WTA.append(matches[7])
                    WbW.append(matches[14])
                    players.add(player_2)

plt.scatter(WTA, WbW)
135/131:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            matches.append(rank[player_1]) #Update WbW rank for player 1
            matches.append(rank[player_2]) #Update WbW rank fot player 2
            
            if player_1 not in players : 
                if matches[6] != '' :
                    WTA.append(matches[6])
                    WbW.append(matches[13])
                    players.add(player_1)
                
            if player_2 not in players :
                if matches[7] != '' :
                    WTA.append(matches[7])
                    WbW.append(matches[14])
                    players.add(player_2)

plt.scatter(WTA, WbW)
135/132:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            
            if player_1 not in players : 
                if matches[6] != '' :
                    WTA.append(matches[6])
                    WbW.append(rank[player_1])
                    players.add(player_1)
                
            if player_2 not in players :
                if matches[7] != '' :
                    WTA.append(matches[7])
                    WbW.append(rank[player_2])
                    players.add(player_2)

plt.scatter(WTA, WbW)
135/133:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            
            if player_1 not in players : 
                if matches[6] != '' :
                    WTA.append(matches[6])
                    WbW.append(rank[player_1])
                    players.add(player_1)
                
            if player_2 not in players :
                if matches[7] != '' :
                    WTA.append(matches[7])
                    WbW.append(rank[player_1])
                    players.add(player_2)

plt.scatter(WTA, WbW)
135/134:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

WTA = []
WbW = []
for g in groups :
    players = set()
    start_date = g[0][1]
    
    if start_date.year != 2007 : 
        new_list = sublist(toy_data, start_date)
        rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
        
        for matches in g :  
            player_1 = matches[4]
            player_2 = matches[5]
            
            if player_1 not in players : 
                if matches[6] != '' :
                    WTA.append(matches[6])
                    WbW.append(rank[player_1])
                    players.add(player_1)
                
            if player_2 not in players :
                if matches[7] != '' :
                    WTA.append(matches[7])
                    WbW.append(rank[player_2])
                    players.add(player_2)

plt.scatter(WTA, WbW)
135/135:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

def plot_WTA_vs_WbW(lst) : 
    groups = []
    
    for k, g in groupby(toy_data,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in groups :
        players = set()
        start_date = g[0][1]

        if start_date.year != 2007 : 
            new_list = sublist(toy_data, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot
135/136:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

def plot_WTA_vs_WbW(lst) : 
    groups = []
    
    for k, g in groupby(toy_data,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in groups :
        players = set()
        start_date = g[0][1]

        if start_date.year != 2007 : 
            new_list = sublist(toy_data, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(toy_data)
136/1:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)


#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/2:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2008.csv', '../assignment-final-data/2007.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)


#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

final_list
136/3:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/200t.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)


#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

final_list
136/4:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)


#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']

final_list
136/5:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

final_list


#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/6:
#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
clean_list(final_list)
136/7:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/8:
#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    return lst
    
clean_list(final_list)
136/9:
#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
    uniquekeys = []
    groups = []
    for k, g in groupby(lst,  lambda x: x[0]) :
        groups.append(list(g))    # Store group iterator as a list
        uniquekeys.append(k)
    
    return groups
    
clean_list(final_list)
136/10:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/11:
#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
    uniquekeys = []
    groups = []
    for k, g in groupby(lst,  lambda x: x[0]) :
        groups.append(list(g))    # Store group iterator as a list
        uniquekeys.append(k)
    
    return groups
    
clean_list(final_list)
136/12:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
    uniquekeys = []
    groups = []
    for k, g in groupby(lst,  lambda x: x[0]) :
        groups.append(list(g))    # Store group iterator as a list
        uniquekeys.append(k)
    
    return groups
    
clean_list(final_list)
136/13:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/14:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
    uniquekeys = []
    groups = []
    for k, g in groupby(lst,  lambda x: x[0]) :
        groups.append(list(g))    # Store group iterator as a list
        uniquekeys.append(k)
    
    return groups
    
clean_list(final_list)
136/15:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/16:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
clean_list(final_list)
136/17: final_lst
136/18: final_list
136/19:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
136/20:
get_winner(final_lst)
final_lst
136/21:
get_winner(final_list)
final_list
136/22:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    groups = []
    uniquekeys = []
    for k, g in groupby(toy_data,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
        uniquekeys.append(k)
136/23:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    groups = []
    uniquekeys = []
    for k, g in groupby(toy_data,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
136/24:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    groups = []
    uniquekeys = []
    for k, g in groupby(toy_data,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return groups
136/25:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(toy_data,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return list(grouped_lst, uniquekeys)

grouping_tournament(final_data)[1]
136/26:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(toy_data,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return list(grouped_lst, uniquekeys)

grouping_tournaments(final_data)[1]
136/27:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(toy_data,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return list(grouped_lst, uniquekeys)

grouping_tournaments(final_list)[1]
136/28:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       groups.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return list(grouped_lst, uniquekeys)

grouping_tournaments(final_list)[1]
136/29:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return list(grouped_lst, uniquekeys)

grouping_tournaments(final_list)[1]
136/30:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouping_tournaments(final_list)[1]
136/31:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouping_tournaments(final_list)[0]
136/32:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
136/33:
#Determining the total number of rounds in the tournament

import math

output_total_participants = {}
output_total_rounds = {}
output_total_matches = {}
tournament = []
last_tournament = None 

for match in toy_data : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]

    if name != last_tournament : 
        output_total_participants.update({name : 0})
        output_total_rounds.update({name : 0})
        output_total_matches.update({name : 1})
        tournament.append([name, 0])
        last_tournament = name
        participants = set()
    
    elif name == last_tournament : 
        output_total_matches[name] += 1

    if player_1 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_1)

    if player_2 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_2)
        
    output_total_participants[name] = tournament[-1][1]
    output_total_rounds = math.ceil(math.log(output_total_participants[name], 2))
136/34:
#Determining the total number of rounds in the tournament

import math

output_total_participants = {}
output_total_rounds = {}
output_total_matches = {}
tournament = []
last_tournament = None 

for match in final_list : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]

    if name != last_tournament : 
        output_total_participants.update({name : 0})
        output_total_rounds.update({name : 0})
        output_total_matches.update({name : 1})
        tournament.append([name, 0])
        last_tournament = name
        participants = set()
    
    elif name == last_tournament : 
        output_total_matches[name] += 1

    if player_1 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_1)

    if player_2 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_2)
        
    output_total_participants[name] = tournament[-1][1]
    output_total_rounds = math.ceil(math.log(output_total_participants[name], 2))
136/35:
#Determining the total number of rounds in the tournament

import math

output_total_participants = {}
output_total_rounds = {}
output_total_matches = {}
tournament = []
last_tournament = None 

for match in final_list : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]

    if name != last_tournament : 
        output_total_participants.update({name : 0})
        output_total_rounds.update({name : 0})
        output_total_matches.update({name : 1})
        tournament.append([name, 0])
        last_tournament = name
        participants = set()
    
    elif name == last_tournament : 
        output_total_matches[name] += 1

    if player_1 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_1)

    if player_2 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_2)
        
    output_total_participants[name] = tournament[-1][1]
    output_total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
136/36:
#Determining the total number of rounds in the tournament

import math

output_total_participants = {}
output_total_rounds = {}
output_total_matches = {}
tournament = []
last_tournament = None 

for match in final_list : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]

    if name != last_tournament : 
        output_total_participants.update({name : 0})
        output_total_rounds.update({name : 0})
        output_total_matches.update({name : 1})
        tournament.append([name, 0])
        last_tournament = name
        participants = set()
    
    elif name == last_tournament : 
        output_total_matches[name] += 1

    if player_1 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_1)

    if player_2 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_2)
        
    output_total_participants[name] = tournament[-1][1]
    output_total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
ouput_total_matches
136/37:
#Determining the total number of rounds in the tournament

import math

output_total_participants = {}
output_total_rounds = {}
output_total_matches = {}
tournament = []
last_tournament = None 

for match in final_list : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]

    if name != last_tournament : 
        output_total_participants.update({name : 0})
        output_total_rounds.update({name : 0})
        output_total_matches.update({name : 1})
        tournament.append([name, 0])
        last_tournament = name
        participants = set()
    
    elif name == last_tournament : 
        output_total_matches[name] += 1

    if player_1 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_1)

    if player_2 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_2)
        
    output_total_participants[name] = tournament[-1][1]
    output_total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
output_total_matches
136/38:
#Determining the total number of rounds in the tournament

import math

output_total_participants = {}
output_total_rounds = {}
output_total_matches = {}
tournament = []
last_tournament = None 

for match in final_list : 
    name = match[0]
    player_1 = match[4]
    player_2 = match[5]

    if name != last_tournament : 
        output_total_participants.update({name : 0})
        output_total_rounds.update({name : 0})
        output_total_matches.update({name : 1})
        tournament.append([name, 0])
        last_tournament = name
        participants = set()
    
    elif name == last_tournament : 
        output_total_matches[name] += 1

    if player_1 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_1)

    if player_2 not in participants : 
        tournament[-1][1] += 1
        participants.add(player_2)
        
    output_total_participants[name] = tournament[-1][1]
    output_total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
output_total_participants
136/39:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped_list : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(group)

    for match in tournament :
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)

        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
136/40:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(group)

    for match in tournament :
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)

        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
136/41:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)

        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
136/42:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/43:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
clean_list(final_list)
136/44:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
136/45:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0] 

def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        no_of_players = get_total_participants(toy_data)[name] #Function that calculates the number of players in tournament
        no_of_matches = get_total_matches(toy_data)[name] #Function that calculates the number of matches in tournament
        rounds = get_total_rounds(toy_data)[name] #Function that calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
136/46:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)

        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
136/47:
def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in lst : 
        name = match[0]
         
        if name != last_tournament : 
            output.append({name : 1})
            last_tournament = name 
        elif : 
            output[name] += 1
    
    return output
            
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in lst: 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in lst : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
136/48:
def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in lst : 
        name = match[0]
         
        if name != last_tournament : 
            output.append({name : 1})
            last_tournament = name 
        else : 
            output[name] += 1
    
    return output
            
    
def get_total_rounds(lst) : 
    output = {}
    last_tournament = None
    
    for match in lst: 
        name = match[0] 
        player_1 = match[4]
        player_2 = match[5] 
        
        if name != last_tournament : 
            output.update({name : 0})
            last_tournament = name
            
        output[name] = math.ceil(math.log(get_total_participants(toy_data)[name], 2))
        
    return output 

def get_total_matches(lst) : 
    output = {}
    last_tournament = None
    
    for match in lst : 
        name = match[0] 
 
        
        if name != last_tournament : 
            output.update({name : 1}) 
            last_tournament = name
            
        elif name == last_tournament : 
            output[name] += 1
            
        
    return output
136/49:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
136/50:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
    
clean_list(final_list)
136/51:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
136/52:
get_winner(final_list)
final_list
136/53:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0] 

def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        no_of_players = get_total_participants(toy_data)[name] #Function that calculates the number of players in tournament
        no_of_matches = get_total_matches(toy_data)[name] #Function that calculates the number of matches in tournament
        rounds = get_total_rounds(toy_data)[name] #Function that calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
136/54:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_1)

        if player_2 not in participants : 
            tournament[-1][1] += 1
            participants.add(player_2)

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
136/55: grouped
136/56:
for tournament in grouped : 
    for match in tournament : 
        player_1 = match[4]
136/57:
for tournament in grouped : 
    for match in tournament : 
        print(match)
136/58:
for tournament in grouped : 
    for match in tournament : 
        print(match[4])
136/59:
for tournament in grouped : 
    for match in tournament : 
        player_1 = match[4]
136/60:
for tournament in grouped : 
    for match in tournament : 
        print(match[4])
136/61:
for tournament in grouped : 
    for match in tournament : 
        if match[4] not in [] : 
            print(match)
136/62:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        player_1 = match[4]
        player_2 = match[5]
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
136/63:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
137/1:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/2:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/3:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/4:
get_winner(final_list)
final_list
137/5:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
137/6:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0] 

def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        no_of_players = get_total_participants(toy_data)[name] #Function that calculates the number of players in tournament
        no_of_matches = get_total_matches(toy_data)[name] #Function that calculates the number of matches in tournament
        rounds = get_total_rounds(toy_data)[name] #Function that calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/7:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
137/8:
for tournament in grouped : 
    for match in tournament : 
        if match[4] not in [] : 
            print(match)
137/9:
for tournament in grouped : 
    for match in tournament : 
        if match[4] not in [] : 
            print(match)
137/10:
for tournament in grouped : 
    for match in tournament : 
            print(match)
137/11:
for tournament in grouped : 
    for match in tournament : 
        if match[4] = '2007-01-01'
            print(match)
137/12:
for tournament in grouped : 
    for match in tournament : 
        if match[4] == '2007-01-01'
            print(match)
137/13:
for tournament in grouped : 
    for match in tournament : 
        if match[4] == '2007-01-01' :
            print(match)
137/14:
for tournament in grouped : 
    for match in tournament : 
            print(match)
137/15:
for tournament in grouped : 
    for match in tournament : 
            if match[1] == '2007-01-01' : 
                print(match)
137/16:
for tournament in grouped : 
    for match in tournament : 
            if match[4] == 'Baker L.' : 
                print(match)
137/17:
for tournament in grouped : 
    for match in tournament : 
        winners = []
            if match[4] == 'Baker L.' : 
                winners.append(match[4])
                
print(winners)
137/18:
for tournament in grouped : 
    for match in tournament : 
        winners = []
        if match[4] == 'Baker L.' : 
            winners.append(match[4])
                
print(winners)
137/19: grouped
137/20:
for tournament in grouped : 
    for match in tournament : 
        print(match)
137/21:
for tournament in grouped : 
    for match in tournament : 
        print(match[4])
137/22:
for tournament in grouped : 
    for match in tournament : 
        print(match)
137/23: grouped
137/24:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/25:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/26:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/27:
get_winner(final_list)
final_list
137/28:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
137/29:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/30:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for tournament in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
137/31:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/32:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/33:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/34:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: x[0]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/35:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = tournament[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(tournament)

    for match in tournament :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
137/36:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(output_total_participants[name], 2))
    
total_participants
137/37:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/38:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1]) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/39:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/40:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    total_participants.update({name : 0})
    total_rounds.update({name : 0})
    total_matches.update({name : 1})
    tournament.append([name, 0])
    total_matches[name] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name] = tournament[-1][1]
    total_rounds[name] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/41:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1.year()
137/42:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1
137/43:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
dt1.year
137/44:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
str(dt1.year)
137/45:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
str(dt1.year) + ha
137/46:
string1 = '2002-02-25' 
string2 = '2002-02-04'
string3 = '2008-02-01'

dt1 = datetime.strptime(string3, "%Y-%m-%d").date()
dt2 = datetime.strptime(string2, "%Y-%m-%d").date()
str(dt1.year) + 'ha'
137/47:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    year = str(g[0][1].year)
    total_participants.update({name + year : 0})
    total_rounds.update({name + year : 0})
    total_matches.update({name + year : 1})
    tournament.append([name + year, 0])
    total_matches[name + year] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name + year] = tournament[-1][1]
    total_rounds[name + year] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/48:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    year = g[0][1].year
    total_participants.update({name + year : 0})
    total_rounds.update({name + year : 0})
    total_matches.update({name + year : 1})
    tournament.append([name + year, 0])
    total_matches[name + year] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name + year] = tournament[-1][1]
    total_rounds[name + year] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/49:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/50:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    year = str(g[0][1].year)
    total_participants.update({name + year : 0})
    total_rounds.update({name + year : 0})
    total_matches.update({name + year : 1})
    tournament.append([name + year, 0])
    total_matches[name + year] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name + year] = tournament[-1][1]
    total_rounds[name + year] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/51:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/52:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/53:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/54:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/55:
get_winner(final_list)
final_list
137/56:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/57:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    year = g[0][1].year
    total_participants.update({name + year : 0})
    total_rounds.update({name + year : 0})
    total_matches.update({name + year : 1})
    tournament.append([name + year, 0])
    total_matches[name + year] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name + year] = tournament[-1][1]
    total_rounds[name + year] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/58:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    year = g[0][1]
    total_participants.update({name + year : 0})
    total_rounds.update({name + year : 0})
    total_matches.update({name + year : 1})
    tournament.append([name + year, 0])
    total_matches[name + year] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[name + year] = tournament[-1][1]
    total_rounds[name + year] = math.ceil(math.log(total_participants[name], 2))
    
total_participants
137/59:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    date = g[0][1]
    tourney = name + date
    total_participants.update({tourney : 0})
    total_rounds.update({tourney : 0})
    total_matches.update({tourney : 1})
    tournament.append([tourney, 0])
    total_matches[tourney] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
    
total_participants
137/60:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    total_participants.update({tourney : 0})
    total_rounds.update({tourney : 0})
    total_matches.update({tourney : 1})
    tournament.append([tourney, 0])
    total_matches[tourney] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
    
total_participants
137/61:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    total_participants.update({tourney : 0})
    total_rounds.update({tourney : 0})
    total_matches.update({tourney : 1})
    tournament.append([tourney, 0])
    total_matches[tourney] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
    
total_rounds
137/62:
#Determining the total number of rounds in the tournament

import math

total_participants = {}
total_rounds = {}
total_matches = {}
tournament = []
last_tournament = None 

for g in grouped : 
    participants = set()
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    total_participants.update({tourney : 0})
    total_rounds.update({tourney : 0})
    total_matches.update({tourney : 1})
    tournament.append([tourney, 0])
    total_matches[tourney] = len(g)

    for match in g :
        
        if match[4] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[4])

        if match[5] not in participants : 
            tournament[-1][1] += 1
            participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
    
total_matches
137/63:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/64:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/65:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/66:
get_winner(final_list)
final_list
137/67:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/68:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
        return [total_matches, total_participants, total_rounds]
137/69:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
        return [total_matches, total_participants, total_rounds]
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
137/70: total_matches
137/71:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
        return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
137/72: total_matches
137/73:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
137/74: total_matches
137/75: total_participants
137/76:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return list(total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
137/77:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

    total_participants[tourney] = tournament[-1][1]
    total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
137/78:
#Determining the total number of rounds in the tournament

import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
137/79: tournament_participants
137/80: total_participants
137/81: total_rounds
137/82:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/83: reconstruct_tournament(grouped)
137/84:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/85: reconstruct_tournament(grouped)
137/86:
reconstruct_tournament(grouped)
grouped
137/87:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/88:
reconstruct_tournament(grouped)
grouped
137/89:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/90:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 2 :
                            match.append(i)

                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')

                        elif i == rounds - 1 : 
                            match.append('Semi Finals')

                        elif i == rounds  : 
                            match.append('Finals')
                        
                    else : 
                        match.append(i)
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                
                participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/91:
reconstruct_tournament(grouped)
grouped
137/92:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                    participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/93:
reconstruct_tournament(grouped)
grouped
137/94:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/95:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/96:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/97:
get_winner(final_list)
final_list
137/98:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
grouped
137/99:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        
        winners = [] #List containing the winner of each match in the tournament
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        
        if name not in round_robin : #Different algorithm for RR tourneys 
            
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])
                        
                elif no_of_players == no_of_matches : #Third place tournaments 

                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')


                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)

                        if i < rounds - 3 : 
                            match.append(i)
                            
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')

                        elif i == rounds - 2 : 
                            match.append('Semi Finals')

                        elif i == rounds - 1 : 
                            match.append('Third Place')

                        elif i == rounds  : 
                            match.append('Finals')

                    else : 
                        match.append(i)
                    participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)

                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/100:
reconstruct_tournament(grouped)
grouped
137/101:
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of matches = total_matches[tourney]
    rounds = total_rounds[tourney]
137/102:
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
137/103:
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    check = []
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    check.append(no_of_players) 

check
137/104:
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    check.append(no_of_players) 

check
137/105:
check = []
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    check.append(no_of_players)
137/106:
check = []
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    check.append(no_of_players) 
    
check
137/107:
check = []
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    
    for match in g : 
        print(match)
137/108:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        i = 1
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])
                elif no_of_players == no_of_matches : #Third place tournaments 
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 3 : 
                            match.append(i)
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')
                        elif i == rounds - 2 : 
                            match.append('Semi Finals')
                        elif i == rounds - 1 : 
                            match.append('Third Place')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 3 : 
                            match.append(i)
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')
                        elif i == rounds - 2 : 
                            match.append('Semi Finals')
                        elif i == rounds - 1 : 
                            match.append('Third Place')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/109:
reconstruct_tournament(grouped)
grouped
137/110:
check = []
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    participant_count = []
    i = 1
    
    for match in g : 
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 in participant_count :
            i += participant_count.count(player_1)
            match.append(i)
            
        elif player_2 in participant_count :
            i += participant_count.count(player_2)
            match.append(i)
            
        else :
            match.append(i)
        participant_count.append(match[12])
137/111:
check = []
for g in grouped : 
    name = g[0][0]
    date = g[0][1]
    tourney = name + ' ' + date
    no_of_players = total_participants[tourney]
    no_of_matches = total_matches[tourney]
    rounds = total_rounds[tourney]
    participant_count = []
    i = 1
    
    for match in g : 
        player_1 = match[4]
        player_2 = match[5]
        
        if player_1 in participant_count :
            i += participant_count.count(player_1)
            match.append(i)
            
        elif player_2 in participant_count :
            i += participant_count.count(player_2)
            match.append(i)
            
        else :
            match.append(i)
        participant_count.append(match[12])
        
grouped
137/112:
def check(lst)
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            participant_count.append(match[12])
        
check(grouped) 
grouped
137/113:
def check(lst) :
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            participant_count.append(match[12])
        
check(grouped) 
grouped
137/114:
def check(lst) :
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            participant_count.append(match[12])
        
check(grouped) 
grouped
137/115:
def check(lst) :
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])
            
            return participant_count
        
check(grouped)
137/116:
def check(lst) :
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])
            
        return participant_count
        
check(grouped)
137/117:
def check(lst) :
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])
            
    return participant_count
        
check(grouped)
137/118:
def check(lst) :
    for g in lst : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])
            
        return participant_count
        
check(grouped)
137/119:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])
137/120:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        participant_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in participant_count :
                i += participant_count.count(player_1)
                match.append(i)

            elif player_2 in participant_count :
                i += participant_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])

grouped
137/121:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        winner_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in winner_count :
                i += winner_count.count(player_1)
                match.append(i)

            elif player_2 in winner_count :
                i += winner_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            participant_count.append(match[12])

grouped
137/122:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        winner_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in winner_count :
                i += winner_count.count(player_1)
                match.append(i)

            elif player_2 in winner_count :
                i += winner_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            winner_count.append(match[12])

grouped
137/123:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        winner_count = []
        i = 1

        for match in g : 
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in winner_count :
                i += 1
                match.append(i)

            elif player_2 in winner_count :
                i += winner_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            winner_count.append(match[12])

grouped
137/124:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        winner_count = []

        for match in g : 
            i = 1
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in winner_count :
                i += 1
                match.append(i)

            elif player_2 in winner_count :
                i += winner_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            winner_count.append(match[12])

grouped
137/125:

    for g in grouped : 
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney]
        no_of_matches = total_matches[tourney]
        rounds = total_rounds[tourney]
        winner_count = []

        for match in g : 
            i = 1
            player_1 = match[4]
            player_2 = match[5]

            if player_1 in winner_count :
                i += winner_count.count(player_1)
                match.append(i)

            elif player_2 in winner_count :
                i += winner_count.count(player_2)
                match.append(i)

            else :
                match.append(i)
            
            winner_count.append(match[12])

grouped
137/126:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/127:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/128:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/129: get_winner(final_list)
137/130:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
137/131:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if no_of_players == no_of_matches - 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])
                elif no_of_players == no_of_matches : #Third place tournaments 
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 3 : 
                            match.append(i)
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')
                        elif i == rounds - 2 : 
                            match.append('Semi Finals')
                        elif i == rounds - 1 : 
                            match.append('Third Place')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 3 : 
                            match.append(i)
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')
                        elif i == rounds - 2 : 
                            match.append('Semi Finals')
                        elif i == rounds - 1 : 
                            match.append('Third Place')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/132:
reconstruct_tournament(grouped)
grouped
137/133:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if no_of_players == no_of_matches + 1 : #No third place tournaments
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 2 :
                            match.append(i)
                        elif i == rounds - 2 : 
                            match.append('Quarter Finals')
                        elif i == rounds - 1 : 
                            match.append('Semi Finals')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])
                elif no_of_players == no_of_matches : #Third place tournaments 
                    if player_1 in participants_count : 
                        i += participants_count.count(player_1)
                        if i < rounds - 3 : 
                            match.append(i)
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')
                        elif i == rounds - 2 : 
                            match.append('Semi Finals')
                        elif i == rounds - 1 : 
                            match.append('Third Place')
                        elif i == rounds  : 
                            match.append('Finals')
                    elif player_2 in participants_count : # To account for byes in R2
                        i += participants_count.count(player_2)
                        if i < rounds - 3 : 
                            match.append(i)
                        elif i == rounds - 3 :
                            match.append('Quarter Finals')
                        elif i == rounds - 2 : 
                            match.append('Semi Finals')
                        elif i == rounds - 1 : 
                            match.append('Third Place')
                        elif i == rounds  : 
                            match.append('Finals')
                    else : 
                        match.append(i)
                    participants_count.append(match[12])

                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/134:
reconstruct_tournament(grouped)
grouped
137/135:
for g in grouped : 
    for match in g : 
        if match[13] == 'Finals' : 
            print(match)
137/136:
for g in grouped : 
    for match in g : 
        if match[13] == 'Third Place' : 
            print(match)
137/137: total_participants('Internationaux de Strasbourg 2007-05-21')
137/138: total_participants['Internationaux de Strasbourg 2007-05-21']
137/139: total_matches['Internationaux de Strasbourg 2007-05-21']
137/140: total_rounds['Internationaux de Strasbourg 2007-05-21']
137/141:
for g in grouped : 
    for match in g : 
        if match[13] == 'Semi Finals' : 
            print(match)
137/142:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
137/143:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))
137/144:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
137/145: get_winner(final_list)
137/146:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
137/147:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
137/148:
reconstruct_tournament(grouped)
grouped
137/149:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    f i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
137/150:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    if i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
137/151:
reconstruct_tournament(grouped)
grouped
137/152:
for g in grouped : 
    for match in g : 
        if match[0] in round_robin : 
            print(match)
137/153:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                player_1 = mach[4]
                player_2 = match[5]
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    if i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
137/154:
reconstruct_tournament(grouped)
grouped
137/155:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                player_1 = match[4]
                player_2 = match[5]
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    if i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
137/156:
reconstruct_tournament(grouped)
grouped
137/157:
for g in grouped : 
    for match in g : 
        if match[0] in round_robin : 
            print(match)
137/158:
#Ans 2 

def get_players(lst) : 
    players = set()

    for tournament in lst : 
        for match in tournament :
            player_1 = match[4]
            player_2 = match[5]
            if player_1 not in players : 
                players.add(player_1)
            if player_2 not in players : 
                players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for tournament in lst : 
        for match in tournament :
            winner = match[12]
            output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(grouped, get_wins)[1]
137/159:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for tournament in lst : 
        for match in tournament : 
            player1 = match[4]
            player2 = match[5]
            winner = match[12]
            if player1 == winner : 
                loser = player2 
            else : 
                loser = player1

            lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output
137/160:
#Ans 2 

def get_players(lst) : 
    players = set()

    for tournament in lst : 
        for match in tournament :
            player_1 = match[4]
            player_2 = match[5]
            if player_1 not in players : 
                players.add(player_1)
            if player_2 not in players : 
                players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for tournament in lst : 
        for match in tournament :
            winner = match[12]
            output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(grouped, get_score)[1]
137/161:
#Ans 2 

def get_players(lst) : 
    players = set()

    for tournament in lst : 
        for match in tournament :
            player_1 = match[4]
            player_2 = match[5]
            if player_1 not in players : 
                players.add(player_1)
            if player_2 not in players : 
                players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for tournament in lst : 
        for match in tournament :
            winner = match[12]
            output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

get_rank(grouped, get_score)[0]
137/162:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

def plot_WTA_vs_WbW(lst) : 
    groups = []
    
    for k, g in groupby(toy_data,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in lst :
        players = set()
        start_date = g[0][1]

        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(toy_data)
137/163:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

def plot_WTA_vs_WbW(lst) : 
    groups = []
    
    for k, g in groupby(toy_data,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in lst :
        players = set()
        start_date = g[0][1]

        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list)
137/164:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

def plot_WTA_vs_WbW(lst) : 
    groups = []
    
    for k, g in groupby(final_list,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in lst :
        players = set()
        start_date = g[0][1]

        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list)
   1:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
   2:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
   3: get_winner(final_list)
   4:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
   5:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                player_1 = match[4]
                player_2 = match[5]
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    if i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
   6:
reconstruct_tournament(grouped)
grouped
   7:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
   8:
reconstruct_tournament(grouped)
grouped
   9:
#Ans 2 

def get_players(lst) : 
    players = set()

    for tournament in lst : 
        for match in tournament :
            player_1 = match[4]
            player_2 = match[5]
            if player_1 not in players : 
                players.add(player_1)
            if player_2 not in players : 
                players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for tournament in lst : 
        for match in tournament :
            winner = match[12]
            output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(grouped, get_wins)[0]
  10:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for tournament in lst : 
        for match in tournament : 
            player1 = match[4]
            player2 = match[5]
            winner = match[12]
            if player1 == winner : 
                loser = player2 
            else : 
                loser = player1

            lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(grouped, get_score)[0]
  11:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
  12:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = datetime.strptime(matches[1], "%Y-%m-%d").date()
        matches[2] = datetime.strptime(matches[2], "%Y-%m-%d").date()
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))

clean_list(final_list)
  13:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
  14: get_winner(final_list)
  15:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
  16:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
  17:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1].year
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
  18:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = str(g[0][1])
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
  19:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = str(g[0][1])
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
total_matches
  20:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = str(g[0][1])
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
total_participants
  21:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = str(g[0][1])
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
  22:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = str(tournament[0][1]) #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                player_1 = match[4]
                player_2 = match[5]
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    if i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
  23:
reconstruct_tournament(grouped)
grouped
  24:
# Import modules to estimate and show results

import csv
from datetime import datetime

#toy data 

def get_data(file) : 
    '''
    To convert rows in data frame into lists and store them all in one list
    Assumes a '.csv' file 
    Returns a list with each element list representing a row of the given file
    '''
    
    with open(file, 'r') as df :
        next(df)
        df_reader = csv.reader(df) 
        final_list = [row for row in df_reader]
        return final_list
    
lst = ['../assignment-final-data/2007.csv', '../assignment-final-data/2008.csv']

final_list = []

for link in lst : 
    final_list = final_list + get_data(link)

#Types of win : 
# Best of 3 : most sets won 
# Retired : One player retired
# Bye : When the match doesnt really take place 

#Type of tournaments : 
#Knockouts 
#Round Robins 

round_robin = ['Sony Ericsson Championships', 'Commonwealth Bank Tournament of Champions', 
               'Qatar Airways Tournament of Champions Sofia', 'Garanti Koza WTA Tournament of Champions', 
               'BNP Paribas WTA Finals', 'WTA Elite Trophy', 'WTA Finals']
  25:
from itertools import groupby 

#Cleaning function 
def clean_list(lst) : 
    for matches in lst : 
        matches[1] = str(datetime.strptime(matches[1], "%Y-%m-%d").date())
        matches[2] = str(datetime.strptime(matches[2], "%Y-%m-%d").date())
        matches[3] = int(matches[3])
        if matches[6] != '' : 
            matches[6] = int(float(matches[6]))
        if matches[7] != ''  :
            matches[7] = int(float(matches[7]))

clean_list(final_list)
  26:
def get_winner(lst) : 
    for row in lst : 
        player_1 = row[4]
        player_2 = row[5]
        set_1 = row[8]
        set_2 = row[9]
        set_3 = row[10]
        
        if row[11] == 'Completed' : #For completed matches
            i = 0 
            set_1 = set_1.split('-')
            set_1 = [int(i) for i in set_1]
            
            set_2 = set_2.split('-')
            set_2 = [int(i) for i in set_2]
            
            if set_1[0] > set_1[1] : 
                i += 1 
            if set_2[0] > set_2[1] :
                i += 1
                
                #Match going to third set
            if set_3 != '' : 
                set_3 = set_3.split('-')
                set_3 = [int(i) for i in set_3]
                    
                if set_3[0] > set_3[1] : 
                    i += 1 
                        
            if i >= 2 : 
                row.append(player_1) 
                
            else : 
                row.append(player_2)
            
        else : #Matches that were not completed 
            store = row[11].split(' Retired')
            
            if player_1 != store[0] : 
                row.append(player_1)
                
            else : 
                row.append(player_2)
  27: get_winner(final_list)
  28:
from itertools import groupby 

#Ans1

def grouping_tournaments(lst) :
    grouped_lst = []
    uniquekeys = []
    for k, g in groupby(lst,  lambda x: (x[0], x[1])) :
       grouped_lst.append(list(g))    # Store group iterator as a list
       uniquekeys.append(k)
    return (grouped_lst, uniquekeys)

grouped = grouping_tournaments(final_list)[0]
  29:
import math

def tournament_stats(lst) :

    total_participants = {}
    total_rounds = {}
    total_matches = {}
    tournament = []
    last_tournament = None 

    for g in lst : 
        participants = set()
        name = g[0][0]
        date = g[0][1]
        tourney = name + ' ' + date
        total_participants.update({tourney : 0})
        total_rounds.update({tourney : 0})
        total_matches.update({tourney : 1})
        tournament.append([tourney, 0])
        total_matches[tourney] = len(g)

        for match in g :

            if match[4] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[4])

            if match[5] not in participants : 
                tournament[-1][1] += 1
                participants.add(match[5])

        total_participants[tourney] = tournament[-1][1]
        total_rounds[tourney] = math.ceil(math.log(total_participants[tourney], 2))
        
    return (total_matches, total_participants, total_rounds)
    
total_matches = tournament_stats(grouped)[0]
total_participants = tournament_stats(grouped)[1]
total_rounds = tournament_stats(grouped)[2]
  30:
def reconstruct_tournament(lst) : 
    
    for tournament in lst :
        participants_count = [] #List containing the number of appearances by a player in the tournament
        participants = set() #Set containing all participants in the tournament
        name = tournament[0][0] #Name of the tournament
        date = tournament[0][1] #Tournament start date 
        tourney = name + ' ' + date
        no_of_players = total_participants[tourney] #calculates the number of players in tournament
        no_of_matches = total_matches[tourney] #calculates the number of matches in tournament
        rounds = total_rounds[tourney] #calculates the number of rounds in a tournament
        if name not in round_robin : #Different algorithm for RR tourneys 
            for match in tournament : #iterate through all matches in a tournament
                i = 1
                player_1 = match[4] #Stores player1
                player_2 = match[5] #Stores player2
                if player_1 in participants_count : 
                    i += participants_count.count(player_1)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                elif player_2 in participants_count : # To account for byes in R2
                    i += participants_count.count(player_2)
                    if i < rounds - 2 :
                        match.append(i)
                    elif i == rounds - 2 : 
                        match.append('Quarter Finals')
                    elif i == rounds - 1 : 
                        match.append('Semi Finals')
                    elif i == rounds  : 
                        match.append('Finals')
                else : 
                    match.append(i)
                participants_count.append(match[12])
                
                if i == 1 : #Store the participants of R1
                    participants.add(player_1)
                    participants.add(player_2)

                if i == 2 : #Add the players that got a 'bye' in R1 to the winners list twice. Assumption is that players who got a bye in R1 will not go against each other in R2 as they are likely to be the top seeded ones.
                    if player_1 not in participants : 
                        participants_count.append(player_1)
                    if player_2 not in participants : 
                        participants_count.append(player_2)
        elif name in round_robin : 
            for match in tournament : 
                player_1 = match[4]
                player_2 = match[5]
                participants_count.append(player_1)
                participants_count.append(player_2)
                i = max(participants_count.count(player_1), participants_count.count(player_2)) 
                if name != 'WTA Elite Trophy': 
                    if i <= 3 : 
                        match.append('Group Stage')
                    if i == 4 : 
                        match.append('Semi Finals')
                    if i == 5 : 
                        match.append('Finals')
                else :  #As WTA Elite Trophy has 12 participants divided into 4 groups of 3 participants
                    if i <= 2 : 
                        match.append('Group Stage')
                    if i == 3 : 
                        match.append('Semi Finals')
                    if i == 4 : 
                        match.append('Finals')
  31:
reconstruct_tournament(grouped)
grouped
  32:
#Ans 2 

def get_players(lst) : 
    players = set()

    for tournament in lst : 
        for match in tournament :
            player_1 = match[4]
            player_2 = match[5]
            if player_1 not in players : 
                players.add(player_1)
            if player_2 not in players : 
                players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
    
    for tournament in lst : 
        for match in tournament :
            winner = match[12]
            output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(grouped, get_wins)[0]
  33:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for tournament in lst : 
        for match in tournament : 
            player1 = match[4]
            player2 = match[5]
            winner = match[12]
            if player1 == winner : 
                loser = player2 
            else : 
                loser = player1

            lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(grouped, get_score)[0]
  34: '2007' %in% '2007 - 01 - 01'
  35: '2007' in'2007 - 01 - 01'
  36:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in tournament :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[0]
  37:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in lst :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[0]
  38:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in lst :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[0]
wins_rank
  39:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in lst :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[1]
wins_rank
  40:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in tournament : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1

        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(final_list, get_score)[0]
  41:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1

        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(final_list, get_score)[0]
  42:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1

        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(final_list, get_score)[0]
WbW_rank
  43:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1

        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(final_list, get_score)[1]
WbW_rank
  44:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) : 
    output = [rows for rows in lst if ((rows[2] - date).days/7 < 0) and ((rows[2] - date).days/7 >= -52)]
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []
    
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year == 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  45:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []
    
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year == 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  46:
#Ans4 : WbW Rankings 

def get_score(lst) : 
    players = get_players(lst)
    count_players = len(players)
    initial = 1/count_players
    output = {players : initial for players in players} #initialize
    lost_to = {players : [] for players in players}
    
    for match in lst : 
        player1 = match[4]
        player2 = match[5]
        winner = match[12]
        if player1 == winner : 
            loser = player2 
        else : 
            loser = player1

        lost_to[loser].append(winner)
              
    for key in output : 
        beat = lost_to[key]
        loss = len(beat) 

        if loss == 0 : 
            output[key] += output[key]

        else : 
            temp = output[key]/loss
            output[key] -= temp
            
            for players in beat :   
                output[players] += temp

        output[key] = 0.85*output[key] + (0.15/count_players) #rescale

    return output

WbW_rank = get_rank(final_list, get_score)[1]
WbW_rank
  47:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in lst :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[1]
wins_rank
  48: sublist(final_list, datetime.strptime('2008-01-01', "%Y-%m-%d").date())
  49:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []
    
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  50:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []
    
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list
   
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' and rank[player_2] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  51:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in lst :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[1]
wins_rank['Jones S.']
  52:
#Ans 2 

def get_players(lst) : 
    players = set()
 
    for match in lst :
        player_1 = match[4]
        player_2 = match[5]
        if player_1 not in players : 
            players.add(player_1)
        if player_2 not in players : 
            players.add(player_2)

    return players

def get_wins(lst) :
    players = get_players(lst)
    output = dict.fromkeys(players, 0) #Initialize a dictionary with all players 
     
    for match in lst :
        winner = match[12]
        output[winner] += 1
    
    return output


def get_rank(lst, fun) : 
    win_count = fun(lst)
    output_lst = []
    output_dct = {}
    i = 1
    
    for key, value in sorted(win_count.items(), key = lambda x : x[1], reverse = True) : 
        output_lst.append([key, value, i])
        output_dct.update({key : i})
        i+=1
    
    
    return [output_lst, output_dct]

wins_rank = get_rank(final_list, get_wins)[1]
wins_rank
  53:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []   
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list  
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  54:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []   
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list  
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players and player_2 not in rank.items() :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  55:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []   
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list  
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players and player_2 in rank.items() :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  56:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst, grouped_list) : 
    #groups = []   
    #for k, g in groupby(lst,  lambda x: x[0]) : 
        #groups.append(list(g))    # Store group iterator as a list  
    WTA = []
    WbW = []
    for g in grouped_list :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament

            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]

                if player_1 not in players and player_1 in rank.items() : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)

                if player_2 not in players and player_2 in rank.items() :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list, grouped)
  57:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst) : 
    groups = []   
    for k, g in groupby(lst,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list  
    WTA = []
    WbW = []
    for g in groups :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]
                if player_1 not in players and player_1 in rank.items() : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)
                if player_2 not in players and player_2 in rank.items() :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list)
  58:
#Ans 5

import matplotlib.pyplot as plt

def sublist(lst, date) :
    output = []
    for rows in lst : 
        current_date = datetime.strptime(rows[1], "%Y-%m-%d").date()
        if ((current_date - date).days/7 < 0) and ((current_date - date).days/7 >= -52) :
            output.append(rows)
            
    return output

def plot_WTA_vs_WbW(lst) : 
    
    groups = []   
    for k, g in groupby(lst,  lambda x: x[0]) : 
        groups.append(list(g))    # Store group iterator as a list
        
    WTA = []
    WbW = []
    
    for g in groups :
        players = set()
        start_date = datetime.strptime(g[0][1], "%Y-%m-%d").date()
        if start_date.year != 2007 : 
            new_list = sublist(lst, start_date)
            rank = get_rank(new_list, get_score)[1] #Gets rank based on results from 52 weeks before start of tournament
            for matches in g :  
                player_1 = matches[4]
                player_2 = matches[5]
                if player_1 not in players and player_1 in rank.items() : 
                    if matches[6] != '' :
                        WTA.append(matches[6])
                        WbW.append(rank[player_1])
                        players.add(player_1)
                if player_2 not in players and player_2 in rank.items() :
                    if matches[7] != '' :
                        WTA.append(matches[7])
                        WbW.append(rank[player_2])
                        players.add(player_2)

    plot = plt.scatter(WTA, WbW)
    return plot

plot_WTA_vs_WbW(final_list)
  59: %history
  60: %history -g
  61: %history -g -f MY470_final_assign
